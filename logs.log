2025-04-06 21:05:33,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:52,196:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:05:52,221:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:05:52,592:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:06:32,303:INFO:PyCaret ClassificationExperiment
2025-04-06 21:06:32,303:INFO:Logging name: clf-default-name
2025-04-06 21:06:32,304:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-06 21:06:32,304:INFO:version 3.3.2
2025-04-06 21:06:32,304:INFO:Initializing setup()
2025-04-06 21:06:32,304:INFO:self.USI: b85d
2025-04-06 21:06:32,304:INFO:self._variable_keys: {'seed', 'exp_id', 'fix_imbalance', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'is_multiclass', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:06:32,304:INFO:Checking environment
2025-04-06 21:06:32,304:INFO:python_version: 3.11.4
2025-04-06 21:06:32,304:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:06:32,304:INFO:machine: AMD64
2025-04-06 21:06:32,334:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:06:32,340:INFO:Memory: svmem(total=17127211008, available=2428715008, percent=85.8, used=14698496000, free=2428715008)
2025-04-06 21:06:32,340:INFO:Physical Core: 6
2025-04-06 21:06:32,340:INFO:Logical Core: 12
2025-04-06 21:06:32,340:INFO:Checking libraries
2025-04-06 21:06:32,340:INFO:System:
2025-04-06 21:06:32,340:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:06:32,340:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:06:32,340:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:06:32,340:INFO:PyCaret required dependencies:
2025-04-06 21:06:35,356:INFO:                 pip: 25.0.1
2025-04-06 21:06:35,356:INFO:          setuptools: 65.5.0
2025-04-06 21:06:35,356:INFO:             pycaret: 3.3.2
2025-04-06 21:06:35,356:INFO:             IPython: 8.32.0
2025-04-06 21:06:35,356:INFO:          ipywidgets: 8.1.5
2025-04-06 21:06:35,356:INFO:                tqdm: 4.67.1
2025-04-06 21:06:35,356:INFO:               numpy: 1.26.4
2025-04-06 21:06:35,356:INFO:              pandas: 2.1.4
2025-04-06 21:06:35,356:INFO:              jinja2: 3.1.2
2025-04-06 21:06:35,356:INFO:               scipy: 1.11.4
2025-04-06 21:06:35,356:INFO:              joblib: 1.3.2
2025-04-06 21:06:35,356:INFO:             sklearn: 1.4.2
2025-04-06 21:06:35,356:INFO:                pyod: 2.0.3
2025-04-06 21:06:35,356:INFO:            imblearn: 0.13.0
2025-04-06 21:06:35,356:INFO:   category_encoders: 2.7.0
2025-04-06 21:06:35,356:INFO:            lightgbm: 4.6.0
2025-04-06 21:06:35,357:INFO:               numba: 0.61.0
2025-04-06 21:06:35,357:INFO:            requests: 2.32.3
2025-04-06 21:06:35,357:INFO:          matplotlib: 3.7.5
2025-04-06 21:06:35,357:INFO:          scikitplot: 0.3.7
2025-04-06 21:06:35,357:INFO:         yellowbrick: 1.5
2025-04-06 21:06:35,357:INFO:              plotly: 5.24.1
2025-04-06 21:06:35,357:INFO:    plotly-resampler: Not installed
2025-04-06 21:06:35,357:INFO:             kaleido: 0.2.1
2025-04-06 21:06:35,357:INFO:           schemdraw: 0.15
2025-04-06 21:06:35,357:INFO:         statsmodels: 0.14.4
2025-04-06 21:06:35,357:INFO:              sktime: 0.26.0
2025-04-06 21:06:35,357:INFO:               tbats: 1.1.3
2025-04-06 21:06:35,357:INFO:            pmdarima: 2.0.4
2025-04-06 21:06:35,357:INFO:              psutil: 7.0.0
2025-04-06 21:06:35,357:INFO:          markupsafe: 2.1.3
2025-04-06 21:06:35,357:INFO:             pickle5: Not installed
2025-04-06 21:06:35,357:INFO:         cloudpickle: 3.1.1
2025-04-06 21:06:35,357:INFO:         deprecation: 2.1.0
2025-04-06 21:06:35,357:INFO:              xxhash: 3.5.0
2025-04-06 21:06:35,357:INFO:           wurlitzer: Not installed
2025-04-06 21:06:35,358:INFO:PyCaret optional dependencies:
2025-04-06 21:06:42,516:INFO:                shap: 0.44.1
2025-04-06 21:06:42,516:INFO:           interpret: 0.6.9
2025-04-06 21:06:42,516:INFO:                umap: 0.5.7
2025-04-06 21:06:42,516:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:06:42,516:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:06:42,516:INFO:             autoviz: Not installed
2025-04-06 21:06:42,516:INFO:           fairlearn: 0.7.0
2025-04-06 21:06:42,516:INFO:          deepchecks: Not installed
2025-04-06 21:06:42,516:INFO:             xgboost: Not installed
2025-04-06 21:06:42,516:INFO:            catboost: 1.2.7
2025-04-06 21:06:42,516:INFO:              kmodes: 0.12.2
2025-04-06 21:06:42,516:INFO:             mlxtend: 0.23.4
2025-04-06 21:06:42,516:INFO:       statsforecast: 1.5.0
2025-04-06 21:06:42,516:INFO:        tune_sklearn: Not installed
2025-04-06 21:06:42,516:INFO:                 ray: Not installed
2025-04-06 21:06:42,517:INFO:            hyperopt: 0.2.7
2025-04-06 21:06:42,517:INFO:              optuna: 4.2.1
2025-04-06 21:06:42,517:INFO:               skopt: 0.10.2
2025-04-06 21:06:42,517:INFO:              mlflow: 2.21.0
2025-04-06 21:06:42,517:INFO:              gradio: 5.21.0
2025-04-06 21:06:42,517:INFO:             fastapi: 0.115.11
2025-04-06 21:06:42,517:INFO:             uvicorn: 0.34.0
2025-04-06 21:06:42,517:INFO:              m2cgen: 0.10.0
2025-04-06 21:06:42,517:INFO:           evidently: 0.4.40
2025-04-06 21:06:42,517:INFO:               fugue: 0.8.7
2025-04-06 21:06:42,517:INFO:           streamlit: 1.42.2
2025-04-06 21:06:42,517:INFO:             prophet: Not installed
2025-04-06 21:06:42,517:INFO:None
2025-04-06 21:06:42,517:INFO:Set up data.
2025-04-06 21:06:42,678:INFO:Set up folding strategy.
2025-04-06 21:06:42,679:INFO:Set up train/test split.
2025-04-06 21:06:56,241:INFO:PyCaret RegressionExperiment
2025-04-06 21:06:56,241:INFO:Logging name: reg-default-name
2025-04-06 21:06:56,241:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:06:56,241:INFO:version 3.3.2
2025-04-06 21:06:56,241:INFO:Initializing setup()
2025-04-06 21:06:56,242:INFO:self.USI: 1fbf
2025-04-06 21:06:56,242:INFO:self._variable_keys: {'seed', 'exp_id', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'data', 'USI', 'transform_target_param', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:06:56,242:INFO:Checking environment
2025-04-06 21:06:56,242:INFO:python_version: 3.11.4
2025-04-06 21:06:56,242:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:06:56,242:INFO:machine: AMD64
2025-04-06 21:06:56,242:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:06:56,247:INFO:Memory: svmem(total=17127211008, available=2227048448, percent=87.0, used=14900162560, free=2227048448)
2025-04-06 21:06:56,247:INFO:Physical Core: 6
2025-04-06 21:06:56,247:INFO:Logical Core: 12
2025-04-06 21:06:56,247:INFO:Checking libraries
2025-04-06 21:06:56,247:INFO:System:
2025-04-06 21:06:56,247:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:06:56,247:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:06:56,247:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:06:56,247:INFO:PyCaret required dependencies:
2025-04-06 21:06:56,248:INFO:                 pip: 25.0.1
2025-04-06 21:06:56,248:INFO:          setuptools: 65.5.0
2025-04-06 21:06:56,248:INFO:             pycaret: 3.3.2
2025-04-06 21:06:56,248:INFO:             IPython: 8.32.0
2025-04-06 21:06:56,248:INFO:          ipywidgets: 8.1.5
2025-04-06 21:06:56,248:INFO:                tqdm: 4.67.1
2025-04-06 21:06:56,248:INFO:               numpy: 1.26.4
2025-04-06 21:06:56,248:INFO:              pandas: 2.1.4
2025-04-06 21:06:56,248:INFO:              jinja2: 3.1.2
2025-04-06 21:06:56,248:INFO:               scipy: 1.11.4
2025-04-06 21:06:56,248:INFO:              joblib: 1.3.2
2025-04-06 21:06:56,248:INFO:             sklearn: 1.4.2
2025-04-06 21:06:56,248:INFO:                pyod: 2.0.3
2025-04-06 21:06:56,248:INFO:            imblearn: 0.13.0
2025-04-06 21:06:56,248:INFO:   category_encoders: 2.7.0
2025-04-06 21:06:56,248:INFO:            lightgbm: 4.6.0
2025-04-06 21:06:56,248:INFO:               numba: 0.61.0
2025-04-06 21:06:56,248:INFO:            requests: 2.32.3
2025-04-06 21:06:56,248:INFO:          matplotlib: 3.7.5
2025-04-06 21:06:56,249:INFO:          scikitplot: 0.3.7
2025-04-06 21:06:56,249:INFO:         yellowbrick: 1.5
2025-04-06 21:06:56,249:INFO:              plotly: 5.24.1
2025-04-06 21:06:56,249:INFO:    plotly-resampler: Not installed
2025-04-06 21:06:56,249:INFO:             kaleido: 0.2.1
2025-04-06 21:06:56,249:INFO:           schemdraw: 0.15
2025-04-06 21:06:56,249:INFO:         statsmodels: 0.14.4
2025-04-06 21:06:56,249:INFO:              sktime: 0.26.0
2025-04-06 21:06:56,249:INFO:               tbats: 1.1.3
2025-04-06 21:06:56,249:INFO:            pmdarima: 2.0.4
2025-04-06 21:06:56,249:INFO:              psutil: 7.0.0
2025-04-06 21:06:56,249:INFO:          markupsafe: 2.1.3
2025-04-06 21:06:56,249:INFO:             pickle5: Not installed
2025-04-06 21:06:56,249:INFO:         cloudpickle: 3.1.1
2025-04-06 21:06:56,249:INFO:         deprecation: 2.1.0
2025-04-06 21:06:56,249:INFO:              xxhash: 3.5.0
2025-04-06 21:06:56,249:INFO:           wurlitzer: Not installed
2025-04-06 21:06:56,249:INFO:PyCaret optional dependencies:
2025-04-06 21:06:56,249:INFO:                shap: 0.44.1
2025-04-06 21:06:56,249:INFO:           interpret: 0.6.9
2025-04-06 21:06:56,250:INFO:                umap: 0.5.7
2025-04-06 21:06:56,250:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:06:56,250:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:06:56,250:INFO:             autoviz: Not installed
2025-04-06 21:06:56,250:INFO:           fairlearn: 0.7.0
2025-04-06 21:06:56,250:INFO:          deepchecks: Not installed
2025-04-06 21:06:56,250:INFO:             xgboost: Not installed
2025-04-06 21:06:56,250:INFO:            catboost: 1.2.7
2025-04-06 21:06:56,250:INFO:              kmodes: 0.12.2
2025-04-06 21:06:56,250:INFO:             mlxtend: 0.23.4
2025-04-06 21:06:56,250:INFO:       statsforecast: 1.5.0
2025-04-06 21:06:56,250:INFO:        tune_sklearn: Not installed
2025-04-06 21:06:56,250:INFO:                 ray: Not installed
2025-04-06 21:06:56,250:INFO:            hyperopt: 0.2.7
2025-04-06 21:06:56,250:INFO:              optuna: 4.2.1
2025-04-06 21:06:56,250:INFO:               skopt: 0.10.2
2025-04-06 21:06:56,250:INFO:              mlflow: 2.21.0
2025-04-06 21:06:56,251:INFO:              gradio: 5.21.0
2025-04-06 21:06:56,251:INFO:             fastapi: 0.115.11
2025-04-06 21:06:56,251:INFO:             uvicorn: 0.34.0
2025-04-06 21:06:56,251:INFO:              m2cgen: 0.10.0
2025-04-06 21:06:56,251:INFO:           evidently: 0.4.40
2025-04-06 21:06:56,251:INFO:               fugue: 0.8.7
2025-04-06 21:06:56,251:INFO:           streamlit: 1.42.2
2025-04-06 21:06:56,251:INFO:             prophet: Not installed
2025-04-06 21:06:56,251:INFO:None
2025-04-06 21:06:56,251:INFO:Set up data.
2025-04-06 21:06:56,402:INFO:Set up folding strategy.
2025-04-06 21:06:56,402:INFO:Set up train/test split.
2025-04-06 21:06:56,499:INFO:Set up index.
2025-04-06 21:06:56,502:INFO:Assigning column types.
2025-04-06 21:06:56,508:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:06:56,508:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,514:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,664:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:56,665:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:56,884:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,889:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,032:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,033:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:06:57,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,182:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,333:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,333:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:06:57,345:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,483:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,631:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,631:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:06:57,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,787:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,934:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,935:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:06:58,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:58,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,084:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:58,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,238:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,239:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:06:58,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,386:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,533:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,542:INFO:Preparing preprocessing pipeline...
2025-04-06 21:06:58,542:INFO:Set up simple imputation.
2025-04-06 21:06:58,556:INFO:Set up encoding of categorical features.
2025-04-06 21:07:00,383:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:07:00,391:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:07:00,391:INFO:Creating final display dataframe.
2025-04-06 21:07:03,509:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape       (30000, 16)
4        Transformed data shape       (30000, 16)
5   Transformed train set shape       (21000, 16)
6    Transformed test set shape        (9000, 16)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              3.2%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              1fbf
2025-04-06 21:07:03,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:07:03,735:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:07:03,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:07:03,888:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:07:03,889:INFO:setup() successfully completed in 7.65s...............
2025-04-06 21:07:03,889:INFO:Initializing compare_models()
2025-04-06 21:07:03,889:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:07:03,889:INFO:Checking exceptions
2025-04-06 21:07:03,894:INFO:Preparing display monitor
2025-04-06 21:07:03,898:INFO:Initializing Linear Regression
2025-04-06 21:07:03,898:INFO:Total runtime is 0.0 minutes
2025-04-06 21:07:03,899:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:03,899:INFO:Initializing create_model()
2025-04-06 21:07:03,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:03,899:INFO:Checking exceptions
2025-04-06 21:07:03,899:INFO:Importing libraries
2025-04-06 21:07:03,899:INFO:Copying training dataset
2025-04-06 21:07:03,911:INFO:Defining folds
2025-04-06 21:07:03,911:INFO:Declaring metric variables
2025-04-06 21:07:03,911:INFO:Importing untrained model
2025-04-06 21:07:03,911:INFO:Linear Regression Imported successfully
2025-04-06 21:07:03,912:INFO:Starting cross validation
2025-04-06 21:07:03,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:16,399:INFO:Calculating mean and std
2025-04-06 21:07:16,400:INFO:Creating metrics dataframe
2025-04-06 21:07:16,403:INFO:Uploading results into container
2025-04-06 21:07:16,404:INFO:Uploading model into container now
2025-04-06 21:07:16,404:INFO:_master_model_container: 1
2025-04-06 21:07:16,404:INFO:_display_container: 2
2025-04-06 21:07:16,404:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:07:16,404:INFO:create_model() successfully completed......................................
2025-04-06 21:07:16,653:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:16,653:INFO:Creating metrics dataframe
2025-04-06 21:07:16,655:INFO:Initializing Lasso Regression
2025-04-06 21:07:16,655:INFO:Total runtime is 0.21262481609980266 minutes
2025-04-06 21:07:16,655:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:16,656:INFO:Initializing create_model()
2025-04-06 21:07:16,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:16,656:INFO:Checking exceptions
2025-04-06 21:07:16,656:INFO:Importing libraries
2025-04-06 21:07:16,656:INFO:Copying training dataset
2025-04-06 21:07:16,668:INFO:Defining folds
2025-04-06 21:07:16,668:INFO:Declaring metric variables
2025-04-06 21:07:16,668:INFO:Importing untrained model
2025-04-06 21:07:16,669:INFO:Lasso Regression Imported successfully
2025-04-06 21:07:16,669:INFO:Starting cross validation
2025-04-06 21:07:16,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:18,823:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.574e+15, tolerance: 2.175e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,120:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.767e+15, tolerance: 2.004e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,285:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.857e+15, tolerance: 2.141e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.569e+15, tolerance: 2.137e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,575:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.051e+15, tolerance: 2.057e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+15, tolerance: 2.217e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,863:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.029e+15, tolerance: 2.021e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,995:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.293e+15, tolerance: 2.123e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,479:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+15, tolerance: 2.076e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,523:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.006e+15, tolerance: 1.903e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,578:INFO:Calculating mean and std
2025-04-06 21:07:25,579:INFO:Creating metrics dataframe
2025-04-06 21:07:25,581:INFO:Uploading results into container
2025-04-06 21:07:25,581:INFO:Uploading model into container now
2025-04-06 21:07:25,582:INFO:_master_model_container: 2
2025-04-06 21:07:25,582:INFO:_display_container: 2
2025-04-06 21:07:25,582:INFO:Lasso(random_state=123)
2025-04-06 21:07:25,582:INFO:create_model() successfully completed......................................
2025-04-06 21:07:25,789:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:25,789:INFO:Creating metrics dataframe
2025-04-06 21:07:25,791:INFO:Initializing Ridge Regression
2025-04-06 21:07:25,792:INFO:Total runtime is 0.3649000644683838 minutes
2025-04-06 21:07:25,792:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:25,792:INFO:Initializing create_model()
2025-04-06 21:07:25,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:25,792:INFO:Checking exceptions
2025-04-06 21:07:25,792:INFO:Importing libraries
2025-04-06 21:07:25,792:INFO:Copying training dataset
2025-04-06 21:07:25,804:INFO:Defining folds
2025-04-06 21:07:25,804:INFO:Declaring metric variables
2025-04-06 21:07:25,804:INFO:Importing untrained model
2025-04-06 21:07:25,805:INFO:Ridge Regression Imported successfully
2025-04-06 21:07:25,805:INFO:Starting cross validation
2025-04-06 21:07:25,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:28,560:INFO:Calculating mean and std
2025-04-06 21:07:28,561:INFO:Creating metrics dataframe
2025-04-06 21:07:28,562:INFO:Uploading results into container
2025-04-06 21:07:28,563:INFO:Uploading model into container now
2025-04-06 21:07:28,563:INFO:_master_model_container: 3
2025-04-06 21:07:28,563:INFO:_display_container: 2
2025-04-06 21:07:28,563:INFO:Ridge(random_state=123)
2025-04-06 21:07:28,563:INFO:create_model() successfully completed......................................
2025-04-06 21:07:28,743:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:28,743:INFO:Creating metrics dataframe
2025-04-06 21:07:28,745:INFO:Initializing Elastic Net
2025-04-06 21:07:28,745:INFO:Total runtime is 0.4141197959582011 minutes
2025-04-06 21:07:28,746:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:28,746:INFO:Initializing create_model()
2025-04-06 21:07:28,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:28,746:INFO:Checking exceptions
2025-04-06 21:07:28,746:INFO:Importing libraries
2025-04-06 21:07:28,746:INFO:Copying training dataset
2025-04-06 21:07:28,759:INFO:Defining folds
2025-04-06 21:07:28,759:INFO:Declaring metric variables
2025-04-06 21:07:28,759:INFO:Importing untrained model
2025-04-06 21:07:28,760:INFO:Elastic Net Imported successfully
2025-04-06 21:07:28,760:INFO:Starting cross validation
2025-04-06 21:07:28,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:30,497:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.016e+15, tolerance: 1.903e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:30,828:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e+15, tolerance: 2.076e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,160:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.584e+15, tolerance: 2.175e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.774e+15, tolerance: 2.004e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,489:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.866e+15, tolerance: 2.141e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,652:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+15, tolerance: 2.137e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,745:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.061e+15, tolerance: 2.057e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,933:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e+15, tolerance: 2.217e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,948:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.037e+15, tolerance: 2.021e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:32,052:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e+15, tolerance: 2.123e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:32,097:INFO:Calculating mean and std
2025-04-06 21:07:32,098:INFO:Creating metrics dataframe
2025-04-06 21:07:32,099:INFO:Uploading results into container
2025-04-06 21:07:32,100:INFO:Uploading model into container now
2025-04-06 21:07:32,100:INFO:_master_model_container: 4
2025-04-06 21:07:32,100:INFO:_display_container: 2
2025-04-06 21:07:32,101:INFO:ElasticNet(random_state=123)
2025-04-06 21:07:32,101:INFO:create_model() successfully completed......................................
2025-04-06 21:07:32,298:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:32,298:INFO:Creating metrics dataframe
2025-04-06 21:07:32,301:INFO:Initializing Least Angle Regression
2025-04-06 21:07:32,301:INFO:Total runtime is 0.4733945568402608 minutes
2025-04-06 21:07:32,301:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:32,302:INFO:Initializing create_model()
2025-04-06 21:07:32,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:32,302:INFO:Checking exceptions
2025-04-06 21:07:32,302:INFO:Importing libraries
2025-04-06 21:07:32,302:INFO:Copying training dataset
2025-04-06 21:07:32,315:INFO:Defining folds
2025-04-06 21:07:32,315:INFO:Declaring metric variables
2025-04-06 21:07:32,315:INFO:Importing untrained model
2025-04-06 21:07:32,315:INFO:Least Angle Regression Imported successfully
2025-04-06 21:07:32,316:INFO:Starting cross validation
2025-04-06 21:07:32,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:34,905:INFO:Calculating mean and std
2025-04-06 21:07:34,906:INFO:Creating metrics dataframe
2025-04-06 21:07:34,907:INFO:Uploading results into container
2025-04-06 21:07:34,908:INFO:Uploading model into container now
2025-04-06 21:07:34,908:INFO:_master_model_container: 5
2025-04-06 21:07:34,908:INFO:_display_container: 2
2025-04-06 21:07:34,908:INFO:Lars(random_state=123)
2025-04-06 21:07:34,909:INFO:create_model() successfully completed......................................
2025-04-06 21:07:35,099:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:35,099:INFO:Creating metrics dataframe
2025-04-06 21:07:35,101:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:07:35,101:INFO:Total runtime is 0.52005881468455 minutes
2025-04-06 21:07:35,102:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:35,102:INFO:Initializing create_model()
2025-04-06 21:07:35,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:35,102:INFO:Checking exceptions
2025-04-06 21:07:35,102:INFO:Importing libraries
2025-04-06 21:07:35,102:INFO:Copying training dataset
2025-04-06 21:07:35,113:INFO:Defining folds
2025-04-06 21:07:35,113:INFO:Declaring metric variables
2025-04-06 21:07:35,114:INFO:Importing untrained model
2025-04-06 21:07:35,114:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:07:35,114:INFO:Starting cross validation
2025-04-06 21:07:35,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:37,791:INFO:Calculating mean and std
2025-04-06 21:07:37,792:INFO:Creating metrics dataframe
2025-04-06 21:07:37,794:INFO:Uploading results into container
2025-04-06 21:07:37,794:INFO:Uploading model into container now
2025-04-06 21:07:37,794:INFO:_master_model_container: 6
2025-04-06 21:07:37,794:INFO:_display_container: 2
2025-04-06 21:07:37,795:INFO:LassoLars(random_state=123)
2025-04-06 21:07:37,795:INFO:create_model() successfully completed......................................
2025-04-06 21:07:37,981:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:37,981:INFO:Creating metrics dataframe
2025-04-06 21:07:37,983:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:07:37,983:INFO:Total runtime is 0.5680956323941548 minutes
2025-04-06 21:07:37,983:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:37,984:INFO:Initializing create_model()
2025-04-06 21:07:37,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:37,984:INFO:Checking exceptions
2025-04-06 21:07:37,984:INFO:Importing libraries
2025-04-06 21:07:37,984:INFO:Copying training dataset
2025-04-06 21:07:37,996:INFO:Defining folds
2025-04-06 21:07:37,997:INFO:Declaring metric variables
2025-04-06 21:07:37,997:INFO:Importing untrained model
2025-04-06 21:07:37,997:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:07:37,997:INFO:Starting cross validation
2025-04-06 21:07:37,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:40,559:INFO:Calculating mean and std
2025-04-06 21:07:40,560:INFO:Creating metrics dataframe
2025-04-06 21:07:40,561:INFO:Uploading results into container
2025-04-06 21:07:40,562:INFO:Uploading model into container now
2025-04-06 21:07:40,562:INFO:_master_model_container: 7
2025-04-06 21:07:40,562:INFO:_display_container: 2
2025-04-06 21:07:40,562:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:07:40,563:INFO:create_model() successfully completed......................................
2025-04-06 21:07:40,742:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:40,742:INFO:Creating metrics dataframe
2025-04-06 21:07:40,744:INFO:Initializing Bayesian Ridge
2025-04-06 21:07:40,745:INFO:Total runtime is 0.614098604520162 minutes
2025-04-06 21:07:40,745:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:40,745:INFO:Initializing create_model()
2025-04-06 21:07:40,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:40,746:INFO:Checking exceptions
2025-04-06 21:07:40,746:INFO:Importing libraries
2025-04-06 21:07:40,746:INFO:Copying training dataset
2025-04-06 21:07:40,757:INFO:Defining folds
2025-04-06 21:07:40,757:INFO:Declaring metric variables
2025-04-06 21:07:40,757:INFO:Importing untrained model
2025-04-06 21:07:40,758:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:07:40,758:INFO:Starting cross validation
2025-04-06 21:07:40,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:43,386:INFO:Calculating mean and std
2025-04-06 21:07:43,387:INFO:Creating metrics dataframe
2025-04-06 21:07:43,389:INFO:Uploading results into container
2025-04-06 21:07:43,389:INFO:Uploading model into container now
2025-04-06 21:07:43,389:INFO:_master_model_container: 8
2025-04-06 21:07:43,389:INFO:_display_container: 2
2025-04-06 21:07:43,390:INFO:BayesianRidge()
2025-04-06 21:07:43,390:INFO:create_model() successfully completed......................................
2025-04-06 21:07:43,595:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:43,595:INFO:Creating metrics dataframe
2025-04-06 21:07:43,597:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:07:43,597:INFO:Total runtime is 0.6616563200950623 minutes
2025-04-06 21:07:43,597:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:43,598:INFO:Initializing create_model()
2025-04-06 21:07:43,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:43,598:INFO:Checking exceptions
2025-04-06 21:07:43,598:INFO:Importing libraries
2025-04-06 21:07:43,598:INFO:Copying training dataset
2025-04-06 21:07:43,609:INFO:Defining folds
2025-04-06 21:07:43,610:INFO:Declaring metric variables
2025-04-06 21:07:43,610:INFO:Importing untrained model
2025-04-06 21:07:43,610:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:07:43,610:INFO:Starting cross validation
2025-04-06 21:07:43,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:46,297:INFO:Calculating mean and std
2025-04-06 21:07:46,298:INFO:Creating metrics dataframe
2025-04-06 21:07:46,299:INFO:Uploading results into container
2025-04-06 21:07:46,300:INFO:Uploading model into container now
2025-04-06 21:07:46,300:INFO:_master_model_container: 9
2025-04-06 21:07:46,300:INFO:_display_container: 2
2025-04-06 21:07:46,300:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:07:46,301:INFO:create_model() successfully completed......................................
2025-04-06 21:07:46,488:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:46,488:INFO:Creating metrics dataframe
2025-04-06 21:07:46,490:INFO:Initializing Huber Regressor
2025-04-06 21:07:46,491:INFO:Total runtime is 0.7098896821339925 minutes
2025-04-06 21:07:46,491:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:46,491:INFO:Initializing create_model()
2025-04-06 21:07:46,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:46,491:INFO:Checking exceptions
2025-04-06 21:07:46,491:INFO:Importing libraries
2025-04-06 21:07:46,491:INFO:Copying training dataset
2025-04-06 21:07:46,502:INFO:Defining folds
2025-04-06 21:07:46,503:INFO:Declaring metric variables
2025-04-06 21:07:46,503:INFO:Importing untrained model
2025-04-06 21:07:46,503:INFO:Huber Regressor Imported successfully
2025-04-06 21:07:46,503:INFO:Starting cross validation
2025-04-06 21:07:46,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:48,586:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,617:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,649:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,861:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,037:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,407:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,622:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,633:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,687:INFO:Calculating mean and std
2025-04-06 21:07:50,688:INFO:Creating metrics dataframe
2025-04-06 21:07:50,690:INFO:Uploading results into container
2025-04-06 21:07:50,690:INFO:Uploading model into container now
2025-04-06 21:07:50,691:INFO:_master_model_container: 10
2025-04-06 21:07:50,691:INFO:_display_container: 2
2025-04-06 21:07:50,691:INFO:HuberRegressor()
2025-04-06 21:07:50,691:INFO:create_model() successfully completed......................................
2025-04-06 21:07:50,876:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:50,876:INFO:Creating metrics dataframe
2025-04-06 21:07:50,878:INFO:Initializing K Neighbors Regressor
2025-04-06 21:07:50,878:INFO:Total runtime is 0.7830108602841696 minutes
2025-04-06 21:07:50,878:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:50,878:INFO:Initializing create_model()
2025-04-06 21:07:50,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:50,879:INFO:Checking exceptions
2025-04-06 21:07:50,879:INFO:Importing libraries
2025-04-06 21:07:50,879:INFO:Copying training dataset
2025-04-06 21:07:50,891:INFO:Defining folds
2025-04-06 21:07:50,891:INFO:Declaring metric variables
2025-04-06 21:07:50,891:INFO:Importing untrained model
2025-04-06 21:07:50,891:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:07:50,892:INFO:Starting cross validation
2025-04-06 21:07:50,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:53,730:INFO:Calculating mean and std
2025-04-06 21:07:53,731:INFO:Creating metrics dataframe
2025-04-06 21:07:53,733:INFO:Uploading results into container
2025-04-06 21:07:53,734:INFO:Uploading model into container now
2025-04-06 21:07:53,734:INFO:_master_model_container: 11
2025-04-06 21:07:53,734:INFO:_display_container: 2
2025-04-06 21:07:53,734:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:07:53,734:INFO:create_model() successfully completed......................................
2025-04-06 21:07:53,912:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:53,913:INFO:Creating metrics dataframe
2025-04-06 21:07:53,915:INFO:Initializing Decision Tree Regressor
2025-04-06 21:07:53,915:INFO:Total runtime is 0.833623468875885 minutes
2025-04-06 21:07:53,915:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:53,915:INFO:Initializing create_model()
2025-04-06 21:07:53,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:53,915:INFO:Checking exceptions
2025-04-06 21:07:53,916:INFO:Importing libraries
2025-04-06 21:07:53,916:INFO:Copying training dataset
2025-04-06 21:07:53,928:INFO:Defining folds
2025-04-06 21:07:53,928:INFO:Declaring metric variables
2025-04-06 21:07:53,928:INFO:Importing untrained model
2025-04-06 21:07:53,928:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:07:53,929:INFO:Starting cross validation
2025-04-06 21:07:53,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:56,981:INFO:Calculating mean and std
2025-04-06 21:07:56,981:INFO:Creating metrics dataframe
2025-04-06 21:07:56,983:INFO:Uploading results into container
2025-04-06 21:07:56,983:INFO:Uploading model into container now
2025-04-06 21:07:56,984:INFO:_master_model_container: 12
2025-04-06 21:07:56,984:INFO:_display_container: 2
2025-04-06 21:07:56,984:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:07:56,984:INFO:create_model() successfully completed......................................
2025-04-06 21:07:57,167:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:57,167:INFO:Creating metrics dataframe
2025-04-06 21:07:57,170:INFO:Initializing Random Forest Regressor
2025-04-06 21:07:57,170:INFO:Total runtime is 0.8878786206245423 minutes
2025-04-06 21:07:57,170:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:57,171:INFO:Initializing create_model()
2025-04-06 21:07:57,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:57,171:INFO:Checking exceptions
2025-04-06 21:07:57,171:INFO:Importing libraries
2025-04-06 21:07:57,171:INFO:Copying training dataset
2025-04-06 21:07:57,185:INFO:Defining folds
2025-04-06 21:07:57,185:INFO:Declaring metric variables
2025-04-06 21:07:57,185:INFO:Importing untrained model
2025-04-06 21:07:57,185:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:07:57,186:INFO:Starting cross validation
2025-04-06 21:07:57,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:35,297:INFO:Calculating mean and std
2025-04-06 21:08:35,300:INFO:Creating metrics dataframe
2025-04-06 21:08:35,303:INFO:Uploading results into container
2025-04-06 21:08:35,304:INFO:Uploading model into container now
2025-04-06 21:08:35,305:INFO:_master_model_container: 13
2025-04-06 21:08:35,305:INFO:_display_container: 2
2025-04-06 21:08:35,306:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:08:35,306:INFO:create_model() successfully completed......................................
2025-04-06 21:08:35,584:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:35,584:INFO:Creating metrics dataframe
2025-04-06 21:08:35,588:INFO:Initializing Extra Trees Regressor
2025-04-06 21:08:35,588:INFO:Total runtime is 1.5281803170839945 minutes
2025-04-06 21:08:35,589:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:35,589:INFO:Initializing create_model()
2025-04-06 21:08:35,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:35,589:INFO:Checking exceptions
2025-04-06 21:08:35,589:INFO:Importing libraries
2025-04-06 21:08:35,589:INFO:Copying training dataset
2025-04-06 21:08:35,607:INFO:Defining folds
2025-04-06 21:08:35,607:INFO:Declaring metric variables
2025-04-06 21:08:35,607:INFO:Importing untrained model
2025-04-06 21:08:35,608:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:08:35,608:INFO:Starting cross validation
2025-04-06 21:08:35,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:51,335:INFO:Calculating mean and std
2025-04-06 21:08:51,337:INFO:Creating metrics dataframe
2025-04-06 21:08:51,338:INFO:Uploading results into container
2025-04-06 21:08:51,339:INFO:Uploading model into container now
2025-04-06 21:08:51,339:INFO:_master_model_container: 14
2025-04-06 21:08:51,339:INFO:_display_container: 2
2025-04-06 21:08:51,340:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:08:51,340:INFO:create_model() successfully completed......................................
2025-04-06 21:08:51,602:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:51,602:INFO:Creating metrics dataframe
2025-04-06 21:08:51,604:INFO:Initializing AdaBoost Regressor
2025-04-06 21:08:51,604:INFO:Total runtime is 1.7951062281926473 minutes
2025-04-06 21:08:51,605:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:51,605:INFO:Initializing create_model()
2025-04-06 21:08:51,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:51,605:INFO:Checking exceptions
2025-04-06 21:08:51,605:INFO:Importing libraries
2025-04-06 21:08:51,605:INFO:Copying training dataset
2025-04-06 21:08:51,617:INFO:Defining folds
2025-04-06 21:08:51,617:INFO:Declaring metric variables
2025-04-06 21:08:51,617:INFO:Importing untrained model
2025-04-06 21:08:51,617:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:08:51,618:INFO:Starting cross validation
2025-04-06 21:08:51,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:56,553:INFO:Calculating mean and std
2025-04-06 21:08:56,554:INFO:Creating metrics dataframe
2025-04-06 21:08:56,555:INFO:Uploading results into container
2025-04-06 21:08:56,556:INFO:Uploading model into container now
2025-04-06 21:08:56,556:INFO:_master_model_container: 15
2025-04-06 21:08:56,556:INFO:_display_container: 2
2025-04-06 21:08:56,557:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:08:56,557:INFO:create_model() successfully completed......................................
2025-04-06 21:08:56,740:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:56,741:INFO:Creating metrics dataframe
2025-04-06 21:08:56,743:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:08:56,743:INFO:Total runtime is 1.8807562788327534 minutes
2025-04-06 21:08:56,743:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:56,744:INFO:Initializing create_model()
2025-04-06 21:08:56,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:56,744:INFO:Checking exceptions
2025-04-06 21:08:56,744:INFO:Importing libraries
2025-04-06 21:08:56,744:INFO:Copying training dataset
2025-04-06 21:08:56,755:INFO:Defining folds
2025-04-06 21:08:56,755:INFO:Declaring metric variables
2025-04-06 21:08:56,755:INFO:Importing untrained model
2025-04-06 21:08:56,756:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:08:56,756:INFO:Starting cross validation
2025-04-06 21:08:56,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:09,264:INFO:Calculating mean and std
2025-04-06 21:09:09,265:INFO:Creating metrics dataframe
2025-04-06 21:09:09,266:INFO:Uploading results into container
2025-04-06 21:09:09,267:INFO:Uploading model into container now
2025-04-06 21:09:09,267:INFO:_master_model_container: 16
2025-04-06 21:09:09,267:INFO:_display_container: 2
2025-04-06 21:09:09,267:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:09:09,268:INFO:create_model() successfully completed......................................
2025-04-06 21:09:09,447:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:09,447:INFO:Creating metrics dataframe
2025-04-06 21:09:09,449:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:09:09,449:INFO:Total runtime is 2.092515472571055 minutes
2025-04-06 21:09:09,449:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:09,450:INFO:Initializing create_model()
2025-04-06 21:09:09,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:09,450:INFO:Checking exceptions
2025-04-06 21:09:09,450:INFO:Importing libraries
2025-04-06 21:09:09,450:INFO:Copying training dataset
2025-04-06 21:09:09,462:INFO:Defining folds
2025-04-06 21:09:09,462:INFO:Declaring metric variables
2025-04-06 21:09:09,462:INFO:Importing untrained model
2025-04-06 21:09:09,463:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:09:09,463:INFO:Starting cross validation
2025-04-06 21:09:09,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:13,339:INFO:Calculating mean and std
2025-04-06 21:09:13,341:INFO:Creating metrics dataframe
2025-04-06 21:09:13,343:INFO:Uploading results into container
2025-04-06 21:09:13,343:INFO:Uploading model into container now
2025-04-06 21:09:13,344:INFO:_master_model_container: 17
2025-04-06 21:09:13,344:INFO:_display_container: 2
2025-04-06 21:09:13,344:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:13,344:INFO:create_model() successfully completed......................................
2025-04-06 21:09:13,569:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:13,569:INFO:Creating metrics dataframe
2025-04-06 21:09:13,571:INFO:Initializing CatBoost Regressor
2025-04-06 21:09:13,572:INFO:Total runtime is 2.161234664916992 minutes
2025-04-06 21:09:13,572:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:13,572:INFO:Initializing create_model()
2025-04-06 21:09:13,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:13,572:INFO:Checking exceptions
2025-04-06 21:09:13,572:INFO:Importing libraries
2025-04-06 21:09:13,572:INFO:Copying training dataset
2025-04-06 21:09:13,584:INFO:Defining folds
2025-04-06 21:09:13,584:INFO:Declaring metric variables
2025-04-06 21:09:13,584:INFO:Importing untrained model
2025-04-06 21:09:13,589:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:09:13,589:INFO:Starting cross validation
2025-04-06 21:09:13,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:32,194:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 5873, in fit
    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5017, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5066, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-04-06 21:09:32,194:INFO:Calculating mean and std
2025-04-06 21:09:32,195:INFO:Creating metrics dataframe
2025-04-06 21:09:32,197:INFO:Uploading results into container
2025-04-06 21:09:32,197:INFO:Uploading model into container now
2025-04-06 21:09:32,197:INFO:_master_model_container: 18
2025-04-06 21:09:32,197:INFO:_display_container: 2
2025-04-06 21:09:32,197:INFO:<catboost.core.CatBoostRegressor object at 0x0000029EB1F93190>
2025-04-06 21:09:32,197:INFO:create_model() successfully completed......................................
2025-04-06 21:09:32,386:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:32,387:INFO:Creating metrics dataframe
2025-04-06 21:09:32,389:INFO:Initializing Dummy Regressor
2025-04-06 21:09:32,389:INFO:Total runtime is 2.4748520652453103 minutes
2025-04-06 21:09:32,389:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:32,390:INFO:Initializing create_model()
2025-04-06 21:09:32,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:32,390:INFO:Checking exceptions
2025-04-06 21:09:32,390:INFO:Importing libraries
2025-04-06 21:09:32,390:INFO:Copying training dataset
2025-04-06 21:09:32,402:INFO:Defining folds
2025-04-06 21:09:32,402:INFO:Declaring metric variables
2025-04-06 21:09:32,402:INFO:Importing untrained model
2025-04-06 21:09:32,402:INFO:Dummy Regressor Imported successfully
2025-04-06 21:09:32,403:INFO:Starting cross validation
2025-04-06 21:09:32,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:34,869:INFO:Calculating mean and std
2025-04-06 21:09:34,870:INFO:Creating metrics dataframe
2025-04-06 21:09:34,872:INFO:Uploading results into container
2025-04-06 21:09:34,873:INFO:Uploading model into container now
2025-04-06 21:09:34,873:INFO:_master_model_container: 19
2025-04-06 21:09:34,873:INFO:_display_container: 2
2025-04-06 21:09:34,873:INFO:DummyRegressor()
2025-04-06 21:09:34,873:INFO:create_model() successfully completed......................................
2025-04-06 21:09:35,055:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:35,055:INFO:Creating metrics dataframe
2025-04-06 21:09:35,082:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:09:35,085:INFO:Initializing create_model()
2025-04-06 21:09:35,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:35,085:INFO:Checking exceptions
2025-04-06 21:09:35,086:INFO:Importing libraries
2025-04-06 21:09:35,086:INFO:Copying training dataset
2025-04-06 21:09:35,105:INFO:Defining folds
2025-04-06 21:09:35,105:INFO:Declaring metric variables
2025-04-06 21:09:35,105:INFO:Importing untrained model
2025-04-06 21:09:35,105:INFO:Declaring custom model
2025-04-06 21:09:35,106:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:09:35,108:INFO:Cross validation set to False
2025-04-06 21:09:35,108:INFO:Fitting Model
2025-04-06 21:09:37,367:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:37,367:INFO:create_model() successfully completed......................................
2025-04-06 21:09:37,536:INFO:_master_model_container: 19
2025-04-06 21:09:37,536:INFO:_display_container: 2
2025-04-06 21:09:37,537:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:37,537:INFO:compare_models() successfully completed......................................
2025-04-06 21:14:04,606:INFO:PyCaret ClusteringExperiment
2025-04-06 21:14:04,607:INFO:Logging name: cluster-default-name
2025-04-06 21:14:04,607:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:14:04,607:INFO:version 3.3.2
2025-04-06 21:14:04,607:INFO:Initializing setup()
2025-04-06 21:14:04,607:INFO:self.USI: a478
2025-04-06 21:14:04,607:INFO:self._variable_keys: {'seed', 'exp_id', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'gpu_param', 'logging_param', 'log_plots_param', 'idx', 'X', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:14:04,607:INFO:Checking environment
2025-04-06 21:14:04,607:INFO:python_version: 3.11.4
2025-04-06 21:14:04,607:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:14:04,607:INFO:machine: AMD64
2025-04-06 21:14:04,607:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:14:04,614:INFO:Memory: svmem(total=17127211008, available=2370609152, percent=86.2, used=14756601856, free=2370609152)
2025-04-06 21:14:04,614:INFO:Physical Core: 6
2025-04-06 21:14:04,614:INFO:Logical Core: 12
2025-04-06 21:14:04,614:INFO:Checking libraries
2025-04-06 21:14:04,614:INFO:System:
2025-04-06 21:14:04,614:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:14:04,614:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:14:04,614:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:14:04,614:INFO:PyCaret required dependencies:
2025-04-06 21:14:04,615:INFO:                 pip: 25.0.1
2025-04-06 21:14:04,615:INFO:          setuptools: 65.5.0
2025-04-06 21:14:04,615:INFO:             pycaret: 3.3.2
2025-04-06 21:14:04,615:INFO:             IPython: 8.32.0
2025-04-06 21:14:04,615:INFO:          ipywidgets: 8.1.5
2025-04-06 21:14:04,615:INFO:                tqdm: 4.67.1
2025-04-06 21:14:04,615:INFO:               numpy: 1.26.4
2025-04-06 21:14:04,615:INFO:              pandas: 2.1.4
2025-04-06 21:14:04,615:INFO:              jinja2: 3.1.2
2025-04-06 21:14:04,615:INFO:               scipy: 1.11.4
2025-04-06 21:14:04,615:INFO:              joblib: 1.3.2
2025-04-06 21:14:04,615:INFO:             sklearn: 1.4.2
2025-04-06 21:14:04,615:INFO:                pyod: 2.0.3
2025-04-06 21:14:04,615:INFO:            imblearn: 0.13.0
2025-04-06 21:14:04,615:INFO:   category_encoders: 2.7.0
2025-04-06 21:14:04,615:INFO:            lightgbm: 4.6.0
2025-04-06 21:14:04,615:INFO:               numba: 0.61.0
2025-04-06 21:14:04,615:INFO:            requests: 2.32.3
2025-04-06 21:14:04,615:INFO:          matplotlib: 3.7.5
2025-04-06 21:14:04,616:INFO:          scikitplot: 0.3.7
2025-04-06 21:14:04,616:INFO:         yellowbrick: 1.5
2025-04-06 21:14:04,616:INFO:              plotly: 5.24.1
2025-04-06 21:14:04,616:INFO:    plotly-resampler: Not installed
2025-04-06 21:14:04,616:INFO:             kaleido: 0.2.1
2025-04-06 21:14:04,616:INFO:           schemdraw: 0.15
2025-04-06 21:14:04,616:INFO:         statsmodels: 0.14.4
2025-04-06 21:14:04,616:INFO:              sktime: 0.26.0
2025-04-06 21:14:04,616:INFO:               tbats: 1.1.3
2025-04-06 21:14:04,616:INFO:            pmdarima: 2.0.4
2025-04-06 21:14:04,616:INFO:              psutil: 7.0.0
2025-04-06 21:14:04,616:INFO:          markupsafe: 2.1.3
2025-04-06 21:14:04,616:INFO:             pickle5: Not installed
2025-04-06 21:14:04,616:INFO:         cloudpickle: 3.1.1
2025-04-06 21:14:04,616:INFO:         deprecation: 2.1.0
2025-04-06 21:14:04,616:INFO:              xxhash: 3.5.0
2025-04-06 21:14:04,616:INFO:           wurlitzer: Not installed
2025-04-06 21:14:04,616:INFO:PyCaret optional dependencies:
2025-04-06 21:14:04,616:INFO:                shap: 0.44.1
2025-04-06 21:14:04,617:INFO:           interpret: 0.6.9
2025-04-06 21:14:04,617:INFO:                umap: 0.5.7
2025-04-06 21:14:04,617:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:14:04,617:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:14:04,617:INFO:             autoviz: Not installed
2025-04-06 21:14:04,617:INFO:           fairlearn: 0.7.0
2025-04-06 21:14:04,617:INFO:          deepchecks: Not installed
2025-04-06 21:14:04,617:INFO:             xgboost: Not installed
2025-04-06 21:14:04,617:INFO:            catboost: 1.2.7
2025-04-06 21:14:04,617:INFO:              kmodes: 0.12.2
2025-04-06 21:14:04,617:INFO:             mlxtend: 0.23.4
2025-04-06 21:14:04,617:INFO:       statsforecast: 1.5.0
2025-04-06 21:14:04,617:INFO:        tune_sklearn: Not installed
2025-04-06 21:14:04,617:INFO:                 ray: Not installed
2025-04-06 21:14:04,617:INFO:            hyperopt: 0.2.7
2025-04-06 21:14:04,618:INFO:              optuna: 4.2.1
2025-04-06 21:14:04,618:INFO:               skopt: 0.10.2
2025-04-06 21:14:04,618:INFO:              mlflow: 2.21.0
2025-04-06 21:14:04,618:INFO:              gradio: 5.21.0
2025-04-06 21:14:04,618:INFO:             fastapi: 0.115.11
2025-04-06 21:14:04,618:INFO:             uvicorn: 0.34.0
2025-04-06 21:14:04,618:INFO:              m2cgen: 0.10.0
2025-04-06 21:14:04,618:INFO:           evidently: 0.4.40
2025-04-06 21:14:04,618:INFO:               fugue: 0.8.7
2025-04-06 21:14:04,618:INFO:           streamlit: 1.42.2
2025-04-06 21:14:04,618:INFO:             prophet: Not installed
2025-04-06 21:14:04,618:INFO:None
2025-04-06 21:14:04,618:INFO:Set up data.
2025-04-06 21:14:04,779:INFO:Set up index.
2025-04-06 21:14:04,779:INFO:Assigning column types.
2025-04-06 21:14:04,784:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:14:04,784:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:14:04,785:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,826:INFO:Preparing preprocessing pipeline...
2025-04-06 21:14:04,827:INFO:Set up simple imputation.
2025-04-06 21:14:04,832:INFO:Set up encoding of categorical features.
2025-04-06 21:16:49,896:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:16:49,941:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:16:50,353:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:19:12,240:INFO:PyCaret ClusteringExperiment
2025-04-06 21:19:12,240:INFO:Logging name: cluster-default-name
2025-04-06 21:19:12,240:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:19:12,240:INFO:version 3.3.2
2025-04-06 21:19:12,240:INFO:Initializing setup()
2025-04-06 21:19:12,240:INFO:self.USI: 02e7
2025-04-06 21:19:12,241:INFO:self._variable_keys: {'seed', 'exp_id', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'gpu_param', 'logging_param', 'log_plots_param', 'idx', 'X', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:19:12,241:INFO:Checking environment
2025-04-06 21:19:12,241:INFO:python_version: 3.11.4
2025-04-06 21:19:12,241:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:19:12,241:INFO:machine: AMD64
2025-04-06 21:19:12,241:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:19:12,247:INFO:Memory: svmem(total=17127211008, available=7965089792, percent=53.5, used=9162121216, free=7965089792)
2025-04-06 21:19:12,247:INFO:Physical Core: 6
2025-04-06 21:19:12,247:INFO:Logical Core: 12
2025-04-06 21:19:12,247:INFO:Checking libraries
2025-04-06 21:19:12,247:INFO:System:
2025-04-06 21:19:12,247:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:19:12,247:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:19:12,248:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:19:12,248:INFO:PyCaret required dependencies:
2025-04-06 21:19:12,248:INFO:                 pip: 25.0.1
2025-04-06 21:19:12,248:INFO:          setuptools: 65.5.0
2025-04-06 21:19:12,248:INFO:             pycaret: 3.3.2
2025-04-06 21:19:12,248:INFO:             IPython: 8.32.0
2025-04-06 21:19:12,248:INFO:          ipywidgets: 8.1.5
2025-04-06 21:19:12,248:INFO:                tqdm: 4.67.1
2025-04-06 21:19:12,248:INFO:               numpy: 1.26.4
2025-04-06 21:19:12,248:INFO:              pandas: 2.1.4
2025-04-06 21:19:12,248:INFO:              jinja2: 3.1.2
2025-04-06 21:19:12,248:INFO:               scipy: 1.11.4
2025-04-06 21:19:12,248:INFO:              joblib: 1.3.2
2025-04-06 21:19:12,248:INFO:             sklearn: 1.4.2
2025-04-06 21:19:12,248:INFO:                pyod: 2.0.3
2025-04-06 21:19:12,248:INFO:            imblearn: 0.13.0
2025-04-06 21:19:12,248:INFO:   category_encoders: 2.7.0
2025-04-06 21:19:12,248:INFO:            lightgbm: 4.6.0
2025-04-06 21:19:12,249:INFO:               numba: 0.61.0
2025-04-06 21:19:12,249:INFO:            requests: 2.32.3
2025-04-06 21:19:12,249:INFO:          matplotlib: 3.7.5
2025-04-06 21:19:12,249:INFO:          scikitplot: 0.3.7
2025-04-06 21:19:12,249:INFO:         yellowbrick: 1.5
2025-04-06 21:19:12,249:INFO:              plotly: 5.24.1
2025-04-06 21:19:12,249:INFO:    plotly-resampler: Not installed
2025-04-06 21:19:12,249:INFO:             kaleido: 0.2.1
2025-04-06 21:19:12,249:INFO:           schemdraw: 0.15
2025-04-06 21:19:12,249:INFO:         statsmodels: 0.14.4
2025-04-06 21:19:12,249:INFO:              sktime: 0.26.0
2025-04-06 21:19:12,249:INFO:               tbats: 1.1.3
2025-04-06 21:19:12,249:INFO:            pmdarima: 2.0.4
2025-04-06 21:19:12,249:INFO:              psutil: 7.0.0
2025-04-06 21:19:12,249:INFO:          markupsafe: 2.1.3
2025-04-06 21:19:12,249:INFO:             pickle5: Not installed
2025-04-06 21:19:12,249:INFO:         cloudpickle: 3.1.1
2025-04-06 21:19:12,249:INFO:         deprecation: 2.1.0
2025-04-06 21:19:12,249:INFO:              xxhash: 3.5.0
2025-04-06 21:19:12,249:INFO:           wurlitzer: Not installed
2025-04-06 21:19:12,249:INFO:PyCaret optional dependencies:
2025-04-06 21:19:12,250:INFO:                shap: 0.44.1
2025-04-06 21:19:12,250:INFO:           interpret: 0.6.9
2025-04-06 21:19:12,250:INFO:                umap: 0.5.7
2025-04-06 21:19:12,250:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:19:12,250:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:19:12,250:INFO:             autoviz: Not installed
2025-04-06 21:19:12,250:INFO:           fairlearn: 0.7.0
2025-04-06 21:19:12,250:INFO:          deepchecks: Not installed
2025-04-06 21:19:12,250:INFO:             xgboost: Not installed
2025-04-06 21:19:12,250:INFO:            catboost: 1.2.7
2025-04-06 21:19:12,250:INFO:              kmodes: 0.12.2
2025-04-06 21:19:12,250:INFO:             mlxtend: 0.23.4
2025-04-06 21:19:12,250:INFO:       statsforecast: 1.5.0
2025-04-06 21:19:12,250:INFO:        tune_sklearn: Not installed
2025-04-06 21:19:12,250:INFO:                 ray: Not installed
2025-04-06 21:19:12,250:INFO:            hyperopt: 0.2.7
2025-04-06 21:19:12,250:INFO:              optuna: 4.2.1
2025-04-06 21:19:12,250:INFO:               skopt: 0.10.2
2025-04-06 21:19:12,250:INFO:              mlflow: 2.21.0
2025-04-06 21:19:12,251:INFO:              gradio: 5.21.0
2025-04-06 21:19:12,251:INFO:             fastapi: 0.115.11
2025-04-06 21:19:12,251:INFO:             uvicorn: 0.34.0
2025-04-06 21:19:12,251:INFO:              m2cgen: 0.10.0
2025-04-06 21:19:12,251:INFO:           evidently: 0.4.40
2025-04-06 21:19:12,251:INFO:               fugue: 0.8.7
2025-04-06 21:19:12,251:INFO:           streamlit: 1.42.2
2025-04-06 21:19:12,251:INFO:             prophet: Not installed
2025-04-06 21:19:12,251:INFO:None
2025-04-06 21:19:12,251:INFO:Set up data.
2025-04-06 21:19:12,263:INFO:Set up index.
2025-04-06 21:19:12,263:INFO:Assigning column types.
2025-04-06 21:19:12,266:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:19:12,266:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:19:12,266:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,266:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,267:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,268:INFO:Preparing preprocessing pipeline...
2025-04-06 21:19:12,268:INFO:Set up simple imputation.
2025-04-06 21:19:12,272:INFO:Set up encoding of categorical features.
2025-04-06 21:19:16,056:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2025-04-06 21:19:16,057:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:19:16,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'likes',
                                             'dislikes', 'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thu...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=OneHotEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-06 21:19:16,064:INFO:Creating final display dataframe.
2025-04-06 21:19:19,590:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-06 21:19:20,663:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:19:20,674:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape            (1600, 16)
2     Transformed data shape          (1600, 6424)
3           Numeric features                     5
4       Categorical features                     8
5   Rows with missing values                  3.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  cluster-default-name
16                       USI                  02e7
2025-04-06 21:19:20,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:20,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:20,684:INFO:setup() successfully completed in 8.45s...............
2025-04-06 21:19:20,685:INFO:Initializing create_model()
2025-04-06 21:19:20,685:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002A1F4DAAAD0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-06 21:19:20,685:INFO:Checking exceptions
2025-04-06 21:19:21,762:INFO:Importing untrained model
2025-04-06 21:19:21,762:INFO:K-Means Clustering Imported successfully
2025-04-06 21:19:21,910:INFO:Fitting Model
2025-04-06 21:19:26,577:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:19:26,577:INFO:create_models() successfully completed......................................
2025-04-06 21:19:26,578:INFO:Uploading results into container
2025-04-06 21:19:26,579:INFO:Uploading model into container now
2025-04-06 21:19:26,586:INFO:_master_model_container: 1
2025-04-06 21:19:26,586:INFO:_display_container: 2
2025-04-06 21:19:26,586:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:19:26,586:INFO:create_model() successfully completed......................................
2025-04-06 21:22:04,081:INFO:PyCaret RegressionExperiment
2025-04-06 21:22:04,081:INFO:Logging name: reg-default-name
2025-04-06 21:22:04,081:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:22:04,081:INFO:version 3.3.2
2025-04-06 21:22:04,081:INFO:Initializing setup()
2025-04-06 21:22:04,081:INFO:self.USI: 3728
2025-04-06 21:22:04,081:INFO:self._variable_keys: {'seed', 'exp_id', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'data', 'USI', 'transform_target_param', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:22:04,081:INFO:Checking environment
2025-04-06 21:22:04,081:INFO:python_version: 3.11.4
2025-04-06 21:22:04,081:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:22:04,081:INFO:machine: AMD64
2025-04-06 21:22:04,081:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:22:04,092:INFO:Memory: svmem(total=17127211008, available=7550414848, percent=55.9, used=9576796160, free=7550414848)
2025-04-06 21:22:04,092:INFO:Physical Core: 6
2025-04-06 21:22:04,093:INFO:Logical Core: 12
2025-04-06 21:22:04,093:INFO:Checking libraries
2025-04-06 21:22:04,093:INFO:System:
2025-04-06 21:22:04,093:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:22:04,093:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:22:04,093:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:22:04,093:INFO:PyCaret required dependencies:
2025-04-06 21:22:04,093:INFO:                 pip: 25.0.1
2025-04-06 21:22:04,094:INFO:          setuptools: 65.5.0
2025-04-06 21:22:04,094:INFO:             pycaret: 3.3.2
2025-04-06 21:22:04,094:INFO:             IPython: 8.32.0
2025-04-06 21:22:04,094:INFO:          ipywidgets: 8.1.5
2025-04-06 21:22:04,094:INFO:                tqdm: 4.67.1
2025-04-06 21:22:04,094:INFO:               numpy: 1.26.4
2025-04-06 21:22:04,094:INFO:              pandas: 2.1.4
2025-04-06 21:22:04,094:INFO:              jinja2: 3.1.2
2025-04-06 21:22:04,094:INFO:               scipy: 1.11.4
2025-04-06 21:22:04,094:INFO:              joblib: 1.3.2
2025-04-06 21:22:04,094:INFO:             sklearn: 1.4.2
2025-04-06 21:22:04,094:INFO:                pyod: 2.0.3
2025-04-06 21:22:04,094:INFO:            imblearn: 0.13.0
2025-04-06 21:22:04,094:INFO:   category_encoders: 2.7.0
2025-04-06 21:22:04,094:INFO:            lightgbm: 4.6.0
2025-04-06 21:22:04,094:INFO:               numba: 0.61.0
2025-04-06 21:22:04,094:INFO:            requests: 2.32.3
2025-04-06 21:22:04,094:INFO:          matplotlib: 3.7.5
2025-04-06 21:22:04,095:INFO:          scikitplot: 0.3.7
2025-04-06 21:22:04,095:INFO:         yellowbrick: 1.5
2025-04-06 21:22:04,095:INFO:              plotly: 5.24.1
2025-04-06 21:22:04,095:INFO:    plotly-resampler: Not installed
2025-04-06 21:22:04,095:INFO:             kaleido: 0.2.1
2025-04-06 21:22:04,095:INFO:           schemdraw: 0.15
2025-04-06 21:22:04,095:INFO:         statsmodels: 0.14.4
2025-04-06 21:22:04,095:INFO:              sktime: 0.26.0
2025-04-06 21:22:04,095:INFO:               tbats: 1.1.3
2025-04-06 21:22:04,095:INFO:            pmdarima: 2.0.4
2025-04-06 21:22:04,095:INFO:              psutil: 7.0.0
2025-04-06 21:22:04,095:INFO:          markupsafe: 2.1.3
2025-04-06 21:22:04,095:INFO:             pickle5: Not installed
2025-04-06 21:22:04,095:INFO:         cloudpickle: 3.1.1
2025-04-06 21:22:04,095:INFO:         deprecation: 2.1.0
2025-04-06 21:22:04,095:INFO:              xxhash: 3.5.0
2025-04-06 21:22:04,095:INFO:           wurlitzer: Not installed
2025-04-06 21:22:04,095:INFO:PyCaret optional dependencies:
2025-04-06 21:22:04,095:INFO:                shap: 0.44.1
2025-04-06 21:22:04,096:INFO:           interpret: 0.6.9
2025-04-06 21:22:04,096:INFO:                umap: 0.5.7
2025-04-06 21:22:04,096:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:22:04,096:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:22:04,096:INFO:             autoviz: Not installed
2025-04-06 21:22:04,096:INFO:           fairlearn: 0.7.0
2025-04-06 21:22:04,096:INFO:          deepchecks: Not installed
2025-04-06 21:22:04,096:INFO:             xgboost: Not installed
2025-04-06 21:22:04,096:INFO:            catboost: 1.2.7
2025-04-06 21:22:04,096:INFO:              kmodes: 0.12.2
2025-04-06 21:22:04,096:INFO:             mlxtend: 0.23.4
2025-04-06 21:22:04,096:INFO:       statsforecast: 1.5.0
2025-04-06 21:22:04,096:INFO:        tune_sklearn: Not installed
2025-04-06 21:22:04,096:INFO:                 ray: Not installed
2025-04-06 21:22:04,096:INFO:            hyperopt: 0.2.7
2025-04-06 21:22:04,096:INFO:              optuna: 4.2.1
2025-04-06 21:22:04,096:INFO:               skopt: 0.10.2
2025-04-06 21:22:04,096:INFO:              mlflow: 2.21.0
2025-04-06 21:22:04,097:INFO:              gradio: 5.21.0
2025-04-06 21:22:04,097:INFO:             fastapi: 0.115.11
2025-04-06 21:22:04,097:INFO:             uvicorn: 0.34.0
2025-04-06 21:22:04,097:INFO:              m2cgen: 0.10.0
2025-04-06 21:22:04,097:INFO:           evidently: 0.4.40
2025-04-06 21:22:04,097:INFO:               fugue: 0.8.7
2025-04-06 21:22:04,097:INFO:           streamlit: 1.42.2
2025-04-06 21:22:04,097:INFO:             prophet: Not installed
2025-04-06 21:22:04,097:INFO:None
2025-04-06 21:22:04,097:INFO:Set up data.
2025-04-06 21:22:04,111:INFO:Set up folding strategy.
2025-04-06 21:22:04,111:INFO:Set up train/test split.
2025-04-06 21:22:04,127:INFO:Set up index.
2025-04-06 21:22:04,127:INFO:Assigning column types.
2025-04-06 21:22:04,132:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:22:04,132:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,283:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,291:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,428:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,429:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,430:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:22:04,437:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,578:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,728:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,728:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:22:04,741:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,876:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,889:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,026:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,027:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:22:05,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,177:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,324:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:22:05,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,469:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,626:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,627:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:22:05,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,772:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,919:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,921:INFO:Preparing preprocessing pipeline...
2025-04-06 21:22:05,921:INFO:Set up simple imputation.
2025-04-06 21:22:05,925:INFO:Set up encoding of categorical features.
2025-04-06 21:22:06,152:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:22:06,162:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:22:06,162:INFO:Creating final display dataframe.
2025-04-06 21:22:07,011:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1600, 16)
4        Transformed data shape        (1600, 24)
5   Transformed train set shape        (1120, 24)
6    Transformed test set shape         (480, 24)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              3.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3728
2025-04-06 21:22:07,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:07,203:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:07,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:07,374:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:07,375:INFO:setup() successfully completed in 3.3s...............
2025-04-06 21:22:07,375:INFO:Initializing compare_models()
2025-04-06 21:22:07,375:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:22:07,375:INFO:Checking exceptions
2025-04-06 21:22:07,378:INFO:Preparing display monitor
2025-04-06 21:22:07,380:INFO:Initializing Linear Regression
2025-04-06 21:22:07,380:INFO:Total runtime is 0.0 minutes
2025-04-06 21:22:07,380:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:07,380:INFO:Initializing create_model()
2025-04-06 21:22:07,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:07,380:INFO:Checking exceptions
2025-04-06 21:22:07,380:INFO:Importing libraries
2025-04-06 21:22:07,381:INFO:Copying training dataset
2025-04-06 21:22:07,386:INFO:Defining folds
2025-04-06 21:22:07,386:INFO:Declaring metric variables
2025-04-06 21:22:07,386:INFO:Importing untrained model
2025-04-06 21:22:07,386:INFO:Linear Regression Imported successfully
2025-04-06 21:22:07,386:INFO:Starting cross validation
2025-04-06 21:22:07,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:17,903:INFO:Calculating mean and std
2025-04-06 21:22:17,905:INFO:Creating metrics dataframe
2025-04-06 21:22:17,908:INFO:Uploading results into container
2025-04-06 21:22:17,909:INFO:Uploading model into container now
2025-04-06 21:22:17,911:INFO:_master_model_container: 1
2025-04-06 21:22:17,911:INFO:_display_container: 2
2025-04-06 21:22:17,912:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:22:17,912:INFO:create_model() successfully completed......................................
2025-04-06 21:22:18,194:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:18,195:INFO:Creating metrics dataframe
2025-04-06 21:22:18,197:INFO:Initializing Lasso Regression
2025-04-06 21:22:18,197:INFO:Total runtime is 0.18028005758921306 minutes
2025-04-06 21:22:18,197:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:18,197:INFO:Initializing create_model()
2025-04-06 21:22:18,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:18,197:INFO:Checking exceptions
2025-04-06 21:22:18,197:INFO:Importing libraries
2025-04-06 21:22:18,197:INFO:Copying training dataset
2025-04-06 21:22:18,202:INFO:Defining folds
2025-04-06 21:22:18,202:INFO:Declaring metric variables
2025-04-06 21:22:18,202:INFO:Importing untrained model
2025-04-06 21:22:18,202:INFO:Lasso Regression Imported successfully
2025-04-06 21:22:18,203:INFO:Starting cross validation
2025-04-06 21:22:18,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:18,460:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+14, tolerance: 6.350e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+14, tolerance: 6.616e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,508:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+14, tolerance: 7.104e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,525:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+14, tolerance: 6.987e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,561:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+14, tolerance: 7.562e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,568:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+14, tolerance: 7.503e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,602:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+14, tolerance: 6.975e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,608:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+14, tolerance: 7.344e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,659:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+14, tolerance: 7.010e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,685:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+14, tolerance: 5.322e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,724:INFO:Calculating mean and std
2025-04-06 21:22:22,725:INFO:Creating metrics dataframe
2025-04-06 21:22:22,727:INFO:Uploading results into container
2025-04-06 21:22:22,727:INFO:Uploading model into container now
2025-04-06 21:22:22,728:INFO:_master_model_container: 2
2025-04-06 21:22:22,728:INFO:_display_container: 2
2025-04-06 21:22:22,728:INFO:Lasso(random_state=123)
2025-04-06 21:22:22,728:INFO:create_model() successfully completed......................................
2025-04-06 21:22:22,927:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:22,927:INFO:Creating metrics dataframe
2025-04-06 21:22:22,929:INFO:Initializing Ridge Regression
2025-04-06 21:22:22,929:INFO:Total runtime is 0.2591538111368815 minutes
2025-04-06 21:22:22,930:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:22,930:INFO:Initializing create_model()
2025-04-06 21:22:22,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:22,930:INFO:Checking exceptions
2025-04-06 21:22:22,930:INFO:Importing libraries
2025-04-06 21:22:22,930:INFO:Copying training dataset
2025-04-06 21:22:22,935:INFO:Defining folds
2025-04-06 21:22:22,936:INFO:Declaring metric variables
2025-04-06 21:22:22,936:INFO:Importing untrained model
2025-04-06 21:22:22,936:INFO:Ridge Regression Imported successfully
2025-04-06 21:22:22,936:INFO:Starting cross validation
2025-04-06 21:22:22,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:23,325:INFO:Calculating mean and std
2025-04-06 21:22:23,326:INFO:Creating metrics dataframe
2025-04-06 21:22:23,328:INFO:Uploading results into container
2025-04-06 21:22:23,328:INFO:Uploading model into container now
2025-04-06 21:22:23,328:INFO:_master_model_container: 3
2025-04-06 21:22:23,328:INFO:_display_container: 2
2025-04-06 21:22:23,328:INFO:Ridge(random_state=123)
2025-04-06 21:22:23,328:INFO:create_model() successfully completed......................................
2025-04-06 21:22:23,521:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:23,522:INFO:Creating metrics dataframe
2025-04-06 21:22:23,524:INFO:Initializing Elastic Net
2025-04-06 21:22:23,524:INFO:Total runtime is 0.26906989018122357 minutes
2025-04-06 21:22:23,524:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:23,524:INFO:Initializing create_model()
2025-04-06 21:22:23,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:23,524:INFO:Checking exceptions
2025-04-06 21:22:23,524:INFO:Importing libraries
2025-04-06 21:22:23,524:INFO:Copying training dataset
2025-04-06 21:22:23,529:INFO:Defining folds
2025-04-06 21:22:23,530:INFO:Declaring metric variables
2025-04-06 21:22:23,530:INFO:Importing untrained model
2025-04-06 21:22:23,530:INFO:Elastic Net Imported successfully
2025-04-06 21:22:23,530:INFO:Starting cross validation
2025-04-06 21:22:23,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:23,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+14, tolerance: 5.322e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+14, tolerance: 6.350e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+14, tolerance: 6.616e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,800:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+14, tolerance: 7.010e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,814:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+14, tolerance: 7.104e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,844:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+14, tolerance: 6.987e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,865:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+14, tolerance: 7.562e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,885:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+14, tolerance: 7.503e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,893:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+14, tolerance: 6.975e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+14, tolerance: 7.344e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,955:INFO:Calculating mean and std
2025-04-06 21:22:23,956:INFO:Creating metrics dataframe
2025-04-06 21:22:23,958:INFO:Uploading results into container
2025-04-06 21:22:23,958:INFO:Uploading model into container now
2025-04-06 21:22:23,959:INFO:_master_model_container: 4
2025-04-06 21:22:23,959:INFO:_display_container: 2
2025-04-06 21:22:23,959:INFO:ElasticNet(random_state=123)
2025-04-06 21:22:23,959:INFO:create_model() successfully completed......................................
2025-04-06 21:22:24,147:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:24,147:INFO:Creating metrics dataframe
2025-04-06 21:22:24,151:INFO:Initializing Least Angle Regression
2025-04-06 21:22:24,151:INFO:Total runtime is 0.2795220613479614 minutes
2025-04-06 21:22:24,152:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:24,152:INFO:Initializing create_model()
2025-04-06 21:22:24,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:24,152:INFO:Checking exceptions
2025-04-06 21:22:24,152:INFO:Importing libraries
2025-04-06 21:22:24,152:INFO:Copying training dataset
2025-04-06 21:22:24,157:INFO:Defining folds
2025-04-06 21:22:24,157:INFO:Declaring metric variables
2025-04-06 21:22:24,158:INFO:Importing untrained model
2025-04-06 21:22:24,158:INFO:Least Angle Regression Imported successfully
2025-04-06 21:22:24,158:INFO:Starting cross validation
2025-04-06 21:22:24,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:24,387:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.209e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,388:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.954e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.518e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.915e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,390:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.412e+04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,392:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.345e+04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.031e+03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.516e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.529e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,401:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.063e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,402:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.138e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.024e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.512e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.274e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,406:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.748e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,406:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.923e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,408:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.829e+05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,408:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.328e+04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,409:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.336e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,409:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.093e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.383e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.191e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.373e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.396e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.381e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,423:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.451e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,450:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.167e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,450:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.078e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,451:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.191e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,451:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.904e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,453:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.981e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,454:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.811e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,454:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.213e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,456:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.387e+07, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,456:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.439e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.217e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,469:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.866e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.441e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.023e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.996e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.192e+05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.800e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,473:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.419e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.438e+04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.480e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.367e+11, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.952e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.338e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.169e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,476:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.474e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,476:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.439e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,478:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.536e+03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,479:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.357e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,512:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.804e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.168e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.395e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.403e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,515:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.938e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,516:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.290e+03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,516:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.682e+06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,517:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.054e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,536:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.945e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,536:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.248e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.254e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.761e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.338e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.316e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.209e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.687e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.179e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.281e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.091e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.990e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.671e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.006e+05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.207e+04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.552e+04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,541:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.919e+04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,541:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.775e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,591:INFO:Calculating mean and std
2025-04-06 21:22:24,592:INFO:Creating metrics dataframe
2025-04-06 21:22:24,594:INFO:Uploading results into container
2025-04-06 21:22:24,594:INFO:Uploading model into container now
2025-04-06 21:22:24,594:INFO:_master_model_container: 5
2025-04-06 21:22:24,595:INFO:_display_container: 2
2025-04-06 21:22:24,595:INFO:Lars(random_state=123)
2025-04-06 21:22:24,595:INFO:create_model() successfully completed......................................
2025-04-06 21:22:24,778:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:24,778:INFO:Creating metrics dataframe
2025-04-06 21:22:24,780:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:22:24,780:INFO:Total runtime is 0.2900100549062093 minutes
2025-04-06 21:22:24,780:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:24,781:INFO:Initializing create_model()
2025-04-06 21:22:24,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:24,781:INFO:Checking exceptions
2025-04-06 21:22:24,781:INFO:Importing libraries
2025-04-06 21:22:24,781:INFO:Copying training dataset
2025-04-06 21:22:24,787:INFO:Defining folds
2025-04-06 21:22:24,787:INFO:Declaring metric variables
2025-04-06 21:22:24,787:INFO:Importing untrained model
2025-04-06 21:22:24,788:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:22:24,788:INFO:Starting cross validation
2025-04-06 21:22:24,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:25,056:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.454e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,057:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.734e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,058:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.050e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,059:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.866e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,060:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=4.259e+03, previous alpha=8.300e+02, with an active set of 19 regressors.
  warnings.warn(

2025-04-06 21:22:25,091:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.480e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,092:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.398e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,092:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.396e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,093:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.699e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,093:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.792e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.521e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.757e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.224e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,095:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.951e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,096:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.243e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,096:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.471e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.240e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.189e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.261e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,099:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=2.272e+04, previous alpha=9.279e+01, with an active set of 20 regressors.
  warnings.warn(

2025-04-06 21:22:25,127:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.096e+05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,127:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.492e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,128:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.906e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,130:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=7.119e+03, previous alpha=7.107e+02, with an active set of 18 regressors.
  warnings.warn(

2025-04-06 21:22:25,157:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.074e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,158:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.716e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,159:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.042e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,159:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.415e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,160:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.717e+08, previous alpha=1.023e+04, with an active set of 13 regressors.
  warnings.warn(

2025-04-06 21:22:25,165:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.294e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,166:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.032e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.018e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.436e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.976e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,168:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.069e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,169:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.908e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,169:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.907e+03, previous alpha=1.060e+03, with an active set of 17 regressors.
  warnings.warn(

2025-04-06 21:22:25,215:INFO:Calculating mean and std
2025-04-06 21:22:25,216:INFO:Creating metrics dataframe
2025-04-06 21:22:25,218:INFO:Uploading results into container
2025-04-06 21:22:25,218:INFO:Uploading model into container now
2025-04-06 21:22:25,219:INFO:_master_model_container: 6
2025-04-06 21:22:25,219:INFO:_display_container: 2
2025-04-06 21:22:25,219:INFO:LassoLars(random_state=123)
2025-04-06 21:22:25,219:INFO:create_model() successfully completed......................................
2025-04-06 21:22:25,406:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:25,406:INFO:Creating metrics dataframe
2025-04-06 21:22:25,408:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:22:25,408:INFO:Total runtime is 0.30046358505884807 minutes
2025-04-06 21:22:25,408:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:25,408:INFO:Initializing create_model()
2025-04-06 21:22:25,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:25,409:INFO:Checking exceptions
2025-04-06 21:22:25,409:INFO:Importing libraries
2025-04-06 21:22:25,409:INFO:Copying training dataset
2025-04-06 21:22:25,413:INFO:Defining folds
2025-04-06 21:22:25,413:INFO:Declaring metric variables
2025-04-06 21:22:25,413:INFO:Importing untrained model
2025-04-06 21:22:25,414:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:22:25,414:INFO:Starting cross validation
2025-04-06 21:22:25,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:25,817:INFO:Calculating mean and std
2025-04-06 21:22:25,818:INFO:Creating metrics dataframe
2025-04-06 21:22:25,820:INFO:Uploading results into container
2025-04-06 21:22:25,821:INFO:Uploading model into container now
2025-04-06 21:22:25,821:INFO:_master_model_container: 7
2025-04-06 21:22:25,821:INFO:_display_container: 2
2025-04-06 21:22:25,821:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:22:25,821:INFO:create_model() successfully completed......................................
2025-04-06 21:22:26,011:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:26,011:INFO:Creating metrics dataframe
2025-04-06 21:22:26,013:INFO:Initializing Bayesian Ridge
2025-04-06 21:22:26,013:INFO:Total runtime is 0.31055250962575276 minutes
2025-04-06 21:22:26,013:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:26,014:INFO:Initializing create_model()
2025-04-06 21:22:26,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:26,014:INFO:Checking exceptions
2025-04-06 21:22:26,014:INFO:Importing libraries
2025-04-06 21:22:26,014:INFO:Copying training dataset
2025-04-06 21:22:26,018:INFO:Defining folds
2025-04-06 21:22:26,018:INFO:Declaring metric variables
2025-04-06 21:22:26,019:INFO:Importing untrained model
2025-04-06 21:22:26,019:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:22:26,019:INFO:Starting cross validation
2025-04-06 21:22:26,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:26,413:INFO:Calculating mean and std
2025-04-06 21:22:26,414:INFO:Creating metrics dataframe
2025-04-06 21:22:26,415:INFO:Uploading results into container
2025-04-06 21:22:26,416:INFO:Uploading model into container now
2025-04-06 21:22:26,416:INFO:_master_model_container: 8
2025-04-06 21:22:26,416:INFO:_display_container: 2
2025-04-06 21:22:26,416:INFO:BayesianRidge()
2025-04-06 21:22:26,416:INFO:create_model() successfully completed......................................
2025-04-06 21:22:26,601:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:26,601:INFO:Creating metrics dataframe
2025-04-06 21:22:26,603:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:22:26,604:INFO:Total runtime is 0.3203834096590678 minutes
2025-04-06 21:22:26,604:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:26,604:INFO:Initializing create_model()
2025-04-06 21:22:26,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:26,604:INFO:Checking exceptions
2025-04-06 21:22:26,604:INFO:Importing libraries
2025-04-06 21:22:26,604:INFO:Copying training dataset
2025-04-06 21:22:26,609:INFO:Defining folds
2025-04-06 21:22:26,609:INFO:Declaring metric variables
2025-04-06 21:22:26,609:INFO:Importing untrained model
2025-04-06 21:22:26,609:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:22:26,609:INFO:Starting cross validation
2025-04-06 21:22:26,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:27,016:INFO:Calculating mean and std
2025-04-06 21:22:27,017:INFO:Creating metrics dataframe
2025-04-06 21:22:27,018:INFO:Uploading results into container
2025-04-06 21:22:27,019:INFO:Uploading model into container now
2025-04-06 21:22:27,019:INFO:_master_model_container: 9
2025-04-06 21:22:27,019:INFO:_display_container: 2
2025-04-06 21:22:27,019:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:22:27,019:INFO:create_model() successfully completed......................................
2025-04-06 21:22:27,211:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:27,212:INFO:Creating metrics dataframe
2025-04-06 21:22:27,214:INFO:Initializing Huber Regressor
2025-04-06 21:22:27,214:INFO:Total runtime is 0.33057785828908287 minutes
2025-04-06 21:22:27,214:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:27,214:INFO:Initializing create_model()
2025-04-06 21:22:27,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:27,215:INFO:Checking exceptions
2025-04-06 21:22:27,215:INFO:Importing libraries
2025-04-06 21:22:27,215:INFO:Copying training dataset
2025-04-06 21:22:27,221:INFO:Defining folds
2025-04-06 21:22:27,221:INFO:Declaring metric variables
2025-04-06 21:22:27,221:INFO:Importing untrained model
2025-04-06 21:22:27,221:INFO:Huber Regressor Imported successfully
2025-04-06 21:22:27,221:INFO:Starting cross validation
2025-04-06 21:22:27,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:27,507:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:22:27,544:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:22:27,678:INFO:Calculating mean and std
2025-04-06 21:22:27,679:INFO:Creating metrics dataframe
2025-04-06 21:22:27,680:INFO:Uploading results into container
2025-04-06 21:22:27,681:INFO:Uploading model into container now
2025-04-06 21:22:27,682:INFO:_master_model_container: 10
2025-04-06 21:22:27,682:INFO:_display_container: 2
2025-04-06 21:22:27,682:INFO:HuberRegressor()
2025-04-06 21:22:27,682:INFO:create_model() successfully completed......................................
2025-04-06 21:22:27,868:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:27,868:INFO:Creating metrics dataframe
2025-04-06 21:22:27,870:INFO:Initializing K Neighbors Regressor
2025-04-06 21:22:27,871:INFO:Total runtime is 0.3415256222089132 minutes
2025-04-06 21:22:27,871:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:27,871:INFO:Initializing create_model()
2025-04-06 21:22:27,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:27,871:INFO:Checking exceptions
2025-04-06 21:22:27,871:INFO:Importing libraries
2025-04-06 21:22:27,871:INFO:Copying training dataset
2025-04-06 21:22:27,877:INFO:Defining folds
2025-04-06 21:22:27,877:INFO:Declaring metric variables
2025-04-06 21:22:27,878:INFO:Importing untrained model
2025-04-06 21:22:27,878:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:22:27,878:INFO:Starting cross validation
2025-04-06 21:22:27,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:28,286:INFO:Calculating mean and std
2025-04-06 21:22:28,287:INFO:Creating metrics dataframe
2025-04-06 21:22:28,288:INFO:Uploading results into container
2025-04-06 21:22:28,289:INFO:Uploading model into container now
2025-04-06 21:22:28,289:INFO:_master_model_container: 11
2025-04-06 21:22:28,289:INFO:_display_container: 2
2025-04-06 21:22:28,289:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:22:28,289:INFO:create_model() successfully completed......................................
2025-04-06 21:22:28,476:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:28,476:INFO:Creating metrics dataframe
2025-04-06 21:22:28,478:INFO:Initializing Decision Tree Regressor
2025-04-06 21:22:28,478:INFO:Total runtime is 0.3516429424285889 minutes
2025-04-06 21:22:28,478:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:28,479:INFO:Initializing create_model()
2025-04-06 21:22:28,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:28,479:INFO:Checking exceptions
2025-04-06 21:22:28,479:INFO:Importing libraries
2025-04-06 21:22:28,479:INFO:Copying training dataset
2025-04-06 21:22:28,484:INFO:Defining folds
2025-04-06 21:22:28,484:INFO:Declaring metric variables
2025-04-06 21:22:28,485:INFO:Importing untrained model
2025-04-06 21:22:28,485:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:22:28,485:INFO:Starting cross validation
2025-04-06 21:22:28,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:28,883:INFO:Calculating mean and std
2025-04-06 21:22:28,884:INFO:Creating metrics dataframe
2025-04-06 21:22:28,885:INFO:Uploading results into container
2025-04-06 21:22:28,886:INFO:Uploading model into container now
2025-04-06 21:22:28,886:INFO:_master_model_container: 12
2025-04-06 21:22:28,886:INFO:_display_container: 2
2025-04-06 21:22:28,886:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:22:28,886:INFO:create_model() successfully completed......................................
2025-04-06 21:22:29,058:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:29,059:INFO:Creating metrics dataframe
2025-04-06 21:22:29,061:INFO:Initializing Random Forest Regressor
2025-04-06 21:22:29,061:INFO:Total runtime is 0.3613513032595317 minutes
2025-04-06 21:22:29,061:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:29,061:INFO:Initializing create_model()
2025-04-06 21:22:29,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:29,061:INFO:Checking exceptions
2025-04-06 21:22:29,061:INFO:Importing libraries
2025-04-06 21:22:29,062:INFO:Copying training dataset
2025-04-06 21:22:29,066:INFO:Defining folds
2025-04-06 21:22:29,066:INFO:Declaring metric variables
2025-04-06 21:22:29,066:INFO:Importing untrained model
2025-04-06 21:22:29,067:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:22:29,067:INFO:Starting cross validation
2025-04-06 21:22:29,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:30,841:INFO:Calculating mean and std
2025-04-06 21:22:30,842:INFO:Creating metrics dataframe
2025-04-06 21:22:30,843:INFO:Uploading results into container
2025-04-06 21:22:30,844:INFO:Uploading model into container now
2025-04-06 21:22:30,844:INFO:_master_model_container: 13
2025-04-06 21:22:30,844:INFO:_display_container: 2
2025-04-06 21:22:30,844:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:30,845:INFO:create_model() successfully completed......................................
2025-04-06 21:22:31,033:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:31,033:INFO:Creating metrics dataframe
2025-04-06 21:22:31,035:INFO:Initializing Extra Trees Regressor
2025-04-06 21:22:31,036:INFO:Total runtime is 0.3942694902420044 minutes
2025-04-06 21:22:31,036:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:31,036:INFO:Initializing create_model()
2025-04-06 21:22:31,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:31,036:INFO:Checking exceptions
2025-04-06 21:22:31,036:INFO:Importing libraries
2025-04-06 21:22:31,036:INFO:Copying training dataset
2025-04-06 21:22:31,041:INFO:Defining folds
2025-04-06 21:22:31,041:INFO:Declaring metric variables
2025-04-06 21:22:31,041:INFO:Importing untrained model
2025-04-06 21:22:31,042:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:22:31,042:INFO:Starting cross validation
2025-04-06 21:22:31,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:32,163:INFO:Calculating mean and std
2025-04-06 21:22:32,164:INFO:Creating metrics dataframe
2025-04-06 21:22:32,165:INFO:Uploading results into container
2025-04-06 21:22:32,166:INFO:Uploading model into container now
2025-04-06 21:22:32,166:INFO:_master_model_container: 14
2025-04-06 21:22:32,166:INFO:_display_container: 2
2025-04-06 21:22:32,166:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:32,166:INFO:create_model() successfully completed......................................
2025-04-06 21:22:32,345:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:32,345:INFO:Creating metrics dataframe
2025-04-06 21:22:32,347:INFO:Initializing AdaBoost Regressor
2025-04-06 21:22:32,347:INFO:Total runtime is 0.41611528396606445 minutes
2025-04-06 21:22:32,348:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:32,348:INFO:Initializing create_model()
2025-04-06 21:22:32,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:32,348:INFO:Checking exceptions
2025-04-06 21:22:32,348:INFO:Importing libraries
2025-04-06 21:22:32,348:INFO:Copying training dataset
2025-04-06 21:22:32,353:INFO:Defining folds
2025-04-06 21:22:32,353:INFO:Declaring metric variables
2025-04-06 21:22:32,353:INFO:Importing untrained model
2025-04-06 21:22:32,353:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:22:32,354:INFO:Starting cross validation
2025-04-06 21:22:32,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:32,918:INFO:Calculating mean and std
2025-04-06 21:22:32,919:INFO:Creating metrics dataframe
2025-04-06 21:22:32,920:INFO:Uploading results into container
2025-04-06 21:22:32,921:INFO:Uploading model into container now
2025-04-06 21:22:32,921:INFO:_master_model_container: 15
2025-04-06 21:22:32,921:INFO:_display_container: 2
2025-04-06 21:22:32,921:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:22:32,921:INFO:create_model() successfully completed......................................
2025-04-06 21:22:33,105:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:33,105:INFO:Creating metrics dataframe
2025-04-06 21:22:33,107:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:22:33,107:INFO:Total runtime is 0.42878547112147014 minutes
2025-04-06 21:22:33,107:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:33,107:INFO:Initializing create_model()
2025-04-06 21:22:33,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:33,107:INFO:Checking exceptions
2025-04-06 21:22:33,107:INFO:Importing libraries
2025-04-06 21:22:33,107:INFO:Copying training dataset
2025-04-06 21:22:33,112:INFO:Defining folds
2025-04-06 21:22:33,112:INFO:Declaring metric variables
2025-04-06 21:22:33,112:INFO:Importing untrained model
2025-04-06 21:22:33,113:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:22:33,113:INFO:Starting cross validation
2025-04-06 21:22:33,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:33,962:INFO:Calculating mean and std
2025-04-06 21:22:33,962:INFO:Creating metrics dataframe
2025-04-06 21:22:33,964:INFO:Uploading results into container
2025-04-06 21:22:33,964:INFO:Uploading model into container now
2025-04-06 21:22:33,965:INFO:_master_model_container: 16
2025-04-06 21:22:33,965:INFO:_display_container: 2
2025-04-06 21:22:33,965:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:22:33,965:INFO:create_model() successfully completed......................................
2025-04-06 21:22:34,138:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:34,138:INFO:Creating metrics dataframe
2025-04-06 21:22:34,141:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:22:34,141:INFO:Total runtime is 0.44601293007532755 minutes
2025-04-06 21:22:34,141:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:34,141:INFO:Initializing create_model()
2025-04-06 21:22:34,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:34,141:INFO:Checking exceptions
2025-04-06 21:22:34,141:INFO:Importing libraries
2025-04-06 21:22:34,141:INFO:Copying training dataset
2025-04-06 21:22:34,146:INFO:Defining folds
2025-04-06 21:22:34,146:INFO:Declaring metric variables
2025-04-06 21:22:34,146:INFO:Importing untrained model
2025-04-06 21:22:34,147:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:22:34,147:INFO:Starting cross validation
2025-04-06 21:22:34,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:35,632:INFO:Calculating mean and std
2025-04-06 21:22:35,633:INFO:Creating metrics dataframe
2025-04-06 21:22:35,635:INFO:Uploading results into container
2025-04-06 21:22:35,636:INFO:Uploading model into container now
2025-04-06 21:22:35,636:INFO:_master_model_container: 17
2025-04-06 21:22:35,636:INFO:_display_container: 2
2025-04-06 21:22:35,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:35,637:INFO:create_model() successfully completed......................................
2025-04-06 21:22:35,833:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:35,833:INFO:Creating metrics dataframe
2025-04-06 21:22:35,835:INFO:Initializing CatBoost Regressor
2025-04-06 21:22:35,836:INFO:Total runtime is 0.47426937023798627 minutes
2025-04-06 21:22:35,836:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:35,836:INFO:Initializing create_model()
2025-04-06 21:22:35,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:35,836:INFO:Checking exceptions
2025-04-06 21:22:35,836:INFO:Importing libraries
2025-04-06 21:22:35,836:INFO:Copying training dataset
2025-04-06 21:22:35,841:INFO:Defining folds
2025-04-06 21:22:35,841:INFO:Declaring metric variables
2025-04-06 21:22:35,841:INFO:Importing untrained model
2025-04-06 21:22:35,845:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:22:35,845:INFO:Starting cross validation
2025-04-06 21:22:35,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:44,806:INFO:Calculating mean and std
2025-04-06 21:22:44,807:INFO:Creating metrics dataframe
2025-04-06 21:22:44,810:INFO:Uploading results into container
2025-04-06 21:22:44,811:INFO:Uploading model into container now
2025-04-06 21:22:44,811:INFO:_master_model_container: 18
2025-04-06 21:22:44,811:INFO:_display_container: 2
2025-04-06 21:22:44,811:INFO:<catboost.core.CatBoostRegressor object at 0x0000029EA7C20250>
2025-04-06 21:22:44,811:INFO:create_model() successfully completed......................................
2025-04-06 21:22:45,015:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:45,015:INFO:Creating metrics dataframe
2025-04-06 21:22:45,017:INFO:Initializing Dummy Regressor
2025-04-06 21:22:45,017:INFO:Total runtime is 0.627294369538625 minutes
2025-04-06 21:22:45,017:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:45,017:INFO:Initializing create_model()
2025-04-06 21:22:45,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:45,018:INFO:Checking exceptions
2025-04-06 21:22:45,018:INFO:Importing libraries
2025-04-06 21:22:45,018:INFO:Copying training dataset
2025-04-06 21:22:45,025:INFO:Defining folds
2025-04-06 21:22:45,025:INFO:Declaring metric variables
2025-04-06 21:22:45,025:INFO:Importing untrained model
2025-04-06 21:22:45,025:INFO:Dummy Regressor Imported successfully
2025-04-06 21:22:45,026:INFO:Starting cross validation
2025-04-06 21:22:45,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:45,446:INFO:Calculating mean and std
2025-04-06 21:22:45,446:INFO:Creating metrics dataframe
2025-04-06 21:22:45,448:INFO:Uploading results into container
2025-04-06 21:22:45,448:INFO:Uploading model into container now
2025-04-06 21:22:45,449:INFO:_master_model_container: 19
2025-04-06 21:22:45,449:INFO:_display_container: 2
2025-04-06 21:22:45,449:INFO:DummyRegressor()
2025-04-06 21:22:45,449:INFO:create_model() successfully completed......................................
2025-04-06 21:22:45,639:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:45,639:INFO:Creating metrics dataframe
2025-04-06 21:22:45,642:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:22:45,644:INFO:Initializing create_model()
2025-04-06 21:22:45,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:45,644:INFO:Checking exceptions
2025-04-06 21:22:45,644:INFO:Importing libraries
2025-04-06 21:22:45,644:INFO:Copying training dataset
2025-04-06 21:22:45,650:INFO:Defining folds
2025-04-06 21:22:45,650:INFO:Declaring metric variables
2025-04-06 21:22:45,650:INFO:Importing untrained model
2025-04-06 21:22:45,650:INFO:Declaring custom model
2025-04-06 21:22:45,650:INFO:Huber Regressor Imported successfully
2025-04-06 21:22:45,652:INFO:Cross validation set to False
2025-04-06 21:22:45,652:INFO:Fitting Model
2025-04-06 21:22:45,836:INFO:HuberRegressor()
2025-04-06 21:22:45,836:INFO:create_model() successfully completed......................................
2025-04-06 21:22:46,008:INFO:_master_model_container: 19
2025-04-06 21:22:46,008:INFO:_display_container: 2
2025-04-06 21:22:46,008:INFO:HuberRegressor()
2025-04-06 21:22:46,008:INFO:compare_models() successfully completed......................................
2025-04-06 21:51:31,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:52:02,009:INFO:PyCaret RegressionExperiment
2025-04-06 21:52:02,009:INFO:Logging name: reg-default-name
2025-04-06 21:52:02,009:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:52:02,010:INFO:version 3.3.2
2025-04-06 21:52:02,010:INFO:Initializing setup()
2025-04-06 21:52:02,010:INFO:self.USI: 335a
2025-04-06 21:52:02,010:INFO:self._variable_keys: {'X_train', 'USI', 'exp_id', 'n_jobs_param', 'target_param', 'y_train', 'exp_name_log', 'gpu_param', 'data', 'html_param', 'logging_param', '_available_plots', 'X', 'log_plots_param', 'fold_shuffle_param', 'transform_target_param', 'y', 'X_test', 'fold_groups_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'seed', '_ml_usecase', 'pipeline', 'idx', 'memory'}
2025-04-06 21:52:02,010:INFO:Checking environment
2025-04-06 21:52:02,010:INFO:python_version: 3.11.4
2025-04-06 21:52:02,010:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:52:02,010:INFO:machine: AMD64
2025-04-06 21:52:02,035:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:52:02,040:INFO:Memory: svmem(total=17127211008, available=5105315840, percent=70.2, used=12021895168, free=5105315840)
2025-04-06 21:52:02,040:INFO:Physical Core: 6
2025-04-06 21:52:02,040:INFO:Logical Core: 12
2025-04-06 21:52:02,040:INFO:Checking libraries
2025-04-06 21:52:02,040:INFO:System:
2025-04-06 21:52:02,040:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:52:02,040:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:52:02,040:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:52:02,040:INFO:PyCaret required dependencies:
2025-04-06 21:52:02,774:INFO:                 pip: 25.0.1
2025-04-06 21:52:02,774:INFO:          setuptools: 65.5.0
2025-04-06 21:52:02,774:INFO:             pycaret: 3.3.2
2025-04-06 21:52:02,775:INFO:             IPython: 8.12.3
2025-04-06 21:52:02,775:INFO:          ipywidgets: 8.1.5
2025-04-06 21:52:02,775:INFO:                tqdm: 4.67.1
2025-04-06 21:52:02,775:INFO:               numpy: 1.26.4
2025-04-06 21:52:02,775:INFO:              pandas: 2.1.4
2025-04-06 21:52:02,775:INFO:              jinja2: 3.1.2
2025-04-06 21:52:02,775:INFO:               scipy: 1.11.4
2025-04-06 21:52:02,775:INFO:              joblib: 1.3.2
2025-04-06 21:52:02,775:INFO:             sklearn: 1.4.2
2025-04-06 21:52:02,775:INFO:                pyod: 2.0.3
2025-04-06 21:52:02,775:INFO:            imblearn: 0.13.0
2025-04-06 21:52:02,775:INFO:   category_encoders: 2.7.0
2025-04-06 21:52:02,775:INFO:            lightgbm: 4.6.0
2025-04-06 21:52:02,775:INFO:               numba: 0.61.0
2025-04-06 21:52:02,775:INFO:            requests: 2.32.3
2025-04-06 21:52:02,775:INFO:          matplotlib: 3.7.5
2025-04-06 21:52:02,775:INFO:          scikitplot: 0.3.7
2025-04-06 21:52:02,775:INFO:         yellowbrick: 1.5
2025-04-06 21:52:02,775:INFO:              plotly: 5.24.1
2025-04-06 21:52:02,776:INFO:    plotly-resampler: Not installed
2025-04-06 21:52:02,776:INFO:             kaleido: 0.2.1
2025-04-06 21:52:02,776:INFO:           schemdraw: 0.15
2025-04-06 21:52:02,776:INFO:         statsmodels: 0.14.4
2025-04-06 21:52:02,776:INFO:              sktime: 0.26.0
2025-04-06 21:52:02,776:INFO:               tbats: 1.1.3
2025-04-06 21:52:02,776:INFO:            pmdarima: 2.0.4
2025-04-06 21:52:02,776:INFO:              psutil: 7.0.0
2025-04-06 21:52:02,776:INFO:          markupsafe: 2.1.3
2025-04-06 21:52:02,776:INFO:             pickle5: Not installed
2025-04-06 21:52:02,776:INFO:         cloudpickle: 3.1.1
2025-04-06 21:52:02,776:INFO:         deprecation: 2.1.0
2025-04-06 21:52:02,776:INFO:              xxhash: 3.5.0
2025-04-06 21:52:02,776:INFO:           wurlitzer: Not installed
2025-04-06 21:52:02,776:INFO:PyCaret optional dependencies:
2025-04-06 21:52:05,798:INFO:                shap: 0.44.1
2025-04-06 21:52:05,799:INFO:           interpret: 0.6.9
2025-04-06 21:52:05,799:INFO:                umap: 0.5.7
2025-04-06 21:52:05,799:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:52:05,799:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:52:05,799:INFO:             autoviz: Not installed
2025-04-06 21:52:05,799:INFO:           fairlearn: 0.7.0
2025-04-06 21:52:05,799:INFO:          deepchecks: Not installed
2025-04-06 21:52:05,799:INFO:             xgboost: Not installed
2025-04-06 21:52:05,799:INFO:            catboost: 1.2.7
2025-04-06 21:52:05,799:INFO:              kmodes: 0.12.2
2025-04-06 21:52:05,799:INFO:             mlxtend: 0.23.4
2025-04-06 21:52:05,799:INFO:       statsforecast: 1.5.0
2025-04-06 21:52:05,799:INFO:        tune_sklearn: Not installed
2025-04-06 21:52:05,799:INFO:                 ray: Not installed
2025-04-06 21:52:05,799:INFO:            hyperopt: 0.2.7
2025-04-06 21:52:05,799:INFO:              optuna: 4.2.1
2025-04-06 21:52:05,799:INFO:               skopt: 0.10.2
2025-04-06 21:52:05,799:INFO:              mlflow: 2.21.0
2025-04-06 21:52:05,800:INFO:              gradio: 5.21.0
2025-04-06 21:52:05,800:INFO:             fastapi: 0.115.11
2025-04-06 21:52:05,800:INFO:             uvicorn: 0.34.0
2025-04-06 21:52:05,800:INFO:              m2cgen: 0.10.0
2025-04-06 21:52:05,800:INFO:           evidently: 0.4.40
2025-04-06 21:52:05,800:INFO:               fugue: 0.8.7
2025-04-06 21:52:05,800:INFO:           streamlit: 1.42.2
2025-04-06 21:52:05,800:INFO:             prophet: Not installed
2025-04-06 21:52:05,800:INFO:None
2025-04-06 21:52:05,800:INFO:Set up data.
2025-04-06 21:52:05,811:INFO:Set up folding strategy.
2025-04-06 21:52:05,811:INFO:Set up train/test split.
2025-04-06 21:52:05,819:INFO:Set up index.
2025-04-06 21:52:05,820:INFO:Assigning column types.
2025-04-06 21:52:05,824:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:52:05,824:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,830:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:05,973:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,005:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,011:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,017:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,151:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,152:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:52:06,158:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,299:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,305:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,312:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,445:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,445:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:52:06,457:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,593:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,738:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,738:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:52:06,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,883:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,034:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:52:07,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,185:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,333:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,333:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:52:07,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,481:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,634:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,636:INFO:Preparing preprocessing pipeline...
2025-04-06 21:52:07,636:INFO:Set up simple imputation.
2025-04-06 21:52:07,639:INFO:Set up encoding of categorical features.
2025-04-06 21:52:07,861:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:52:07,873:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:52:07,873:INFO:Creating final display dataframe.
2025-04-06 21:52:08,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1000, 16)
4        Transformed data shape        (1000, 20)
5   Transformed train set shape         (700, 20)
6    Transformed test set shape         (300, 20)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              2.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              335a
2025-04-06 21:52:08,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:08,690:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:08,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:08,837:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:08,838:INFO:setup() successfully completed in 6.84s...............
2025-04-06 21:52:08,838:INFO:Initializing compare_models()
2025-04-06 21:52:08,839:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:52:08,839:INFO:Checking exceptions
2025-04-06 21:52:08,841:INFO:Preparing display monitor
2025-04-06 21:52:08,844:INFO:Initializing Linear Regression
2025-04-06 21:52:08,844:INFO:Total runtime is 0.0 minutes
2025-04-06 21:52:08,844:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:08,844:INFO:Initializing create_model()
2025-04-06 21:52:08,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:08,844:INFO:Checking exceptions
2025-04-06 21:52:08,844:INFO:Importing libraries
2025-04-06 21:52:08,844:INFO:Copying training dataset
2025-04-06 21:52:08,848:INFO:Defining folds
2025-04-06 21:52:08,848:INFO:Declaring metric variables
2025-04-06 21:52:08,848:INFO:Importing untrained model
2025-04-06 21:52:08,850:INFO:Linear Regression Imported successfully
2025-04-06 21:52:08,850:INFO:Starting cross validation
2025-04-06 21:52:08,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:17,348:INFO:Calculating mean and std
2025-04-06 21:52:17,349:INFO:Creating metrics dataframe
2025-04-06 21:52:17,351:INFO:Uploading results into container
2025-04-06 21:52:17,351:INFO:Uploading model into container now
2025-04-06 21:52:17,351:INFO:_master_model_container: 1
2025-04-06 21:52:17,352:INFO:_display_container: 2
2025-04-06 21:52:17,352:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:52:17,352:INFO:create_model() successfully completed......................................
2025-04-06 21:52:17,529:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:17,529:INFO:Creating metrics dataframe
2025-04-06 21:52:17,531:INFO:Initializing Lasso Regression
2025-04-06 21:52:17,531:INFO:Total runtime is 0.14478984276453655 minutes
2025-04-06 21:52:17,531:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:17,531:INFO:Initializing create_model()
2025-04-06 21:52:17,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:17,531:INFO:Checking exceptions
2025-04-06 21:52:17,531:INFO:Importing libraries
2025-04-06 21:52:17,531:INFO:Copying training dataset
2025-04-06 21:52:17,536:INFO:Defining folds
2025-04-06 21:52:17,536:INFO:Declaring metric variables
2025-04-06 21:52:17,537:INFO:Importing untrained model
2025-04-06 21:52:17,537:INFO:Lasso Regression Imported successfully
2025-04-06 21:52:17,537:INFO:Starting cross validation
2025-04-06 21:52:17,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:17,746:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,762:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,796:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,805:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,809:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,032:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,035:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,073:INFO:Calculating mean and std
2025-04-06 21:52:22,074:INFO:Creating metrics dataframe
2025-04-06 21:52:22,076:INFO:Uploading results into container
2025-04-06 21:52:22,076:INFO:Uploading model into container now
2025-04-06 21:52:22,077:INFO:_master_model_container: 2
2025-04-06 21:52:22,077:INFO:_display_container: 2
2025-04-06 21:52:22,077:INFO:Lasso(random_state=123)
2025-04-06 21:52:22,077:INFO:create_model() successfully completed......................................
2025-04-06 21:52:22,234:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:22,235:INFO:Creating metrics dataframe
2025-04-06 21:52:22,237:INFO:Initializing Ridge Regression
2025-04-06 21:52:22,237:INFO:Total runtime is 0.2232274572054545 minutes
2025-04-06 21:52:22,237:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:22,238:INFO:Initializing create_model()
2025-04-06 21:52:22,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:22,238:INFO:Checking exceptions
2025-04-06 21:52:22,238:INFO:Importing libraries
2025-04-06 21:52:22,238:INFO:Copying training dataset
2025-04-06 21:52:22,243:INFO:Defining folds
2025-04-06 21:52:22,243:INFO:Declaring metric variables
2025-04-06 21:52:22,243:INFO:Importing untrained model
2025-04-06 21:52:22,243:INFO:Ridge Regression Imported successfully
2025-04-06 21:52:22,244:INFO:Starting cross validation
2025-04-06 21:52:22,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:22,546:INFO:Calculating mean and std
2025-04-06 21:52:22,547:INFO:Creating metrics dataframe
2025-04-06 21:52:22,549:INFO:Uploading results into container
2025-04-06 21:52:22,549:INFO:Uploading model into container now
2025-04-06 21:52:22,549:INFO:_master_model_container: 3
2025-04-06 21:52:22,549:INFO:_display_container: 2
2025-04-06 21:52:22,550:INFO:Ridge(random_state=123)
2025-04-06 21:52:22,550:INFO:create_model() successfully completed......................................
2025-04-06 21:52:22,692:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:22,693:INFO:Creating metrics dataframe
2025-04-06 21:52:22,695:INFO:Initializing Elastic Net
2025-04-06 21:52:22,695:INFO:Total runtime is 0.23084967533747355 minutes
2025-04-06 21:52:22,696:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:22,696:INFO:Initializing create_model()
2025-04-06 21:52:22,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:22,696:INFO:Checking exceptions
2025-04-06 21:52:22,696:INFO:Importing libraries
2025-04-06 21:52:22,696:INFO:Copying training dataset
2025-04-06 21:52:22,701:INFO:Defining folds
2025-04-06 21:52:22,701:INFO:Declaring metric variables
2025-04-06 21:52:22,701:INFO:Importing untrained model
2025-04-06 21:52:22,701:INFO:Elastic Net Imported successfully
2025-04-06 21:52:22,701:INFO:Starting cross validation
2025-04-06 21:52:22,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:22,858:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,883:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,886:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,933:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,941:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,953:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,969:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,978:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:23,022:INFO:Calculating mean and std
2025-04-06 21:52:23,022:INFO:Creating metrics dataframe
2025-04-06 21:52:23,024:INFO:Uploading results into container
2025-04-06 21:52:23,024:INFO:Uploading model into container now
2025-04-06 21:52:23,025:INFO:_master_model_container: 4
2025-04-06 21:52:23,025:INFO:_display_container: 2
2025-04-06 21:52:23,025:INFO:ElasticNet(random_state=123)
2025-04-06 21:52:23,025:INFO:create_model() successfully completed......................................
2025-04-06 21:52:23,175:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:23,175:INFO:Creating metrics dataframe
2025-04-06 21:52:23,178:INFO:Initializing Least Angle Regression
2025-04-06 21:52:23,178:INFO:Total runtime is 0.23890920877456664 minutes
2025-04-06 21:52:23,178:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:23,178:INFO:Initializing create_model()
2025-04-06 21:52:23,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:23,178:INFO:Checking exceptions
2025-04-06 21:52:23,178:INFO:Importing libraries
2025-04-06 21:52:23,179:INFO:Copying training dataset
2025-04-06 21:52:23,184:INFO:Defining folds
2025-04-06 21:52:23,184:INFO:Declaring metric variables
2025-04-06 21:52:23,184:INFO:Importing untrained model
2025-04-06 21:52:23,184:INFO:Least Angle Regression Imported successfully
2025-04-06 21:52:23,185:INFO:Starting cross validation
2025-04-06 21:52:23,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.121e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.120e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.372e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,342:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.648e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.431e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.080e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.567e+02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,344:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.488e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,344:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.301e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,358:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,358:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,359:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,360:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,360:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,361:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,361:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,363:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,363:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,364:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,367:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.412e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,368:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.698e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,369:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.589e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,370:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.551e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,370:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.154e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,371:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.175e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,372:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.115e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,372:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.886e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.513e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,390:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.871e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.958e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.629e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.726e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,392:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.376e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.619e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.127e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.382e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,395:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,396:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,396:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,397:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.011e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.339e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.335e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.975e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,416:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,417:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,418:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.973e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.309e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.449e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.946e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.865e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,423:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.290e+02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,424:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.199e+05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,424:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.387e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,425:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.188e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,430:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,431:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,432:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,432:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,433:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,433:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,434:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,435:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,435:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.342e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,438:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,439:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,439:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,440:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,440:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,441:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.163e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,442:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.558e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,442:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,443:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,444:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.913e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,444:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.308e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.481e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.113e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.647e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.429e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.331e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.280e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.261e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.848e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.208e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,449:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.147e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,465:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,466:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,466:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,467:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.905e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.210e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.344e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,469:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.795e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.296e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.561e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.488e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.365e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.294e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.322e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,512:INFO:Calculating mean and std
2025-04-06 21:52:23,513:INFO:Creating metrics dataframe
2025-04-06 21:52:23,515:INFO:Uploading results into container
2025-04-06 21:52:23,515:INFO:Uploading model into container now
2025-04-06 21:52:23,515:INFO:_master_model_container: 5
2025-04-06 21:52:23,516:INFO:_display_container: 2
2025-04-06 21:52:23,516:INFO:Lars(random_state=123)
2025-04-06 21:52:23,516:INFO:create_model() successfully completed......................................
2025-04-06 21:52:23,664:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:23,665:INFO:Creating metrics dataframe
2025-04-06 21:52:23,668:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:52:23,668:INFO:Total runtime is 0.247063414255778 minutes
2025-04-06 21:52:23,668:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:23,668:INFO:Initializing create_model()
2025-04-06 21:52:23,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:23,668:INFO:Checking exceptions
2025-04-06 21:52:23,668:INFO:Importing libraries
2025-04-06 21:52:23,668:INFO:Copying training dataset
2025-04-06 21:52:23,673:INFO:Defining folds
2025-04-06 21:52:23,673:INFO:Declaring metric variables
2025-04-06 21:52:23,673:INFO:Importing untrained model
2025-04-06 21:52:23,674:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:52:23,674:INFO:Starting cross validation
2025-04-06 21:52:23,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:23,831:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.433e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.215e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.107e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,833:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.334e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,833:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.969e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,834:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.995e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,835:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.374e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,835:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.355e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.161e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.451e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,837:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.079e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,844:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,845:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,845:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,846:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,846:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,847:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,847:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,850:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,896:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.029e+10, previous alpha=6.634e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,901:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.793e+07, previous alpha=5.163e+03, with an active set of 12 regressors.
  warnings.warn(

2025-04-06 21:52:23,916:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,916:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.114e+10, previous alpha=6.961e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.894e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.944e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.526e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,921:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.799e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,921:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.823e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,922:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.346e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,922:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.385e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,923:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.498e+08, previous alpha=2.565e+03, with an active set of 14 regressors.
  warnings.warn(

2025-04-06 21:52:23,934:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,934:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,935:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,935:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,939:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,939:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=8.178e+09, previous alpha=4.617e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,986:INFO:Calculating mean and std
2025-04-06 21:52:23,986:INFO:Creating metrics dataframe
2025-04-06 21:52:23,988:INFO:Uploading results into container
2025-04-06 21:52:23,988:INFO:Uploading model into container now
2025-04-06 21:52:23,989:INFO:_master_model_container: 6
2025-04-06 21:52:23,989:INFO:_display_container: 2
2025-04-06 21:52:23,989:INFO:LassoLars(random_state=123)
2025-04-06 21:52:23,989:INFO:create_model() successfully completed......................................
2025-04-06 21:52:24,134:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:24,134:INFO:Creating metrics dataframe
2025-04-06 21:52:24,137:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:52:24,137:INFO:Total runtime is 0.2548876325289408 minutes
2025-04-06 21:52:24,137:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:24,137:INFO:Initializing create_model()
2025-04-06 21:52:24,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:24,138:INFO:Checking exceptions
2025-04-06 21:52:24,138:INFO:Importing libraries
2025-04-06 21:52:24,138:INFO:Copying training dataset
2025-04-06 21:52:24,142:INFO:Defining folds
2025-04-06 21:52:24,142:INFO:Declaring metric variables
2025-04-06 21:52:24,142:INFO:Importing untrained model
2025-04-06 21:52:24,143:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:52:24,143:INFO:Starting cross validation
2025-04-06 21:52:24,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:24,469:INFO:Calculating mean and std
2025-04-06 21:52:24,470:INFO:Creating metrics dataframe
2025-04-06 21:52:24,472:INFO:Uploading results into container
2025-04-06 21:52:24,472:INFO:Uploading model into container now
2025-04-06 21:52:24,473:INFO:_master_model_container: 7
2025-04-06 21:52:24,473:INFO:_display_container: 2
2025-04-06 21:52:24,473:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:52:24,473:INFO:create_model() successfully completed......................................
2025-04-06 21:52:24,628:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:24,628:INFO:Creating metrics dataframe
2025-04-06 21:52:24,630:INFO:Initializing Bayesian Ridge
2025-04-06 21:52:24,631:INFO:Total runtime is 0.2631000876426697 minutes
2025-04-06 21:52:24,631:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:24,631:INFO:Initializing create_model()
2025-04-06 21:52:24,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:24,631:INFO:Checking exceptions
2025-04-06 21:52:24,631:INFO:Importing libraries
2025-04-06 21:52:24,631:INFO:Copying training dataset
2025-04-06 21:52:24,637:INFO:Defining folds
2025-04-06 21:52:24,637:INFO:Declaring metric variables
2025-04-06 21:52:24,637:INFO:Importing untrained model
2025-04-06 21:52:24,638:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:52:24,638:INFO:Starting cross validation
2025-04-06 21:52:24,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:24,949:INFO:Calculating mean and std
2025-04-06 21:52:24,950:INFO:Creating metrics dataframe
2025-04-06 21:52:24,951:INFO:Uploading results into container
2025-04-06 21:52:24,952:INFO:Uploading model into container now
2025-04-06 21:52:24,952:INFO:_master_model_container: 8
2025-04-06 21:52:24,952:INFO:_display_container: 2
2025-04-06 21:52:24,953:INFO:BayesianRidge()
2025-04-06 21:52:24,953:INFO:create_model() successfully completed......................................
2025-04-06 21:52:25,102:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:25,102:INFO:Creating metrics dataframe
2025-04-06 21:52:25,105:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:52:25,105:INFO:Total runtime is 0.2710230350494385 minutes
2025-04-06 21:52:25,105:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:25,106:INFO:Initializing create_model()
2025-04-06 21:52:25,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:25,106:INFO:Checking exceptions
2025-04-06 21:52:25,106:INFO:Importing libraries
2025-04-06 21:52:25,106:INFO:Copying training dataset
2025-04-06 21:52:25,111:INFO:Defining folds
2025-04-06 21:52:25,111:INFO:Declaring metric variables
2025-04-06 21:52:25,111:INFO:Importing untrained model
2025-04-06 21:52:25,112:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:52:25,112:INFO:Starting cross validation
2025-04-06 21:52:25,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:25,414:INFO:Calculating mean and std
2025-04-06 21:52:25,415:INFO:Creating metrics dataframe
2025-04-06 21:52:25,417:INFO:Uploading results into container
2025-04-06 21:52:25,417:INFO:Uploading model into container now
2025-04-06 21:52:25,418:INFO:_master_model_container: 9
2025-04-06 21:52:25,418:INFO:_display_container: 2
2025-04-06 21:52:25,418:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:52:25,418:INFO:create_model() successfully completed......................................
2025-04-06 21:52:25,571:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:25,571:INFO:Creating metrics dataframe
2025-04-06 21:52:25,573:INFO:Initializing Huber Regressor
2025-04-06 21:52:25,573:INFO:Total runtime is 0.27882731358210244 minutes
2025-04-06 21:52:25,574:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:25,574:INFO:Initializing create_model()
2025-04-06 21:52:25,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:25,574:INFO:Checking exceptions
2025-04-06 21:52:25,574:INFO:Importing libraries
2025-04-06 21:52:25,574:INFO:Copying training dataset
2025-04-06 21:52:25,579:INFO:Defining folds
2025-04-06 21:52:25,579:INFO:Declaring metric variables
2025-04-06 21:52:25,579:INFO:Importing untrained model
2025-04-06 21:52:25,580:INFO:Huber Regressor Imported successfully
2025-04-06 21:52:25,580:INFO:Starting cross validation
2025-04-06 21:52:25,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:25,811:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,812:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,837:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,870:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,887:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,895:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,936:INFO:Calculating mean and std
2025-04-06 21:52:25,937:INFO:Creating metrics dataframe
2025-04-06 21:52:25,938:INFO:Uploading results into container
2025-04-06 21:52:25,938:INFO:Uploading model into container now
2025-04-06 21:52:25,939:INFO:_master_model_container: 10
2025-04-06 21:52:25,939:INFO:_display_container: 2
2025-04-06 21:52:25,939:INFO:HuberRegressor()
2025-04-06 21:52:25,939:INFO:create_model() successfully completed......................................
2025-04-06 21:52:26,081:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:26,081:INFO:Creating metrics dataframe
2025-04-06 21:52:26,084:INFO:Initializing K Neighbors Regressor
2025-04-06 21:52:26,084:INFO:Total runtime is 0.2873404224713643 minutes
2025-04-06 21:52:26,084:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:26,085:INFO:Initializing create_model()
2025-04-06 21:52:26,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:26,085:INFO:Checking exceptions
2025-04-06 21:52:26,085:INFO:Importing libraries
2025-04-06 21:52:26,085:INFO:Copying training dataset
2025-04-06 21:52:26,090:INFO:Defining folds
2025-04-06 21:52:26,090:INFO:Declaring metric variables
2025-04-06 21:52:26,090:INFO:Importing untrained model
2025-04-06 21:52:26,090:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:52:26,091:INFO:Starting cross validation
2025-04-06 21:52:26,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:26,404:INFO:Calculating mean and std
2025-04-06 21:52:26,404:INFO:Creating metrics dataframe
2025-04-06 21:52:26,406:INFO:Uploading results into container
2025-04-06 21:52:26,406:INFO:Uploading model into container now
2025-04-06 21:52:26,406:INFO:_master_model_container: 11
2025-04-06 21:52:26,406:INFO:_display_container: 2
2025-04-06 21:52:26,406:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:52:26,407:INFO:create_model() successfully completed......................................
2025-04-06 21:52:26,560:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:26,560:INFO:Creating metrics dataframe
2025-04-06 21:52:26,563:INFO:Initializing Decision Tree Regressor
2025-04-06 21:52:26,563:INFO:Total runtime is 0.29531611998875934 minutes
2025-04-06 21:52:26,564:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:26,564:INFO:Initializing create_model()
2025-04-06 21:52:26,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:26,564:INFO:Checking exceptions
2025-04-06 21:52:26,564:INFO:Importing libraries
2025-04-06 21:52:26,564:INFO:Copying training dataset
2025-04-06 21:52:26,569:INFO:Defining folds
2025-04-06 21:52:26,569:INFO:Declaring metric variables
2025-04-06 21:52:26,569:INFO:Importing untrained model
2025-04-06 21:52:26,569:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:52:26,569:INFO:Starting cross validation
2025-04-06 21:52:26,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:26,868:INFO:Calculating mean and std
2025-04-06 21:52:26,869:INFO:Creating metrics dataframe
2025-04-06 21:52:26,871:INFO:Uploading results into container
2025-04-06 21:52:26,871:INFO:Uploading model into container now
2025-04-06 21:52:26,871:INFO:_master_model_container: 12
2025-04-06 21:52:26,871:INFO:_display_container: 2
2025-04-06 21:52:26,872:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:52:26,872:INFO:create_model() successfully completed......................................
2025-04-06 21:52:27,019:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:27,019:INFO:Creating metrics dataframe
2025-04-06 21:52:27,021:INFO:Initializing Random Forest Regressor
2025-04-06 21:52:27,021:INFO:Total runtime is 0.3029526591300964 minutes
2025-04-06 21:52:27,021:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:27,021:INFO:Initializing create_model()
2025-04-06 21:52:27,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:27,021:INFO:Checking exceptions
2025-04-06 21:52:27,022:INFO:Importing libraries
2025-04-06 21:52:27,022:INFO:Copying training dataset
2025-04-06 21:52:27,026:INFO:Defining folds
2025-04-06 21:52:27,026:INFO:Declaring metric variables
2025-04-06 21:52:27,027:INFO:Importing untrained model
2025-04-06 21:52:27,027:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:52:27,027:INFO:Starting cross validation
2025-04-06 21:52:27,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:28,195:INFO:Calculating mean and std
2025-04-06 21:52:28,195:INFO:Creating metrics dataframe
2025-04-06 21:52:28,197:INFO:Uploading results into container
2025-04-06 21:52:28,197:INFO:Uploading model into container now
2025-04-06 21:52:28,198:INFO:_master_model_container: 13
2025-04-06 21:52:28,198:INFO:_display_container: 2
2025-04-06 21:52:28,198:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:28,198:INFO:create_model() successfully completed......................................
2025-04-06 21:52:28,344:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:28,344:INFO:Creating metrics dataframe
2025-04-06 21:52:28,346:INFO:Initializing Extra Trees Regressor
2025-04-06 21:52:28,346:INFO:Total runtime is 0.325038468837738 minutes
2025-04-06 21:52:28,346:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:28,347:INFO:Initializing create_model()
2025-04-06 21:52:28,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:28,347:INFO:Checking exceptions
2025-04-06 21:52:28,347:INFO:Importing libraries
2025-04-06 21:52:28,347:INFO:Copying training dataset
2025-04-06 21:52:28,352:INFO:Defining folds
2025-04-06 21:52:28,352:INFO:Declaring metric variables
2025-04-06 21:52:28,352:INFO:Importing untrained model
2025-04-06 21:52:28,352:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:52:28,353:INFO:Starting cross validation
2025-04-06 21:52:28,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:29,160:INFO:Calculating mean and std
2025-04-06 21:52:29,161:INFO:Creating metrics dataframe
2025-04-06 21:52:29,162:INFO:Uploading results into container
2025-04-06 21:52:29,163:INFO:Uploading model into container now
2025-04-06 21:52:29,163:INFO:_master_model_container: 14
2025-04-06 21:52:29,163:INFO:_display_container: 2
2025-04-06 21:52:29,164:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:29,164:INFO:create_model() successfully completed......................................
2025-04-06 21:52:29,313:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:29,314:INFO:Creating metrics dataframe
2025-04-06 21:52:29,316:INFO:Initializing AdaBoost Regressor
2025-04-06 21:52:29,316:INFO:Total runtime is 0.34120856523513793 minutes
2025-04-06 21:52:29,316:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:29,316:INFO:Initializing create_model()
2025-04-06 21:52:29,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:29,316:INFO:Checking exceptions
2025-04-06 21:52:29,317:INFO:Importing libraries
2025-04-06 21:52:29,317:INFO:Copying training dataset
2025-04-06 21:52:29,322:INFO:Defining folds
2025-04-06 21:52:29,322:INFO:Declaring metric variables
2025-04-06 21:52:29,322:INFO:Importing untrained model
2025-04-06 21:52:29,322:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:52:29,323:INFO:Starting cross validation
2025-04-06 21:52:29,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:29,774:INFO:Calculating mean and std
2025-04-06 21:52:29,775:INFO:Creating metrics dataframe
2025-04-06 21:52:29,777:INFO:Uploading results into container
2025-04-06 21:52:29,777:INFO:Uploading model into container now
2025-04-06 21:52:29,777:INFO:_master_model_container: 15
2025-04-06 21:52:29,777:INFO:_display_container: 2
2025-04-06 21:52:29,778:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:52:29,778:INFO:create_model() successfully completed......................................
2025-04-06 21:52:29,926:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:29,926:INFO:Creating metrics dataframe
2025-04-06 21:52:29,928:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:52:29,928:INFO:Total runtime is 0.3513988693555196 minutes
2025-04-06 21:52:29,929:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:29,929:INFO:Initializing create_model()
2025-04-06 21:52:29,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:29,929:INFO:Checking exceptions
2025-04-06 21:52:29,929:INFO:Importing libraries
2025-04-06 21:52:29,929:INFO:Copying training dataset
2025-04-06 21:52:29,934:INFO:Defining folds
2025-04-06 21:52:29,934:INFO:Declaring metric variables
2025-04-06 21:52:29,934:INFO:Importing untrained model
2025-04-06 21:52:29,935:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:52:29,935:INFO:Starting cross validation
2025-04-06 21:52:29,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:30,563:INFO:Calculating mean and std
2025-04-06 21:52:30,564:INFO:Creating metrics dataframe
2025-04-06 21:52:30,565:INFO:Uploading results into container
2025-04-06 21:52:30,566:INFO:Uploading model into container now
2025-04-06 21:52:30,566:INFO:_master_model_container: 16
2025-04-06 21:52:30,566:INFO:_display_container: 2
2025-04-06 21:52:30,566:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:52:30,567:INFO:create_model() successfully completed......................................
2025-04-06 21:52:30,712:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:30,712:INFO:Creating metrics dataframe
2025-04-06 21:52:30,714:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:52:30,714:INFO:Total runtime is 0.36449965635935466 minutes
2025-04-06 21:52:30,714:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:30,715:INFO:Initializing create_model()
2025-04-06 21:52:30,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:30,715:INFO:Checking exceptions
2025-04-06 21:52:30,715:INFO:Importing libraries
2025-04-06 21:52:30,715:INFO:Copying training dataset
2025-04-06 21:52:30,719:INFO:Defining folds
2025-04-06 21:52:30,719:INFO:Declaring metric variables
2025-04-06 21:52:30,719:INFO:Importing untrained model
2025-04-06 21:52:30,720:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:52:30,720:INFO:Starting cross validation
2025-04-06 21:52:30,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:31,997:INFO:Calculating mean and std
2025-04-06 21:52:31,998:INFO:Creating metrics dataframe
2025-04-06 21:52:32,000:INFO:Uploading results into container
2025-04-06 21:52:32,001:INFO:Uploading model into container now
2025-04-06 21:52:32,001:INFO:_master_model_container: 17
2025-04-06 21:52:32,001:INFO:_display_container: 2
2025-04-06 21:52:32,002:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:32,002:INFO:create_model() successfully completed......................................
2025-04-06 21:52:32,203:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:32,203:INFO:Creating metrics dataframe
2025-04-06 21:52:32,206:INFO:Initializing CatBoost Regressor
2025-04-06 21:52:32,206:INFO:Total runtime is 0.3893664280573527 minutes
2025-04-06 21:52:32,206:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:32,207:INFO:Initializing create_model()
2025-04-06 21:52:32,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:32,207:INFO:Checking exceptions
2025-04-06 21:52:32,207:INFO:Importing libraries
2025-04-06 21:52:32,207:INFO:Copying training dataset
2025-04-06 21:52:32,213:INFO:Defining folds
2025-04-06 21:52:32,213:INFO:Declaring metric variables
2025-04-06 21:52:32,213:INFO:Importing untrained model
2025-04-06 21:52:32,214:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:52:32,214:INFO:Starting cross validation
2025-04-06 21:52:32,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:42,167:INFO:Calculating mean and std
2025-04-06 21:52:42,167:INFO:Creating metrics dataframe
2025-04-06 21:52:42,169:INFO:Uploading results into container
2025-04-06 21:52:42,169:INFO:Uploading model into container now
2025-04-06 21:52:42,170:INFO:_master_model_container: 18
2025-04-06 21:52:42,170:INFO:_display_container: 2
2025-04-06 21:52:42,170:INFO:<catboost.core.CatBoostRegressor object at 0x000001EBE4821D50>
2025-04-06 21:52:42,170:INFO:create_model() successfully completed......................................
2025-04-06 21:52:42,322:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:42,323:INFO:Creating metrics dataframe
2025-04-06 21:52:42,325:INFO:Initializing Dummy Regressor
2025-04-06 21:52:42,325:INFO:Total runtime is 0.5580158988634746 minutes
2025-04-06 21:52:42,325:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:42,325:INFO:Initializing create_model()
2025-04-06 21:52:42,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:42,326:INFO:Checking exceptions
2025-04-06 21:52:42,326:INFO:Importing libraries
2025-04-06 21:52:42,326:INFO:Copying training dataset
2025-04-06 21:52:42,330:INFO:Defining folds
2025-04-06 21:52:42,330:INFO:Declaring metric variables
2025-04-06 21:52:42,330:INFO:Importing untrained model
2025-04-06 21:52:42,331:INFO:Dummy Regressor Imported successfully
2025-04-06 21:52:42,331:INFO:Starting cross validation
2025-04-06 21:52:42,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:42,695:INFO:Calculating mean and std
2025-04-06 21:52:42,695:INFO:Creating metrics dataframe
2025-04-06 21:52:42,697:INFO:Uploading results into container
2025-04-06 21:52:42,697:INFO:Uploading model into container now
2025-04-06 21:52:42,698:INFO:_master_model_container: 19
2025-04-06 21:52:42,698:INFO:_display_container: 2
2025-04-06 21:52:42,698:INFO:DummyRegressor()
2025-04-06 21:52:42,698:INFO:create_model() successfully completed......................................
2025-04-06 21:52:42,853:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:42,853:INFO:Creating metrics dataframe
2025-04-06 21:52:42,856:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:52:42,858:INFO:Initializing create_model()
2025-04-06 21:52:42,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:42,858:INFO:Checking exceptions
2025-04-06 21:52:42,858:INFO:Importing libraries
2025-04-06 21:52:42,858:INFO:Copying training dataset
2025-04-06 21:52:42,863:INFO:Defining folds
2025-04-06 21:52:42,863:INFO:Declaring metric variables
2025-04-06 21:52:42,864:INFO:Importing untrained model
2025-04-06 21:52:42,864:INFO:Declaring custom model
2025-04-06 21:52:42,864:INFO:Huber Regressor Imported successfully
2025-04-06 21:52:42,865:INFO:Cross validation set to False
2025-04-06 21:52:42,865:INFO:Fitting Model
2025-04-06 21:52:43,057:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:43,058:INFO:HuberRegressor()
2025-04-06 21:52:43,058:INFO:create_model() successfully completed......................................
2025-04-06 21:52:43,216:INFO:_master_model_container: 19
2025-04-06 21:52:43,216:INFO:_display_container: 2
2025-04-06 21:52:43,216:INFO:HuberRegressor()
2025-04-06 21:52:43,217:INFO:compare_models() successfully completed......................................
2025-04-06 21:55:08,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:18,334:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:55:18,339:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:55:18,677:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:56:17,130:INFO:PyCaret RegressionExperiment
2025-04-06 21:56:17,130:INFO:Logging name: reg-default-name
2025-04-06 21:56:17,130:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:56:17,130:INFO:version 3.3.2
2025-04-06 21:56:17,130:INFO:Initializing setup()
2025-04-06 21:56:17,130:INFO:self.USI: 61f6
2025-04-06 21:56:17,130:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:17,131:INFO:Checking environment
2025-04-06 21:56:17,131:INFO:python_version: 3.11.4
2025-04-06 21:56:17,131:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:17,131:INFO:machine: AMD64
2025-04-06 21:56:17,161:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:17,166:INFO:Memory: svmem(total=17127211008, available=5194280960, percent=69.7, used=11932930048, free=5194280960)
2025-04-06 21:56:17,166:INFO:Physical Core: 6
2025-04-06 21:56:17,166:INFO:Logical Core: 12
2025-04-06 21:56:17,166:INFO:Checking libraries
2025-04-06 21:56:17,166:INFO:System:
2025-04-06 21:56:17,166:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:17,166:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:17,166:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:17,166:INFO:PyCaret required dependencies:
2025-04-06 21:56:17,916:INFO:                 pip: 25.0.1
2025-04-06 21:56:17,916:INFO:          setuptools: 65.5.0
2025-04-06 21:56:17,916:INFO:             pycaret: 3.3.2
2025-04-06 21:56:17,916:INFO:             IPython: 8.12.3
2025-04-06 21:56:17,916:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:17,916:INFO:                tqdm: 4.67.1
2025-04-06 21:56:17,916:INFO:               numpy: 1.26.4
2025-04-06 21:56:17,916:INFO:              pandas: 2.1.4
2025-04-06 21:56:17,916:INFO:              jinja2: 3.1.2
2025-04-06 21:56:17,916:INFO:               scipy: 1.11.4
2025-04-06 21:56:17,916:INFO:              joblib: 1.3.2
2025-04-06 21:56:17,916:INFO:             sklearn: 1.4.2
2025-04-06 21:56:17,916:INFO:                pyod: 2.0.3
2025-04-06 21:56:17,916:INFO:            imblearn: 0.13.0
2025-04-06 21:56:17,916:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:17,917:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:17,917:INFO:               numba: 0.61.0
2025-04-06 21:56:17,917:INFO:            requests: 2.32.3
2025-04-06 21:56:17,917:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:17,917:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:17,917:INFO:         yellowbrick: 1.5
2025-04-06 21:56:17,917:INFO:              plotly: 5.24.1
2025-04-06 21:56:17,917:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:17,917:INFO:             kaleido: 0.2.1
2025-04-06 21:56:17,917:INFO:           schemdraw: 0.15
2025-04-06 21:56:17,917:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:17,917:INFO:              sktime: 0.26.0
2025-04-06 21:56:17,917:INFO:               tbats: 1.1.3
2025-04-06 21:56:17,918:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:17,918:INFO:              psutil: 7.0.0
2025-04-06 21:56:17,918:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:17,918:INFO:             pickle5: Not installed
2025-04-06 21:56:17,918:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:17,918:INFO:         deprecation: 2.1.0
2025-04-06 21:56:17,918:INFO:              xxhash: 3.5.0
2025-04-06 21:56:17,918:INFO:           wurlitzer: Not installed
2025-04-06 21:56:17,918:INFO:PyCaret optional dependencies:
2025-04-06 21:56:20,640:INFO:                shap: 0.44.1
2025-04-06 21:56:20,640:INFO:           interpret: 0.6.9
2025-04-06 21:56:20,640:INFO:                umap: 0.5.7
2025-04-06 21:56:20,640:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:20,640:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:20,640:INFO:             autoviz: Not installed
2025-04-06 21:56:20,640:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:20,640:INFO:          deepchecks: Not installed
2025-04-06 21:56:20,640:INFO:             xgboost: Not installed
2025-04-06 21:56:20,640:INFO:            catboost: 1.2.7
2025-04-06 21:56:20,640:INFO:              kmodes: 0.12.2
2025-04-06 21:56:20,640:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:20,640:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:20,640:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:20,640:INFO:                 ray: Not installed
2025-04-06 21:56:20,640:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:20,640:INFO:              optuna: 4.2.1
2025-04-06 21:56:20,640:INFO:               skopt: 0.10.2
2025-04-06 21:56:20,640:INFO:              mlflow: 2.21.0
2025-04-06 21:56:20,640:INFO:              gradio: 5.21.0
2025-04-06 21:56:20,640:INFO:             fastapi: 0.115.11
2025-04-06 21:56:20,640:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:20,640:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:20,640:INFO:           evidently: 0.4.40
2025-04-06 21:56:20,640:INFO:               fugue: 0.8.7
2025-04-06 21:56:20,640:INFO:           streamlit: 1.42.2
2025-04-06 21:56:20,640:INFO:             prophet: Not installed
2025-04-06 21:56:20,640:INFO:None
2025-04-06 21:56:20,640:INFO:Set up data.
2025-04-06 21:56:20,652:INFO:Set up folding strategy.
2025-04-06 21:56:20,652:INFO:Set up train/test split.
2025-04-06 21:56:20,661:INFO:Set up index.
2025-04-06 21:56:20,661:INFO:Assigning column types.
2025-04-06 21:56:20,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:56:20,665:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:20,815:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:20,841:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,847:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:20,989:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:20,989:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:56:20,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,134:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,141:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,147:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,279:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,280:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:56:21,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,427:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,576:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,577:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:56:21,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,722:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,867:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,868:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:56:21,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:22,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,015:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:22,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,161:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,162:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:56:22,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,307:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,450:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,452:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:22,452:INFO:Set up simple imputation.
2025-04-06 21:56:22,455:INFO:Set up encoding of categorical features.
2025-04-06 21:56:30,148:INFO:PyCaret RegressionExperiment
2025-04-06 21:56:30,148:INFO:Logging name: reg-default-name
2025-04-06 21:56:30,148:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:56:30,148:INFO:version 3.3.2
2025-04-06 21:56:30,148:INFO:Initializing setup()
2025-04-06 21:56:30,148:INFO:self.USI: 1c4a
2025-04-06 21:56:30,148:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:30,148:INFO:Checking environment
2025-04-06 21:56:30,148:INFO:python_version: 3.11.4
2025-04-06 21:56:30,148:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:30,148:INFO:machine: AMD64
2025-04-06 21:56:30,149:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:30,153:INFO:Memory: svmem(total=17127211008, available=5154443264, percent=69.9, used=11972767744, free=5154443264)
2025-04-06 21:56:30,153:INFO:Physical Core: 6
2025-04-06 21:56:30,153:INFO:Logical Core: 12
2025-04-06 21:56:30,153:INFO:Checking libraries
2025-04-06 21:56:30,153:INFO:System:
2025-04-06 21:56:30,153:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:30,153:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:30,153:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:30,154:INFO:PyCaret required dependencies:
2025-04-06 21:56:30,154:INFO:                 pip: 25.0.1
2025-04-06 21:56:30,154:INFO:          setuptools: 65.5.0
2025-04-06 21:56:30,154:INFO:             pycaret: 3.3.2
2025-04-06 21:56:30,154:INFO:             IPython: 8.12.3
2025-04-06 21:56:30,154:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:30,154:INFO:                tqdm: 4.67.1
2025-04-06 21:56:30,154:INFO:               numpy: 1.26.4
2025-04-06 21:56:30,154:INFO:              pandas: 2.1.4
2025-04-06 21:56:30,154:INFO:              jinja2: 3.1.2
2025-04-06 21:56:30,154:INFO:               scipy: 1.11.4
2025-04-06 21:56:30,154:INFO:              joblib: 1.3.2
2025-04-06 21:56:30,154:INFO:             sklearn: 1.4.2
2025-04-06 21:56:30,154:INFO:                pyod: 2.0.3
2025-04-06 21:56:30,154:INFO:            imblearn: 0.13.0
2025-04-06 21:56:30,154:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:30,154:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:30,154:INFO:               numba: 0.61.0
2025-04-06 21:56:30,154:INFO:            requests: 2.32.3
2025-04-06 21:56:30,155:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:30,155:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:30,155:INFO:         yellowbrick: 1.5
2025-04-06 21:56:30,155:INFO:              plotly: 5.24.1
2025-04-06 21:56:30,155:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:30,155:INFO:             kaleido: 0.2.1
2025-04-06 21:56:30,155:INFO:           schemdraw: 0.15
2025-04-06 21:56:30,155:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:30,155:INFO:              sktime: 0.26.0
2025-04-06 21:56:30,155:INFO:               tbats: 1.1.3
2025-04-06 21:56:30,155:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:30,155:INFO:              psutil: 7.0.0
2025-04-06 21:56:30,155:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:30,155:INFO:             pickle5: Not installed
2025-04-06 21:56:30,155:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:30,155:INFO:         deprecation: 2.1.0
2025-04-06 21:56:30,155:INFO:              xxhash: 3.5.0
2025-04-06 21:56:30,155:INFO:           wurlitzer: Not installed
2025-04-06 21:56:30,155:INFO:PyCaret optional dependencies:
2025-04-06 21:56:30,155:INFO:                shap: 0.44.1
2025-04-06 21:56:30,156:INFO:           interpret: 0.6.9
2025-04-06 21:56:30,156:INFO:                umap: 0.5.7
2025-04-06 21:56:30,156:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:30,156:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:30,156:INFO:             autoviz: Not installed
2025-04-06 21:56:30,156:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:30,156:INFO:          deepchecks: Not installed
2025-04-06 21:56:30,156:INFO:             xgboost: Not installed
2025-04-06 21:56:30,156:INFO:            catboost: 1.2.7
2025-04-06 21:56:30,156:INFO:              kmodes: 0.12.2
2025-04-06 21:56:30,156:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:30,156:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:30,156:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:30,156:INFO:                 ray: Not installed
2025-04-06 21:56:30,156:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:30,156:INFO:              optuna: 4.2.1
2025-04-06 21:56:30,156:INFO:               skopt: 0.10.2
2025-04-06 21:56:30,156:INFO:              mlflow: 2.21.0
2025-04-06 21:56:30,157:INFO:              gradio: 5.21.0
2025-04-06 21:56:30,157:INFO:             fastapi: 0.115.11
2025-04-06 21:56:30,157:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:30,157:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:30,157:INFO:           evidently: 0.4.40
2025-04-06 21:56:30,157:INFO:               fugue: 0.8.7
2025-04-06 21:56:30,157:INFO:           streamlit: 1.42.2
2025-04-06 21:56:30,157:INFO:             prophet: Not installed
2025-04-06 21:56:30,157:INFO:None
2025-04-06 21:56:30,157:INFO:Set up data.
2025-04-06 21:56:30,168:INFO:Set up folding strategy.
2025-04-06 21:56:30,168:INFO:Set up train/test split.
2025-04-06 21:56:30,177:INFO:Set up index.
2025-04-06 21:56:30,178:INFO:Assigning column types.
2025-04-06 21:56:30,181:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:56:30,182:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,323:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,470:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,470:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:56:30,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,479:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,605:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,761:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,761:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:56:30,774:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,907:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,053:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,054:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:56:31,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,201:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,346:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:56:31,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,493:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,636:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,636:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:56:31,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,780:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,924:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,926:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:31,926:INFO:Set up simple imputation.
2025-04-06 21:56:31,929:INFO:Set up encoding of categorical features.
2025-04-06 21:56:36,370:INFO:PyCaret ClusteringExperiment
2025-04-06 21:56:36,370:INFO:Logging name: cluster-default-name
2025-04-06 21:56:36,370:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:56:36,370:INFO:version 3.3.2
2025-04-06 21:56:36,370:INFO:Initializing setup()
2025-04-06 21:56:36,370:INFO:self.USI: 21a8
2025-04-06 21:56:36,370:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'data', 'memory', 'gpu_param', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'seed', 'logging_param', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:36,370:INFO:Checking environment
2025-04-06 21:56:36,370:INFO:python_version: 3.11.4
2025-04-06 21:56:36,370:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:36,370:INFO:machine: AMD64
2025-04-06 21:56:36,370:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:36,370:INFO:Memory: svmem(total=17127211008, available=5107380224, percent=70.2, used=12019830784, free=5107380224)
2025-04-06 21:56:36,370:INFO:Physical Core: 6
2025-04-06 21:56:36,370:INFO:Logical Core: 12
2025-04-06 21:56:36,370:INFO:Checking libraries
2025-04-06 21:56:36,370:INFO:System:
2025-04-06 21:56:36,370:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:36,370:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:36,370:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:36,370:INFO:PyCaret required dependencies:
2025-04-06 21:56:36,370:INFO:                 pip: 25.0.1
2025-04-06 21:56:36,370:INFO:          setuptools: 65.5.0
2025-04-06 21:56:36,370:INFO:             pycaret: 3.3.2
2025-04-06 21:56:36,370:INFO:             IPython: 8.12.3
2025-04-06 21:56:36,370:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:36,370:INFO:                tqdm: 4.67.1
2025-04-06 21:56:36,370:INFO:               numpy: 1.26.4
2025-04-06 21:56:36,370:INFO:              pandas: 2.1.4
2025-04-06 21:56:36,370:INFO:              jinja2: 3.1.2
2025-04-06 21:56:36,370:INFO:               scipy: 1.11.4
2025-04-06 21:56:36,370:INFO:              joblib: 1.3.2
2025-04-06 21:56:36,370:INFO:             sklearn: 1.4.2
2025-04-06 21:56:36,370:INFO:                pyod: 2.0.3
2025-04-06 21:56:36,370:INFO:            imblearn: 0.13.0
2025-04-06 21:56:36,370:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:36,370:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:36,370:INFO:               numba: 0.61.0
2025-04-06 21:56:36,370:INFO:            requests: 2.32.3
2025-04-06 21:56:36,370:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:36,370:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:36,370:INFO:         yellowbrick: 1.5
2025-04-06 21:56:36,370:INFO:              plotly: 5.24.1
2025-04-06 21:56:36,370:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:36,370:INFO:             kaleido: 0.2.1
2025-04-06 21:56:36,370:INFO:           schemdraw: 0.15
2025-04-06 21:56:36,370:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:36,370:INFO:              sktime: 0.26.0
2025-04-06 21:56:36,370:INFO:               tbats: 1.1.3
2025-04-06 21:56:36,370:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:36,370:INFO:              psutil: 7.0.0
2025-04-06 21:56:36,370:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:36,370:INFO:             pickle5: Not installed
2025-04-06 21:56:36,370:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:36,370:INFO:         deprecation: 2.1.0
2025-04-06 21:56:36,370:INFO:              xxhash: 3.5.0
2025-04-06 21:56:36,370:INFO:           wurlitzer: Not installed
2025-04-06 21:56:36,370:INFO:PyCaret optional dependencies:
2025-04-06 21:56:36,370:INFO:                shap: 0.44.1
2025-04-06 21:56:36,370:INFO:           interpret: 0.6.9
2025-04-06 21:56:36,370:INFO:                umap: 0.5.7
2025-04-06 21:56:36,370:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:36,370:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:36,370:INFO:             autoviz: Not installed
2025-04-06 21:56:36,370:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:36,370:INFO:          deepchecks: Not installed
2025-04-06 21:56:36,370:INFO:             xgboost: Not installed
2025-04-06 21:56:36,370:INFO:            catboost: 1.2.7
2025-04-06 21:56:36,370:INFO:              kmodes: 0.12.2
2025-04-06 21:56:36,370:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:36,370:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:36,370:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:36,370:INFO:                 ray: Not installed
2025-04-06 21:56:36,370:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:36,370:INFO:              optuna: 4.2.1
2025-04-06 21:56:36,370:INFO:               skopt: 0.10.2
2025-04-06 21:56:36,370:INFO:              mlflow: 2.21.0
2025-04-06 21:56:36,370:INFO:              gradio: 5.21.0
2025-04-06 21:56:36,370:INFO:             fastapi: 0.115.11
2025-04-06 21:56:36,370:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:36,370:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:36,370:INFO:           evidently: 0.4.40
2025-04-06 21:56:36,370:INFO:               fugue: 0.8.7
2025-04-06 21:56:36,370:INFO:           streamlit: 1.42.2
2025-04-06 21:56:36,370:INFO:             prophet: Not installed
2025-04-06 21:56:36,370:INFO:None
2025-04-06 21:56:36,370:INFO:Set up data.
2025-04-06 21:56:36,389:INFO:Set up index.
2025-04-06 21:56:36,389:INFO:Assigning column types.
2025-04-06 21:56:36,392:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:56:36,392:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:56:36,392:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,402:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:56:36,402:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,402:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:56:36,403:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,403:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,404:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:36,404:INFO:Set up simple imputation.
2025-04-06 21:56:36,404:INFO:Set up encoding of categorical features.
2025-04-06 21:56:38,825:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2025-04-06 21:56:38,825:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:56:38,832:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'likes',
                                             'dislikes', 'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thu...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=OneHotEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-06 21:56:38,832:INFO:Creating final display dataframe.
2025-04-06 21:56:41,026:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-06 21:56:41,800:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:56:41,808:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape            (1000, 16)
2     Transformed data shape          (1000, 4500)
3           Numeric features                     5
4       Categorical features                     8
5   Rows with missing values                  2.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  cluster-default-name
16                       USI                  21a8
2025-04-06 21:56:41,812:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:41,813:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:41,813:INFO:setup() successfully completed in 5.45s...............
2025-04-06 21:56:41,813:INFO:Initializing create_model()
2025-04-06 21:56:41,813:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024FBA5D0650>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-06 21:56:41,813:INFO:Checking exceptions
2025-04-06 21:56:42,415:INFO:Importing untrained model
2025-04-06 21:56:42,415:INFO:K-Means Clustering Imported successfully
2025-04-06 21:56:42,478:INFO:Fitting Model
2025-04-06 21:56:44,785:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:56:44,786:INFO:create_models() successfully completed......................................
2025-04-06 21:56:44,786:INFO:Uploading results into container
2025-04-06 21:56:44,787:INFO:Uploading model into container now
2025-04-06 21:56:44,794:INFO:_master_model_container: 1
2025-04-06 21:56:44,794:INFO:_display_container: 2
2025-04-06 21:56:44,794:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:56:44,795:INFO:create_model() successfully completed......................................
2025-04-06 21:56:55,188:INFO:Initializing predict_model()
2025-04-06 21:56:55,188:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024FBA5D0650>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-04-06 21:56:56,953:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:57:41,303:INFO:PyCaret RegressionExperiment
2025-04-06 21:57:41,303:INFO:Logging name: reg-default-name
2025-04-06 21:57:41,303:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:57:41,303:INFO:version 3.3.2
2025-04-06 21:57:41,303:INFO:Initializing setup()
2025-04-06 21:57:41,303:INFO:self.USI: 3ef6
2025-04-06 21:57:41,303:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:57:41,303:INFO:Checking environment
2025-04-06 21:57:41,303:INFO:python_version: 3.11.4
2025-04-06 21:57:41,303:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:57:41,304:INFO:machine: AMD64
2025-04-06 21:57:41,304:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:57:41,308:INFO:Memory: svmem(total=17127211008, available=5045952512, percent=70.5, used=12081258496, free=5045952512)
2025-04-06 21:57:41,308:INFO:Physical Core: 6
2025-04-06 21:57:41,308:INFO:Logical Core: 12
2025-04-06 21:57:41,308:INFO:Checking libraries
2025-04-06 21:57:41,308:INFO:System:
2025-04-06 21:57:41,309:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:57:41,309:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:57:41,309:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:57:41,309:INFO:PyCaret required dependencies:
2025-04-06 21:57:41,309:INFO:                 pip: 25.0.1
2025-04-06 21:57:41,309:INFO:          setuptools: 65.5.0
2025-04-06 21:57:41,309:INFO:             pycaret: 3.3.2
2025-04-06 21:57:41,309:INFO:             IPython: 8.12.3
2025-04-06 21:57:41,309:INFO:          ipywidgets: 8.1.5
2025-04-06 21:57:41,309:INFO:                tqdm: 4.67.1
2025-04-06 21:57:41,309:INFO:               numpy: 1.26.4
2025-04-06 21:57:41,309:INFO:              pandas: 2.1.4
2025-04-06 21:57:41,309:INFO:              jinja2: 3.1.2
2025-04-06 21:57:41,309:INFO:               scipy: 1.11.4
2025-04-06 21:57:41,309:INFO:              joblib: 1.3.2
2025-04-06 21:57:41,309:INFO:             sklearn: 1.4.2
2025-04-06 21:57:41,309:INFO:                pyod: 2.0.3
2025-04-06 21:57:41,309:INFO:            imblearn: 0.13.0
2025-04-06 21:57:41,310:INFO:   category_encoders: 2.7.0
2025-04-06 21:57:41,310:INFO:            lightgbm: 4.6.0
2025-04-06 21:57:41,310:INFO:               numba: 0.61.0
2025-04-06 21:57:41,310:INFO:            requests: 2.32.3
2025-04-06 21:57:41,310:INFO:          matplotlib: 3.7.5
2025-04-06 21:57:41,310:INFO:          scikitplot: 0.3.7
2025-04-06 21:57:41,310:INFO:         yellowbrick: 1.5
2025-04-06 21:57:41,310:INFO:              plotly: 5.24.1
2025-04-06 21:57:41,310:INFO:    plotly-resampler: Not installed
2025-04-06 21:57:41,310:INFO:             kaleido: 0.2.1
2025-04-06 21:57:41,310:INFO:           schemdraw: 0.15
2025-04-06 21:57:41,310:INFO:         statsmodels: 0.14.4
2025-04-06 21:57:41,310:INFO:              sktime: 0.26.0
2025-04-06 21:57:41,310:INFO:               tbats: 1.1.3
2025-04-06 21:57:41,310:INFO:            pmdarima: 2.0.4
2025-04-06 21:57:41,310:INFO:              psutil: 7.0.0
2025-04-06 21:57:41,310:INFO:          markupsafe: 2.1.3
2025-04-06 21:57:41,310:INFO:             pickle5: Not installed
2025-04-06 21:57:41,310:INFO:         cloudpickle: 3.1.1
2025-04-06 21:57:41,310:INFO:         deprecation: 2.1.0
2025-04-06 21:57:41,310:INFO:              xxhash: 3.5.0
2025-04-06 21:57:41,311:INFO:           wurlitzer: Not installed
2025-04-06 21:57:41,311:INFO:PyCaret optional dependencies:
2025-04-06 21:57:41,311:INFO:                shap: 0.44.1
2025-04-06 21:57:41,311:INFO:           interpret: 0.6.9
2025-04-06 21:57:41,311:INFO:                umap: 0.5.7
2025-04-06 21:57:41,311:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:57:41,311:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:57:41,311:INFO:             autoviz: Not installed
2025-04-06 21:57:41,311:INFO:           fairlearn: 0.7.0
2025-04-06 21:57:41,311:INFO:          deepchecks: Not installed
2025-04-06 21:57:41,311:INFO:             xgboost: Not installed
2025-04-06 21:57:41,311:INFO:            catboost: 1.2.7
2025-04-06 21:57:41,311:INFO:              kmodes: 0.12.2
2025-04-06 21:57:41,311:INFO:             mlxtend: 0.23.4
2025-04-06 21:57:41,311:INFO:       statsforecast: 1.5.0
2025-04-06 21:57:41,311:INFO:        tune_sklearn: Not installed
2025-04-06 21:57:41,311:INFO:                 ray: Not installed
2025-04-06 21:57:41,311:INFO:            hyperopt: 0.2.7
2025-04-06 21:57:41,312:INFO:              optuna: 4.2.1
2025-04-06 21:57:41,312:INFO:               skopt: 0.10.2
2025-04-06 21:57:41,312:INFO:              mlflow: 2.21.0
2025-04-06 21:57:41,312:INFO:              gradio: 5.21.0
2025-04-06 21:57:41,312:INFO:             fastapi: 0.115.11
2025-04-06 21:57:41,312:INFO:             uvicorn: 0.34.0
2025-04-06 21:57:41,312:INFO:              m2cgen: 0.10.0
2025-04-06 21:57:41,312:INFO:           evidently: 0.4.40
2025-04-06 21:57:41,312:INFO:               fugue: 0.8.7
2025-04-06 21:57:41,312:INFO:           streamlit: 1.42.2
2025-04-06 21:57:41,312:INFO:             prophet: Not installed
2025-04-06 21:57:41,312:INFO:None
2025-04-06 21:57:41,312:INFO:Set up data.
2025-04-06 21:57:41,323:INFO:Set up folding strategy.
2025-04-06 21:57:41,323:INFO:Set up train/test split.
2025-04-06 21:57:41,331:INFO:Set up index.
2025-04-06 21:57:41,331:INFO:Assigning column types.
2025-04-06 21:57:41,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:57:41,335:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,339:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,483:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,484:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,485:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,620:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:57:41,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,635:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,760:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,920:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,921:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:57:41,933:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,069:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,082:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,225:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,225:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:57:42,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,376:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,522:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,523:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:57:42,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,668:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,817:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,819:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:57:42,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,962:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,110:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,112:INFO:Preparing preprocessing pipeline...
2025-04-06 21:57:43,112:INFO:Set up simple imputation.
2025-04-06 21:57:43,115:INFO:Set up encoding of categorical features.
2025-04-06 21:57:43,321:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:57:43,330:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:57:43,330:INFO:Creating final display dataframe.
2025-04-06 21:57:43,595:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1000, 16)
4        Transformed data shape        (1000, 20)
5   Transformed train set shape         (700, 20)
6    Transformed test set shape         (300, 20)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              2.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3ef6
2025-04-06 21:57:43,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,748:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,897:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,898:INFO:setup() successfully completed in 2.61s...............
2025-04-06 21:57:43,898:INFO:Initializing compare_models()
2025-04-06 21:57:43,898:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:57:43,898:INFO:Checking exceptions
2025-04-06 21:57:43,900:INFO:Preparing display monitor
2025-04-06 21:57:43,902:INFO:Initializing Linear Regression
2025-04-06 21:57:43,902:INFO:Total runtime is 0.0 minutes
2025-04-06 21:57:43,903:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:43,903:INFO:Initializing create_model()
2025-04-06 21:57:43,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:43,903:INFO:Checking exceptions
2025-04-06 21:57:43,903:INFO:Importing libraries
2025-04-06 21:57:43,903:INFO:Copying training dataset
2025-04-06 21:57:43,909:INFO:Defining folds
2025-04-06 21:57:43,909:INFO:Declaring metric variables
2025-04-06 21:57:43,909:INFO:Importing untrained model
2025-04-06 21:57:43,909:INFO:Linear Regression Imported successfully
2025-04-06 21:57:43,909:INFO:Starting cross validation
2025-04-06 21:57:43,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:52,179:INFO:Calculating mean and std
2025-04-06 21:57:52,181:INFO:Creating metrics dataframe
2025-04-06 21:57:52,183:INFO:Uploading results into container
2025-04-06 21:57:52,184:INFO:Uploading model into container now
2025-04-06 21:57:52,185:INFO:_master_model_container: 1
2025-04-06 21:57:52,185:INFO:_display_container: 2
2025-04-06 21:57:52,185:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:57:52,185:INFO:create_model() successfully completed......................................
2025-04-06 21:57:52,376:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:52,376:INFO:Creating metrics dataframe
2025-04-06 21:57:52,380:INFO:Initializing Lasso Regression
2025-04-06 21:57:52,381:INFO:Total runtime is 0.14132106701533 minutes
2025-04-06 21:57:52,381:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:52,382:INFO:Initializing create_model()
2025-04-06 21:57:52,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:52,382:INFO:Checking exceptions
2025-04-06 21:57:52,382:INFO:Importing libraries
2025-04-06 21:57:52,382:INFO:Copying training dataset
2025-04-06 21:57:52,391:INFO:Defining folds
2025-04-06 21:57:52,392:INFO:Declaring metric variables
2025-04-06 21:57:52,392:INFO:Importing untrained model
2025-04-06 21:57:52,392:INFO:Lasso Regression Imported successfully
2025-04-06 21:57:52,393:INFO:Starting cross validation
2025-04-06 21:57:52,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:52,663:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,669:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,722:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,730:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,743:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,117:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,157:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,201:INFO:Calculating mean and std
2025-04-06 21:57:57,202:INFO:Creating metrics dataframe
2025-04-06 21:57:57,204:INFO:Uploading results into container
2025-04-06 21:57:57,204:INFO:Uploading model into container now
2025-04-06 21:57:57,205:INFO:_master_model_container: 2
2025-04-06 21:57:57,205:INFO:_display_container: 2
2025-04-06 21:57:57,205:INFO:Lasso(random_state=123)
2025-04-06 21:57:57,205:INFO:create_model() successfully completed......................................
2025-04-06 21:57:57,408:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:57,408:INFO:Creating metrics dataframe
2025-04-06 21:57:57,411:INFO:Initializing Ridge Regression
2025-04-06 21:57:57,411:INFO:Total runtime is 0.22515811522801718 minutes
2025-04-06 21:57:57,411:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:57,411:INFO:Initializing create_model()
2025-04-06 21:57:57,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:57,411:INFO:Checking exceptions
2025-04-06 21:57:57,411:INFO:Importing libraries
2025-04-06 21:57:57,411:INFO:Copying training dataset
2025-04-06 21:57:57,417:INFO:Defining folds
2025-04-06 21:57:57,417:INFO:Declaring metric variables
2025-04-06 21:57:57,417:INFO:Importing untrained model
2025-04-06 21:57:57,417:INFO:Ridge Regression Imported successfully
2025-04-06 21:57:57,418:INFO:Starting cross validation
2025-04-06 21:57:57,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:57,754:INFO:Calculating mean and std
2025-04-06 21:57:57,755:INFO:Creating metrics dataframe
2025-04-06 21:57:57,756:INFO:Uploading results into container
2025-04-06 21:57:57,756:INFO:Uploading model into container now
2025-04-06 21:57:57,756:INFO:_master_model_container: 3
2025-04-06 21:57:57,757:INFO:_display_container: 2
2025-04-06 21:57:57,757:INFO:Ridge(random_state=123)
2025-04-06 21:57:57,757:INFO:create_model() successfully completed......................................
2025-04-06 21:57:57,910:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:57,910:INFO:Creating metrics dataframe
2025-04-06 21:57:57,912:INFO:Initializing Elastic Net
2025-04-06 21:57:57,912:INFO:Total runtime is 0.23349734942118328 minutes
2025-04-06 21:57:57,913:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:57,913:INFO:Initializing create_model()
2025-04-06 21:57:57,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:57,913:INFO:Checking exceptions
2025-04-06 21:57:57,913:INFO:Importing libraries
2025-04-06 21:57:57,913:INFO:Copying training dataset
2025-04-06 21:57:57,917:INFO:Defining folds
2025-04-06 21:57:57,917:INFO:Declaring metric variables
2025-04-06 21:57:57,918:INFO:Importing untrained model
2025-04-06 21:57:57,918:INFO:Elastic Net Imported successfully
2025-04-06 21:57:57,918:INFO:Starting cross validation
2025-04-06 21:57:57,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:58,105:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,111:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,141:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,174:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,176:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,198:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,210:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,239:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,257:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,305:INFO:Calculating mean and std
2025-04-06 21:57:58,305:INFO:Creating metrics dataframe
2025-04-06 21:57:58,307:INFO:Uploading results into container
2025-04-06 21:57:58,307:INFO:Uploading model into container now
2025-04-06 21:57:58,308:INFO:_master_model_container: 4
2025-04-06 21:57:58,308:INFO:_display_container: 2
2025-04-06 21:57:58,308:INFO:ElasticNet(random_state=123)
2025-04-06 21:57:58,308:INFO:create_model() successfully completed......................................
2025-04-06 21:57:58,472:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:58,472:INFO:Creating metrics dataframe
2025-04-06 21:57:58,475:INFO:Initializing Least Angle Regression
2025-04-06 21:57:58,475:INFO:Total runtime is 0.24288624127705893 minutes
2025-04-06 21:57:58,475:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:58,476:INFO:Initializing create_model()
2025-04-06 21:57:58,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:58,476:INFO:Checking exceptions
2025-04-06 21:57:58,476:INFO:Importing libraries
2025-04-06 21:57:58,476:INFO:Copying training dataset
2025-04-06 21:57:58,481:INFO:Defining folds
2025-04-06 21:57:58,481:INFO:Declaring metric variables
2025-04-06 21:57:58,481:INFO:Importing untrained model
2025-04-06 21:57:58,482:INFO:Least Angle Regression Imported successfully
2025-04-06 21:57:58,482:INFO:Starting cross validation
2025-04-06 21:57:58,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:58,707:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.121e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,708:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.120e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,710:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.372e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,711:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.648e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,712:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.431e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,712:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.412e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,713:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.080e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,713:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.567e+02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,714:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.488e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,714:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.301e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,715:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.698e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,716:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.589e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,716:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.551e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.154e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,718:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,718:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.175e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,719:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,719:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,720:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.115e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,720:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.886e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,722:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,723:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,724:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,724:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,733:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,734:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,735:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,737:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.973e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,737:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.309e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,738:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.449e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.946e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.865e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,740:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.290e+02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.199e+05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.387e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.188e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,745:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.513e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,746:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.871e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.958e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.629e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.726e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,748:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.011e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.376e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.339e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.619e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.335e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.127e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,753:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.975e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,753:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.382e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,768:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,768:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,769:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,770:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,770:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.163e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.558e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.913e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.308e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.431e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.113e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.481e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,777:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.429e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,777:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.647e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,778:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.280e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,778:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.331e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,779:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.261e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,780:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.848e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,781:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.208e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,781:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.147e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,785:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,785:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.905e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.210e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.344e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.795e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,790:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.296e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,790:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.561e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.488e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.365e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.342e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,793:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.294e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,794:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.322e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,846:INFO:Calculating mean and std
2025-04-06 21:57:58,847:INFO:Creating metrics dataframe
2025-04-06 21:57:58,848:INFO:Uploading results into container
2025-04-06 21:57:58,849:INFO:Uploading model into container now
2025-04-06 21:57:58,849:INFO:_master_model_container: 5
2025-04-06 21:57:58,849:INFO:_display_container: 2
2025-04-06 21:57:58,850:INFO:Lars(random_state=123)
2025-04-06 21:57:58,850:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,010:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,010:INFO:Creating metrics dataframe
2025-04-06 21:57:59,013:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:57:59,013:INFO:Total runtime is 0.25185402631759646 minutes
2025-04-06 21:57:59,013:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,014:INFO:Initializing create_model()
2025-04-06 21:57:59,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,014:INFO:Checking exceptions
2025-04-06 21:57:59,014:INFO:Importing libraries
2025-04-06 21:57:59,014:INFO:Copying training dataset
2025-04-06 21:57:59,019:INFO:Defining folds
2025-04-06 21:57:59,019:INFO:Declaring metric variables
2025-04-06 21:57:59,019:INFO:Importing untrained model
2025-04-06 21:57:59,019:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:57:59,020:INFO:Starting cross validation
2025-04-06 21:57:59,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:59,188:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.433e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,189:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.215e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,190:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.107e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,192:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.334e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,193:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.969e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,194:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.995e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,195:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.374e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,195:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.355e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.161e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.451e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.079e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,216:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,217:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,217:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,218:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,221:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,268:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,269:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,269:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,270:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,271:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.793e+07, previous alpha=5.163e+03, with an active set of 12 regressors.
  warnings.warn(

2025-04-06 21:57:59,273:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,273:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,276:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.114e+10, previous alpha=6.961e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.029e+10, previous alpha=6.634e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,287:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,288:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,288:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,289:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,289:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,290:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,290:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.894e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.944e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.526e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.799e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.823e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.346e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,293:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.385e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,294:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.498e+08, previous alpha=2.565e+03, with an active set of 14 regressors.
  warnings.warn(

2025-04-06 21:57:59,305:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,307:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=8.178e+09, previous alpha=4.617e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,352:INFO:Calculating mean and std
2025-04-06 21:57:59,353:INFO:Creating metrics dataframe
2025-04-06 21:57:59,355:INFO:Uploading results into container
2025-04-06 21:57:59,355:INFO:Uploading model into container now
2025-04-06 21:57:59,355:INFO:_master_model_container: 6
2025-04-06 21:57:59,356:INFO:_display_container: 2
2025-04-06 21:57:59,356:INFO:LassoLars(random_state=123)
2025-04-06 21:57:59,356:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,512:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,512:INFO:Creating metrics dataframe
2025-04-06 21:57:59,514:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:57:59,514:INFO:Total runtime is 0.26020932594935103 minutes
2025-04-06 21:57:59,515:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,515:INFO:Initializing create_model()
2025-04-06 21:57:59,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,515:INFO:Checking exceptions
2025-04-06 21:57:59,515:INFO:Importing libraries
2025-04-06 21:57:59,515:INFO:Copying training dataset
2025-04-06 21:57:59,520:INFO:Defining folds
2025-04-06 21:57:59,521:INFO:Declaring metric variables
2025-04-06 21:57:59,521:INFO:Importing untrained model
2025-04-06 21:57:59,521:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:57:59,521:INFO:Starting cross validation
2025-04-06 21:57:59,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:59,821:INFO:Calculating mean and std
2025-04-06 21:57:59,822:INFO:Creating metrics dataframe
2025-04-06 21:57:59,823:INFO:Uploading results into container
2025-04-06 21:57:59,824:INFO:Uploading model into container now
2025-04-06 21:57:59,825:INFO:_master_model_container: 7
2025-04-06 21:57:59,825:INFO:_display_container: 2
2025-04-06 21:57:59,825:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:57:59,825:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,980:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,980:INFO:Creating metrics dataframe
2025-04-06 21:57:59,983:INFO:Initializing Bayesian Ridge
2025-04-06 21:57:59,983:INFO:Total runtime is 0.26801386674245203 minutes
2025-04-06 21:57:59,983:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,983:INFO:Initializing create_model()
2025-04-06 21:57:59,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,983:INFO:Checking exceptions
2025-04-06 21:57:59,983:INFO:Importing libraries
2025-04-06 21:57:59,984:INFO:Copying training dataset
2025-04-06 21:57:59,988:INFO:Defining folds
2025-04-06 21:57:59,988:INFO:Declaring metric variables
2025-04-06 21:57:59,988:INFO:Importing untrained model
2025-04-06 21:57:59,989:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:57:59,989:INFO:Starting cross validation
2025-04-06 21:57:59,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:00,325:INFO:Calculating mean and std
2025-04-06 21:58:00,326:INFO:Creating metrics dataframe
2025-04-06 21:58:00,328:INFO:Uploading results into container
2025-04-06 21:58:00,329:INFO:Uploading model into container now
2025-04-06 21:58:00,329:INFO:_master_model_container: 8
2025-04-06 21:58:00,329:INFO:_display_container: 2
2025-04-06 21:58:00,329:INFO:BayesianRidge()
2025-04-06 21:58:00,329:INFO:create_model() successfully completed......................................
2025-04-06 21:58:00,502:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:00,502:INFO:Creating metrics dataframe
2025-04-06 21:58:00,505:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:58:00,505:INFO:Total runtime is 0.27672396103541064 minutes
2025-04-06 21:58:00,505:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:00,505:INFO:Initializing create_model()
2025-04-06 21:58:00,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:00,505:INFO:Checking exceptions
2025-04-06 21:58:00,505:INFO:Importing libraries
2025-04-06 21:58:00,505:INFO:Copying training dataset
2025-04-06 21:58:00,510:INFO:Defining folds
2025-04-06 21:58:00,510:INFO:Declaring metric variables
2025-04-06 21:58:00,510:INFO:Importing untrained model
2025-04-06 21:58:00,511:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:58:00,511:INFO:Starting cross validation
2025-04-06 21:58:00,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:00,829:INFO:Calculating mean and std
2025-04-06 21:58:00,830:INFO:Creating metrics dataframe
2025-04-06 21:58:00,831:INFO:Uploading results into container
2025-04-06 21:58:00,832:INFO:Uploading model into container now
2025-04-06 21:58:00,832:INFO:_master_model_container: 9
2025-04-06 21:58:00,832:INFO:_display_container: 2
2025-04-06 21:58:00,833:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:58:00,833:INFO:create_model() successfully completed......................................
2025-04-06 21:58:00,988:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:00,988:INFO:Creating metrics dataframe
2025-04-06 21:58:00,991:INFO:Initializing Huber Regressor
2025-04-06 21:58:00,991:INFO:Total runtime is 0.28481064240137743 minutes
2025-04-06 21:58:00,991:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:00,991:INFO:Initializing create_model()
2025-04-06 21:58:00,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:00,992:INFO:Checking exceptions
2025-04-06 21:58:00,992:INFO:Importing libraries
2025-04-06 21:58:00,992:INFO:Copying training dataset
2025-04-06 21:58:00,997:INFO:Defining folds
2025-04-06 21:58:00,998:INFO:Declaring metric variables
2025-04-06 21:58:00,998:INFO:Importing untrained model
2025-04-06 21:58:00,998:INFO:Huber Regressor Imported successfully
2025-04-06 21:58:00,998:INFO:Starting cross validation
2025-04-06 21:58:00,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:01,244:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,245:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,250:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,275:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,287:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,314:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,321:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,368:INFO:Calculating mean and std
2025-04-06 21:58:01,369:INFO:Creating metrics dataframe
2025-04-06 21:58:01,370:INFO:Uploading results into container
2025-04-06 21:58:01,371:INFO:Uploading model into container now
2025-04-06 21:58:01,371:INFO:_master_model_container: 10
2025-04-06 21:58:01,371:INFO:_display_container: 2
2025-04-06 21:58:01,371:INFO:HuberRegressor()
2025-04-06 21:58:01,371:INFO:create_model() successfully completed......................................
2025-04-06 21:58:01,553:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:01,554:INFO:Creating metrics dataframe
2025-04-06 21:58:01,556:INFO:Initializing K Neighbors Regressor
2025-04-06 21:58:01,557:INFO:Total runtime is 0.29423513015111297 minutes
2025-04-06 21:58:01,557:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:01,557:INFO:Initializing create_model()
2025-04-06 21:58:01,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:01,557:INFO:Checking exceptions
2025-04-06 21:58:01,557:INFO:Importing libraries
2025-04-06 21:58:01,557:INFO:Copying training dataset
2025-04-06 21:58:01,563:INFO:Defining folds
2025-04-06 21:58:01,563:INFO:Declaring metric variables
2025-04-06 21:58:01,564:INFO:Importing untrained model
2025-04-06 21:58:01,564:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:58:01,564:INFO:Starting cross validation
2025-04-06 21:58:01,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:01,901:INFO:Calculating mean and std
2025-04-06 21:58:01,902:INFO:Creating metrics dataframe
2025-04-06 21:58:01,903:INFO:Uploading results into container
2025-04-06 21:58:01,904:INFO:Uploading model into container now
2025-04-06 21:58:01,904:INFO:_master_model_container: 11
2025-04-06 21:58:01,904:INFO:_display_container: 2
2025-04-06 21:58:01,904:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:58:01,905:INFO:create_model() successfully completed......................................
2025-04-06 21:58:02,062:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:02,062:INFO:Creating metrics dataframe
2025-04-06 21:58:02,065:INFO:Initializing Decision Tree Regressor
2025-04-06 21:58:02,065:INFO:Total runtime is 0.30271740357081106 minutes
2025-04-06 21:58:02,065:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:02,065:INFO:Initializing create_model()
2025-04-06 21:58:02,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:02,065:INFO:Checking exceptions
2025-04-06 21:58:02,065:INFO:Importing libraries
2025-04-06 21:58:02,066:INFO:Copying training dataset
2025-04-06 21:58:02,071:INFO:Defining folds
2025-04-06 21:58:02,071:INFO:Declaring metric variables
2025-04-06 21:58:02,071:INFO:Importing untrained model
2025-04-06 21:58:02,071:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:58:02,072:INFO:Starting cross validation
2025-04-06 21:58:02,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:02,437:INFO:Calculating mean and std
2025-04-06 21:58:02,438:INFO:Creating metrics dataframe
2025-04-06 21:58:02,439:INFO:Uploading results into container
2025-04-06 21:58:02,439:INFO:Uploading model into container now
2025-04-06 21:58:02,439:INFO:_master_model_container: 12
2025-04-06 21:58:02,439:INFO:_display_container: 2
2025-04-06 21:58:02,440:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:58:02,440:INFO:create_model() successfully completed......................................
2025-04-06 21:58:02,609:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:02,610:INFO:Creating metrics dataframe
2025-04-06 21:58:02,612:INFO:Initializing Random Forest Regressor
2025-04-06 21:58:02,612:INFO:Total runtime is 0.3118304769198101 minutes
2025-04-06 21:58:02,612:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:02,613:INFO:Initializing create_model()
2025-04-06 21:58:02,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:02,613:INFO:Checking exceptions
2025-04-06 21:58:02,613:INFO:Importing libraries
2025-04-06 21:58:02,613:INFO:Copying training dataset
2025-04-06 21:58:02,617:INFO:Defining folds
2025-04-06 21:58:02,617:INFO:Declaring metric variables
2025-04-06 21:58:02,617:INFO:Importing untrained model
2025-04-06 21:58:02,618:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:58:02,618:INFO:Starting cross validation
2025-04-06 21:58:02,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:03,916:INFO:Calculating mean and std
2025-04-06 21:58:03,917:INFO:Creating metrics dataframe
2025-04-06 21:58:03,919:INFO:Uploading results into container
2025-04-06 21:58:03,920:INFO:Uploading model into container now
2025-04-06 21:58:03,920:INFO:_master_model_container: 13
2025-04-06 21:58:03,920:INFO:_display_container: 2
2025-04-06 21:58:03,921:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:03,921:INFO:create_model() successfully completed......................................
2025-04-06 21:58:04,100:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:04,100:INFO:Creating metrics dataframe
2025-04-06 21:58:04,103:INFO:Initializing Extra Trees Regressor
2025-04-06 21:58:04,103:INFO:Total runtime is 0.33667778174082447 minutes
2025-04-06 21:58:04,103:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:04,104:INFO:Initializing create_model()
2025-04-06 21:58:04,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:04,104:INFO:Checking exceptions
2025-04-06 21:58:04,104:INFO:Importing libraries
2025-04-06 21:58:04,104:INFO:Copying training dataset
2025-04-06 21:58:04,109:INFO:Defining folds
2025-04-06 21:58:04,109:INFO:Declaring metric variables
2025-04-06 21:58:04,109:INFO:Importing untrained model
2025-04-06 21:58:04,109:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:58:04,110:INFO:Starting cross validation
2025-04-06 21:58:04,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:04,957:INFO:Calculating mean and std
2025-04-06 21:58:04,957:INFO:Creating metrics dataframe
2025-04-06 21:58:04,959:INFO:Uploading results into container
2025-04-06 21:58:04,960:INFO:Uploading model into container now
2025-04-06 21:58:04,960:INFO:_master_model_container: 14
2025-04-06 21:58:04,960:INFO:_display_container: 2
2025-04-06 21:58:04,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:04,961:INFO:create_model() successfully completed......................................
2025-04-06 21:58:05,135:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:05,135:INFO:Creating metrics dataframe
2025-04-06 21:58:05,137:INFO:Initializing AdaBoost Regressor
2025-04-06 21:58:05,138:INFO:Total runtime is 0.3539403637250265 minutes
2025-04-06 21:58:05,138:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:05,138:INFO:Initializing create_model()
2025-04-06 21:58:05,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:05,138:INFO:Checking exceptions
2025-04-06 21:58:05,138:INFO:Importing libraries
2025-04-06 21:58:05,138:INFO:Copying training dataset
2025-04-06 21:58:05,143:INFO:Defining folds
2025-04-06 21:58:05,143:INFO:Declaring metric variables
2025-04-06 21:58:05,143:INFO:Importing untrained model
2025-04-06 21:58:05,143:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:58:05,144:INFO:Starting cross validation
2025-04-06 21:58:05,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:05,662:INFO:Calculating mean and std
2025-04-06 21:58:05,663:INFO:Creating metrics dataframe
2025-04-06 21:58:05,666:INFO:Uploading results into container
2025-04-06 21:58:05,667:INFO:Uploading model into container now
2025-04-06 21:58:05,668:INFO:_master_model_container: 15
2025-04-06 21:58:05,668:INFO:_display_container: 2
2025-04-06 21:58:05,668:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:58:05,668:INFO:create_model() successfully completed......................................
2025-04-06 21:58:05,857:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:05,857:INFO:Creating metrics dataframe
2025-04-06 21:58:05,859:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:58:05,859:INFO:Total runtime is 0.3659558455149333 minutes
2025-04-06 21:58:05,859:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:05,859:INFO:Initializing create_model()
2025-04-06 21:58:05,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:05,859:INFO:Checking exceptions
2025-04-06 21:58:05,859:INFO:Importing libraries
2025-04-06 21:58:05,859:INFO:Copying training dataset
2025-04-06 21:58:05,864:INFO:Defining folds
2025-04-06 21:58:05,864:INFO:Declaring metric variables
2025-04-06 21:58:05,864:INFO:Importing untrained model
2025-04-06 21:58:05,865:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:58:05,865:INFO:Starting cross validation
2025-04-06 21:58:05,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:06,476:INFO:Calculating mean and std
2025-04-06 21:58:06,477:INFO:Creating metrics dataframe
2025-04-06 21:58:06,479:INFO:Uploading results into container
2025-04-06 21:58:06,479:INFO:Uploading model into container now
2025-04-06 21:58:06,479:INFO:_master_model_container: 16
2025-04-06 21:58:06,480:INFO:_display_container: 2
2025-04-06 21:58:06,480:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:58:06,480:INFO:create_model() successfully completed......................................
2025-04-06 21:58:06,651:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:06,651:INFO:Creating metrics dataframe
2025-04-06 21:58:06,654:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:58:06,654:INFO:Total runtime is 0.3792034506797791 minutes
2025-04-06 21:58:06,655:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:06,655:INFO:Initializing create_model()
2025-04-06 21:58:06,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:06,655:INFO:Checking exceptions
2025-04-06 21:58:06,655:INFO:Importing libraries
2025-04-06 21:58:06,655:INFO:Copying training dataset
2025-04-06 21:58:06,661:INFO:Defining folds
2025-04-06 21:58:06,661:INFO:Declaring metric variables
2025-04-06 21:58:06,661:INFO:Importing untrained model
2025-04-06 21:58:06,662:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:58:06,662:INFO:Starting cross validation
2025-04-06 21:58:06,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:07,809:INFO:Calculating mean and std
2025-04-06 21:58:07,810:INFO:Creating metrics dataframe
2025-04-06 21:58:07,811:INFO:Uploading results into container
2025-04-06 21:58:07,812:INFO:Uploading model into container now
2025-04-06 21:58:07,812:INFO:_master_model_container: 17
2025-04-06 21:58:07,812:INFO:_display_container: 2
2025-04-06 21:58:07,813:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:07,813:INFO:create_model() successfully completed......................................
2025-04-06 21:58:07,998:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:07,998:INFO:Creating metrics dataframe
2025-04-06 21:58:08,000:INFO:Initializing CatBoost Regressor
2025-04-06 21:58:08,000:INFO:Total runtime is 0.40164004961649585 minutes
2025-04-06 21:58:08,000:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:08,000:INFO:Initializing create_model()
2025-04-06 21:58:08,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:08,000:INFO:Checking exceptions
2025-04-06 21:58:08,000:INFO:Importing libraries
2025-04-06 21:58:08,001:INFO:Copying training dataset
2025-04-06 21:58:08,006:INFO:Defining folds
2025-04-06 21:58:08,006:INFO:Declaring metric variables
2025-04-06 21:58:08,006:INFO:Importing untrained model
2025-04-06 21:58:08,006:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:58:08,007:INFO:Starting cross validation
2025-04-06 21:58:08,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:17,855:INFO:Calculating mean and std
2025-04-06 21:58:17,856:INFO:Creating metrics dataframe
2025-04-06 21:58:17,858:INFO:Uploading results into container
2025-04-06 21:58:17,859:INFO:Uploading model into container now
2025-04-06 21:58:17,859:INFO:_master_model_container: 18
2025-04-06 21:58:17,859:INFO:_display_container: 2
2025-04-06 21:58:17,859:INFO:<catboost.core.CatBoostRegressor object at 0x0000024FBB172A10>
2025-04-06 21:58:17,860:INFO:create_model() successfully completed......................................
2025-04-06 21:58:18,040:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:18,040:INFO:Creating metrics dataframe
2025-04-06 21:58:18,043:INFO:Initializing Dummy Regressor
2025-04-06 21:58:18,043:INFO:Total runtime is 0.569020446141561 minutes
2025-04-06 21:58:18,043:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:18,044:INFO:Initializing create_model()
2025-04-06 21:58:18,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:18,044:INFO:Checking exceptions
2025-04-06 21:58:18,044:INFO:Importing libraries
2025-04-06 21:58:18,044:INFO:Copying training dataset
2025-04-06 21:58:18,049:INFO:Defining folds
2025-04-06 21:58:18,050:INFO:Declaring metric variables
2025-04-06 21:58:18,050:INFO:Importing untrained model
2025-04-06 21:58:18,050:INFO:Dummy Regressor Imported successfully
2025-04-06 21:58:18,051:INFO:Starting cross validation
2025-04-06 21:58:18,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:18,423:INFO:Calculating mean and std
2025-04-06 21:58:18,424:INFO:Creating metrics dataframe
2025-04-06 21:58:18,426:INFO:Uploading results into container
2025-04-06 21:58:18,426:INFO:Uploading model into container now
2025-04-06 21:58:18,427:INFO:_master_model_container: 19
2025-04-06 21:58:18,427:INFO:_display_container: 2
2025-04-06 21:58:18,427:INFO:DummyRegressor()
2025-04-06 21:58:18,427:INFO:create_model() successfully completed......................................
2025-04-06 21:58:18,634:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:18,635:INFO:Creating metrics dataframe
2025-04-06 21:58:18,639:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:58:18,641:INFO:Initializing create_model()
2025-04-06 21:58:18,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:18,641:INFO:Checking exceptions
2025-04-06 21:58:18,642:INFO:Importing libraries
2025-04-06 21:58:18,642:INFO:Copying training dataset
2025-04-06 21:58:18,647:INFO:Defining folds
2025-04-06 21:58:18,648:INFO:Declaring metric variables
2025-04-06 21:58:18,648:INFO:Importing untrained model
2025-04-06 21:58:18,648:INFO:Declaring custom model
2025-04-06 21:58:18,648:INFO:Huber Regressor Imported successfully
2025-04-06 21:58:18,650:INFO:Cross validation set to False
2025-04-06 21:58:18,650:INFO:Fitting Model
2025-04-06 21:58:18,862:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:18,862:INFO:HuberRegressor()
2025-04-06 21:58:18,862:INFO:create_model() successfully completed......................................
2025-04-06 21:58:19,034:INFO:_master_model_container: 19
2025-04-06 21:58:19,034:INFO:_display_container: 2
2025-04-06 21:58:19,035:INFO:HuberRegressor()
2025-04-06 21:58:19,035:INFO:compare_models() successfully completed......................................
2025-04-06 21:58:44,374:INFO:Initializing predict_model()
2025-04-06 21:58:44,374:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024FBA949260>)
2025-04-06 21:58:44,374:INFO:Checking exceptions
2025-04-06 21:58:44,374:INFO:Preloading libraries
2025-04-06 21:58:44,375:INFO:Set up data.
2025-04-06 21:58:44,386:INFO:Set up index.
2025-04-06 21:58:44,662:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-06 21:59:03,825:INFO:Initializing predict_model()
2025-04-06 21:59:03,825:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024FBB25DE40>)
2025-04-06 21:59:03,825:INFO:Checking exceptions
2025-04-06 21:59:03,825:INFO:Preloading libraries
2025-04-06 21:59:03,825:INFO:Set up data.
2025-04-06 21:59:03,833:INFO:Set up index.
2025-04-06 21:59:03,900:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-20 14:51:55,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 14:51:55,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 14:51:55,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 14:51:55,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 14:52:09,667:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-20 14:52:09,685:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-20 14:52:10,020:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-20 14:55:25,751:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-20 14:55:25,769:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-20 14:55:26,099:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-20 15:24:56,081:INFO:PyCaret ClusteringExperiment
2025-04-20 15:24:56,081:INFO:Logging name: cluster-default-name
2025-04-20 15:24:56,081:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-20 15:24:56,081:INFO:version 3.3.2
2025-04-20 15:24:56,081:INFO:Initializing setup()
2025-04-20 15:24:56,081:INFO:self.USI: 2dd2
2025-04-20 15:24:56,082:INFO:self._variable_keys: {'log_plots_param', 'seed', '_available_plots', 'memory', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'n_jobs_param', 'logging_param', 'exp_id', 'pipeline', 'X', 'data', 'idx', 'USI', 'exp_name_log', '_ml_usecase'}
2025-04-20 15:24:56,082:INFO:Checking environment
2025-04-20 15:24:56,082:INFO:python_version: 3.11.4
2025-04-20 15:24:56,082:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-20 15:24:56,082:INFO:machine: AMD64
2025-04-20 15:24:56,106:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-20 15:24:56,111:INFO:Memory: svmem(total=17127211008, available=7914532864, percent=53.8, used=9212678144, free=7914532864)
2025-04-20 15:24:56,111:INFO:Physical Core: 6
2025-04-20 15:24:56,112:INFO:Logical Core: 12
2025-04-20 15:24:56,112:INFO:Checking libraries
2025-04-20 15:24:56,112:INFO:System:
2025-04-20 15:24:56,112:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-20 15:24:56,112:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-20 15:24:56,112:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-20 15:24:56,112:INFO:PyCaret required dependencies:
2025-04-20 15:24:57,011:INFO:                 pip: 25.0.1
2025-04-20 15:24:57,011:INFO:          setuptools: 65.5.0
2025-04-20 15:24:57,011:INFO:             pycaret: 3.3.2
2025-04-20 15:24:57,011:INFO:             IPython: 8.12.3
2025-04-20 15:24:57,011:INFO:          ipywidgets: 8.1.5
2025-04-20 15:24:57,012:INFO:                tqdm: 4.67.1
2025-04-20 15:24:57,012:INFO:               numpy: 1.26.4
2025-04-20 15:24:57,012:INFO:              pandas: 2.1.4
2025-04-20 15:24:57,012:INFO:              jinja2: 3.1.2
2025-04-20 15:24:57,012:INFO:               scipy: 1.11.4
2025-04-20 15:24:57,012:INFO:              joblib: 1.3.2
2025-04-20 15:24:57,012:INFO:             sklearn: 1.4.2
2025-04-20 15:24:57,012:INFO:                pyod: 2.0.3
2025-04-20 15:24:57,012:INFO:            imblearn: 0.13.0
2025-04-20 15:24:57,012:INFO:   category_encoders: 2.7.0
2025-04-20 15:24:57,012:INFO:            lightgbm: 4.6.0
2025-04-20 15:24:57,012:INFO:               numba: 0.61.0
2025-04-20 15:24:57,012:INFO:            requests: 2.32.3
2025-04-20 15:24:57,012:INFO:          matplotlib: 3.7.5
2025-04-20 15:24:57,012:INFO:          scikitplot: 0.3.7
2025-04-20 15:24:57,012:INFO:         yellowbrick: 1.5
2025-04-20 15:24:57,012:INFO:              plotly: 5.24.1
2025-04-20 15:24:57,012:INFO:    plotly-resampler: Not installed
2025-04-20 15:24:57,013:INFO:             kaleido: 0.2.1
2025-04-20 15:24:57,013:INFO:           schemdraw: 0.15
2025-04-20 15:24:57,013:INFO:         statsmodels: 0.14.4
2025-04-20 15:24:57,013:INFO:              sktime: 0.26.0
2025-04-20 15:24:57,013:INFO:               tbats: 1.1.3
2025-04-20 15:24:57,013:INFO:            pmdarima: 2.0.4
2025-04-20 15:24:57,013:INFO:              psutil: 7.0.0
2025-04-20 15:24:57,013:INFO:          markupsafe: 2.1.3
2025-04-20 15:24:57,013:INFO:             pickle5: Not installed
2025-04-20 15:24:57,013:INFO:         cloudpickle: 3.1.1
2025-04-20 15:24:57,013:INFO:         deprecation: 2.1.0
2025-04-20 15:24:57,013:INFO:              xxhash: 3.5.0
2025-04-20 15:24:57,013:INFO:           wurlitzer: Not installed
2025-04-20 15:24:57,013:INFO:PyCaret optional dependencies:
2025-04-20 15:24:59,934:INFO:                shap: 0.44.1
2025-04-20 15:24:59,934:INFO:           interpret: 0.6.9
2025-04-20 15:24:59,934:INFO:                umap: 0.5.7
2025-04-20 15:24:59,934:INFO:     ydata_profiling: 4.14.0
2025-04-20 15:24:59,934:INFO:  explainerdashboard: 0.4.8
2025-04-20 15:24:59,934:INFO:             autoviz: Not installed
2025-04-20 15:24:59,935:INFO:           fairlearn: 0.7.0
2025-04-20 15:24:59,935:INFO:          deepchecks: Not installed
2025-04-20 15:24:59,935:INFO:             xgboost: Not installed
2025-04-20 15:24:59,935:INFO:            catboost: 1.2.7
2025-04-20 15:24:59,935:INFO:              kmodes: 0.12.2
2025-04-20 15:24:59,935:INFO:             mlxtend: 0.23.4
2025-04-20 15:24:59,935:INFO:       statsforecast: 1.5.0
2025-04-20 15:24:59,935:INFO:        tune_sklearn: Not installed
2025-04-20 15:24:59,935:INFO:                 ray: Not installed
2025-04-20 15:24:59,935:INFO:            hyperopt: 0.2.7
2025-04-20 15:24:59,935:INFO:              optuna: 4.2.1
2025-04-20 15:24:59,935:INFO:               skopt: 0.10.2
2025-04-20 15:24:59,935:INFO:              mlflow: 2.21.0
2025-04-20 15:24:59,935:INFO:              gradio: 5.21.0
2025-04-20 15:24:59,935:INFO:             fastapi: 0.115.11
2025-04-20 15:24:59,935:INFO:             uvicorn: 0.34.0
2025-04-20 15:24:59,935:INFO:              m2cgen: 0.10.0
2025-04-20 15:24:59,935:INFO:           evidently: 0.4.40
2025-04-20 15:24:59,935:INFO:               fugue: 0.8.7
2025-04-20 15:24:59,935:INFO:           streamlit: 1.42.2
2025-04-20 15:24:59,936:INFO:             prophet: Not installed
2025-04-20 15:24:59,936:INFO:None
2025-04-20 15:24:59,936:INFO:Set up data.
2025-04-20 15:25:00,146:INFO:Set up index.
2025-04-20 15:25:00,146:INFO:Assigning column types.
2025-04-20 15:25:00,151:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-20 15:25:00,152:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-20 15:25:00,152:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 15:25:00,170:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-20 15:25:00,170:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 15:25:00,170:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-20 15:25:00,170:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 15:25:00,170:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 15:25:00,172:INFO:Preparing preprocessing pipeline...
2025-04-20 15:25:00,172:INFO:Set up simple imputation.
2025-04-20 15:25:00,182:INFO:Set up encoding of categorical features.
2025-04-20 15:29:02,471:INFO:PyCaret RegressionExperiment
2025-04-20 15:29:02,471:INFO:Logging name: reg-default-name
2025-04-20 15:29:02,473:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-20 15:29:02,473:INFO:version 3.3.2
2025-04-20 15:29:02,475:INFO:Initializing setup()
2025-04-20 15:29:02,476:INFO:self.USI: 785a
2025-04-20 15:29:02,477:INFO:self._variable_keys: {'log_plots_param', 'seed', '_available_plots', 'memory', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'transform_target_param', 'n_jobs_param', 'logging_param', 'fold_generator', 'exp_id', 'fold_groups_param', 'pipeline', 'X', 'data', 'y_train', 'y', 'fold_shuffle_param', 'idx', 'X_test', 'USI', 'exp_name_log', 'y_test', 'X_train', '_ml_usecase', 'target_param'}
2025-04-20 15:29:02,478:INFO:Checking environment
2025-04-20 15:29:02,479:INFO:python_version: 3.11.4
2025-04-20 15:29:02,479:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-20 15:29:02,479:INFO:machine: AMD64
2025-04-20 15:29:02,479:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-20 15:29:02,486:INFO:Memory: svmem(total=17127211008, available=354549760, percent=97.9, used=16772661248, free=354549760)
2025-04-20 15:29:02,488:INFO:Physical Core: 6
2025-04-20 15:29:02,488:INFO:Logical Core: 12
2025-04-20 15:29:02,489:INFO:Checking libraries
2025-04-20 15:29:02,489:INFO:System:
2025-04-20 15:29:02,489:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-20 15:29:02,491:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-20 15:29:02,491:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-20 15:29:02,491:INFO:PyCaret required dependencies:
2025-04-20 15:29:02,491:INFO:                 pip: 25.0.1
2025-04-20 15:29:02,491:INFO:          setuptools: 65.5.0
2025-04-20 15:29:02,492:INFO:             pycaret: 3.3.2
2025-04-20 15:29:02,492:INFO:             IPython: 8.12.3
2025-04-20 15:29:02,492:INFO:          ipywidgets: 8.1.5
2025-04-20 15:29:02,492:INFO:                tqdm: 4.67.1
2025-04-20 15:29:02,493:INFO:               numpy: 1.26.4
2025-04-20 15:29:02,494:INFO:              pandas: 2.1.4
2025-04-20 15:29:02,494:INFO:              jinja2: 3.1.2
2025-04-20 15:29:02,494:INFO:               scipy: 1.11.4
2025-04-20 15:29:02,494:INFO:              joblib: 1.3.2
2025-04-20 15:29:02,494:INFO:             sklearn: 1.4.2
2025-04-20 15:29:02,494:INFO:                pyod: 2.0.3
2025-04-20 15:29:02,494:INFO:            imblearn: 0.13.0
2025-04-20 15:29:02,495:INFO:   category_encoders: 2.7.0
2025-04-20 15:29:02,495:INFO:            lightgbm: 4.6.0
2025-04-20 15:29:02,496:INFO:               numba: 0.61.0
2025-04-20 15:29:02,497:INFO:            requests: 2.32.3
2025-04-20 15:29:02,497:INFO:          matplotlib: 3.7.5
2025-04-20 15:29:02,497:INFO:          scikitplot: 0.3.7
2025-04-20 15:29:02,497:INFO:         yellowbrick: 1.5
2025-04-20 15:29:02,497:INFO:              plotly: 5.24.1
2025-04-20 15:29:02,497:INFO:    plotly-resampler: Not installed
2025-04-20 15:29:02,498:INFO:             kaleido: 0.2.1
2025-04-20 15:29:02,498:INFO:           schemdraw: 0.15
2025-04-20 15:29:02,499:INFO:         statsmodels: 0.14.4
2025-04-20 15:29:02,499:INFO:              sktime: 0.26.0
2025-04-20 15:29:02,499:INFO:               tbats: 1.1.3
2025-04-20 15:29:02,499:INFO:            pmdarima: 2.0.4
2025-04-20 15:29:02,500:INFO:              psutil: 7.0.0
2025-04-20 15:29:02,500:INFO:          markupsafe: 2.1.3
2025-04-20 15:29:02,500:INFO:             pickle5: Not installed
2025-04-20 15:29:02,500:INFO:         cloudpickle: 3.1.1
2025-04-20 15:29:02,500:INFO:         deprecation: 2.1.0
2025-04-20 15:29:02,500:INFO:              xxhash: 3.5.0
2025-04-20 15:29:02,500:INFO:           wurlitzer: Not installed
2025-04-20 15:29:02,502:INFO:PyCaret optional dependencies:
2025-04-20 15:29:02,502:INFO:                shap: 0.44.1
2025-04-20 15:29:02,502:INFO:           interpret: 0.6.9
2025-04-20 15:29:02,503:INFO:                umap: 0.5.7
2025-04-20 15:29:02,503:INFO:     ydata_profiling: 4.14.0
2025-04-20 15:29:02,503:INFO:  explainerdashboard: 0.4.8
2025-04-20 15:29:02,503:INFO:             autoviz: Not installed
2025-04-20 15:29:02,503:INFO:           fairlearn: 0.7.0
2025-04-20 15:29:02,503:INFO:          deepchecks: Not installed
2025-04-20 15:29:02,503:INFO:             xgboost: Not installed
2025-04-20 15:29:02,505:INFO:            catboost: 1.2.7
2025-04-20 15:29:02,505:INFO:              kmodes: 0.12.2
2025-04-20 15:29:02,505:INFO:             mlxtend: 0.23.4
2025-04-20 15:29:02,505:INFO:       statsforecast: 1.5.0
2025-04-20 15:29:02,506:INFO:        tune_sklearn: Not installed
2025-04-20 15:29:02,506:INFO:                 ray: Not installed
2025-04-20 15:29:02,506:INFO:            hyperopt: 0.2.7
2025-04-20 15:29:02,506:INFO:              optuna: 4.2.1
2025-04-20 15:29:02,506:INFO:               skopt: 0.10.2
2025-04-20 15:29:02,508:INFO:              mlflow: 2.21.0
2025-04-20 15:29:02,508:INFO:              gradio: 5.21.0
2025-04-20 15:29:02,508:INFO:             fastapi: 0.115.11
2025-04-20 15:29:02,508:INFO:             uvicorn: 0.34.0
2025-04-20 15:29:02,509:INFO:              m2cgen: 0.10.0
2025-04-20 15:29:02,509:INFO:           evidently: 0.4.40
2025-04-20 15:29:02,509:INFO:               fugue: 0.8.7
2025-04-20 15:29:02,509:INFO:           streamlit: 1.42.2
2025-04-20 15:29:02,509:INFO:             prophet: Not installed
2025-04-20 15:29:02,509:INFO:None
2025-04-20 15:29:02,509:INFO:Set up data.
2025-04-20 15:29:02,853:INFO:Set up folding strategy.
2025-04-20 15:29:02,856:INFO:Set up train/test split.
2025-04-20 15:29:03,152:INFO:Set up index.
2025-04-20 15:29:03,156:INFO:Assigning column types.
2025-04-20 15:29:03,193:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-20 15:29:03,194:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,204:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,211:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:03,438:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:03,673:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,680:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,687:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:03,866:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:03,867:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-20 15:29:03,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:03,998:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:04,073:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:04,084:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,094:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:04,277:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:04,278:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-20 15:29:04,294:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:04,478:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:04,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:04,706:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:04,707:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-20 15:29:04,831:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:04,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:04,902:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:05,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 15:29:05,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:05,105:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,106:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-20 15:29:05,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:05,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:05,304:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-20 15:29:05,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:05,509:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,510:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-20 15:29:05,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:05,714:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:05,906:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:05,911:INFO:Preparing preprocessing pipeline...
2025-04-20 15:29:05,912:INFO:Set up simple imputation.
2025-04-20 15:29:05,960:INFO:Set up encoding of categorical features.
2025-04-20 15:29:09,915:INFO:Finished creating preprocessing pipeline.
2025-04-20 15:29:09,927:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-20 15:29:09,927:INFO:Creating final display dataframe.
2025-04-20 15:29:12,766:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-20 15:29:13,357:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-20 15:29:16,052:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-20 15:29:17,237:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape       (40881, 16)
4        Transformed data shape       (40881, 16)
5   Transformed train set shape       (28616, 16)
6    Transformed test set shape       (12265, 16)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              3.2%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              785a
2025-04-20 15:29:17,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:17,441:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:17,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 15:29:17,608:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-20 15:29:17,609:INFO:setup() successfully completed in 15.2s...............
2025-04-20 15:29:17,610:INFO:Initializing compare_models()
2025-04-20 15:29:17,610:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-20 15:29:17,610:INFO:Checking exceptions
2025-04-20 15:29:17,624:INFO:Preparing display monitor
2025-04-20 15:29:17,633:INFO:Initializing Linear Regression
2025-04-20 15:29:17,633:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-04-20 15:29:17,633:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:17,634:INFO:Initializing create_model()
2025-04-20 15:29:17,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:17,635:INFO:Checking exceptions
2025-04-20 15:29:17,635:INFO:Importing libraries
2025-04-20 15:29:17,635:INFO:Copying training dataset
2025-04-20 15:29:17,675:INFO:Defining folds
2025-04-20 15:29:17,676:INFO:Declaring metric variables
2025-04-20 15:29:17,676:INFO:Importing untrained model
2025-04-20 15:29:17,677:INFO:Linear Regression Imported successfully
2025-04-20 15:29:17,678:INFO:Starting cross validation
2025-04-20 15:29:17,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:29:33,792:INFO:Calculating mean and std
2025-04-20 15:29:33,800:INFO:Creating metrics dataframe
2025-04-20 15:29:33,805:INFO:Uploading results into container
2025-04-20 15:29:33,806:INFO:Uploading model into container now
2025-04-20 15:29:33,807:INFO:_master_model_container: 1
2025-04-20 15:29:33,808:INFO:_display_container: 2
2025-04-20 15:29:33,808:INFO:LinearRegression(n_jobs=-1)
2025-04-20 15:29:33,808:INFO:create_model() successfully completed......................................
2025-04-20 15:29:34,198:INFO:SubProcess create_model() end ==================================
2025-04-20 15:29:34,199:INFO:Creating metrics dataframe
2025-04-20 15:29:34,202:INFO:Initializing Lasso Regression
2025-04-20 15:29:34,203:INFO:Total runtime is 0.2761843601862589 minutes
2025-04-20 15:29:34,203:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:34,204:INFO:Initializing create_model()
2025-04-20 15:29:34,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:34,204:INFO:Checking exceptions
2025-04-20 15:29:34,204:INFO:Importing libraries
2025-04-20 15:29:34,204:INFO:Copying training dataset
2025-04-20 15:29:34,240:INFO:Defining folds
2025-04-20 15:29:34,241:INFO:Declaring metric variables
2025-04-20 15:29:34,241:INFO:Importing untrained model
2025-04-20 15:29:34,242:INFO:Lasso Regression Imported successfully
2025-04-20 15:29:34,242:INFO:Starting cross validation
2025-04-20 15:29:34,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:29:36,854:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+16, tolerance: 2.561e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:37,148:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+16, tolerance: 2.723e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:37,626:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+16, tolerance: 2.501e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:38,155:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e+16, tolerance: 2.765e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:38,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+16, tolerance: 2.496e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:38,699:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+16, tolerance: 2.677e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:39,006:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+16, tolerance: 2.670e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:39,221:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+16, tolerance: 2.718e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:44,254:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e+16, tolerance: 2.603e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:44,270:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+16, tolerance: 2.767e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:44,331:INFO:Calculating mean and std
2025-04-20 15:29:44,332:INFO:Creating metrics dataframe
2025-04-20 15:29:44,335:INFO:Uploading results into container
2025-04-20 15:29:44,336:INFO:Uploading model into container now
2025-04-20 15:29:44,336:INFO:_master_model_container: 2
2025-04-20 15:29:44,336:INFO:_display_container: 2
2025-04-20 15:29:44,337:INFO:Lasso(random_state=123)
2025-04-20 15:29:44,337:INFO:create_model() successfully completed......................................
2025-04-20 15:29:44,625:INFO:SubProcess create_model() end ==================================
2025-04-20 15:29:44,625:INFO:Creating metrics dataframe
2025-04-20 15:29:44,633:INFO:Initializing Ridge Regression
2025-04-20 15:29:44,634:INFO:Total runtime is 0.4500400026639302 minutes
2025-04-20 15:29:44,634:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:44,634:INFO:Initializing create_model()
2025-04-20 15:29:44,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:44,635:INFO:Checking exceptions
2025-04-20 15:29:44,635:INFO:Importing libraries
2025-04-20 15:29:44,635:INFO:Copying training dataset
2025-04-20 15:29:44,669:INFO:Defining folds
2025-04-20 15:29:44,670:INFO:Declaring metric variables
2025-04-20 15:29:44,670:INFO:Importing untrained model
2025-04-20 15:29:44,670:INFO:Ridge Regression Imported successfully
2025-04-20 15:29:44,671:INFO:Starting cross validation
2025-04-20 15:29:44,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:29:49,014:INFO:Calculating mean and std
2025-04-20 15:29:49,016:INFO:Creating metrics dataframe
2025-04-20 15:29:49,020:INFO:Uploading results into container
2025-04-20 15:29:49,021:INFO:Uploading model into container now
2025-04-20 15:29:49,021:INFO:_master_model_container: 3
2025-04-20 15:29:49,021:INFO:_display_container: 2
2025-04-20 15:29:49,022:INFO:Ridge(random_state=123)
2025-04-20 15:29:49,022:INFO:create_model() successfully completed......................................
2025-04-20 15:29:49,274:INFO:SubProcess create_model() end ==================================
2025-04-20 15:29:49,274:INFO:Creating metrics dataframe
2025-04-20 15:29:49,278:INFO:Initializing Elastic Net
2025-04-20 15:29:49,279:INFO:Total runtime is 0.5274531801541645 minutes
2025-04-20 15:29:49,279:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:49,279:INFO:Initializing create_model()
2025-04-20 15:29:49,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:49,279:INFO:Checking exceptions
2025-04-20 15:29:49,280:INFO:Importing libraries
2025-04-20 15:29:49,280:INFO:Copying training dataset
2025-04-20 15:29:49,314:INFO:Defining folds
2025-04-20 15:29:49,314:INFO:Declaring metric variables
2025-04-20 15:29:49,315:INFO:Importing untrained model
2025-04-20 15:29:49,315:INFO:Elastic Net Imported successfully
2025-04-20 15:29:49,315:INFO:Starting cross validation
2025-04-20 15:29:49,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:29:51,672:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+16, tolerance: 2.767e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:52,137:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+16, tolerance: 2.603e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:52,547:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+16, tolerance: 2.561e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:53,146:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e+16, tolerance: 2.723e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:53,526:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+16, tolerance: 2.501e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:53,927:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+16, tolerance: 2.765e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:54,288:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+16, tolerance: 2.496e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:54,427:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+16, tolerance: 2.677e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:54,731:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+16, tolerance: 2.670e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:54,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+16, tolerance: 2.718e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-20 15:29:54,959:INFO:Calculating mean and std
2025-04-20 15:29:54,961:INFO:Creating metrics dataframe
2025-04-20 15:29:54,964:INFO:Uploading results into container
2025-04-20 15:29:54,964:INFO:Uploading model into container now
2025-04-20 15:29:54,965:INFO:_master_model_container: 4
2025-04-20 15:29:54,965:INFO:_display_container: 2
2025-04-20 15:29:54,966:INFO:ElasticNet(random_state=123)
2025-04-20 15:29:54,966:INFO:create_model() successfully completed......................................
2025-04-20 15:29:55,230:INFO:SubProcess create_model() end ==================================
2025-04-20 15:29:55,232:INFO:Creating metrics dataframe
2025-04-20 15:29:55,235:INFO:Initializing Least Angle Regression
2025-04-20 15:29:55,237:INFO:Total runtime is 0.6267509539922077 minutes
2025-04-20 15:29:55,237:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:55,238:INFO:Initializing create_model()
2025-04-20 15:29:55,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:55,238:INFO:Checking exceptions
2025-04-20 15:29:55,240:INFO:Importing libraries
2025-04-20 15:29:55,241:INFO:Copying training dataset
2025-04-20 15:29:55,282:INFO:Defining folds
2025-04-20 15:29:55,282:INFO:Declaring metric variables
2025-04-20 15:29:55,283:INFO:Importing untrained model
2025-04-20 15:29:55,284:INFO:Least Angle Regression Imported successfully
2025-04-20 15:29:55,284:INFO:Starting cross validation
2025-04-20 15:29:55,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:29:59,326:INFO:Calculating mean and std
2025-04-20 15:29:59,328:INFO:Creating metrics dataframe
2025-04-20 15:29:59,331:INFO:Uploading results into container
2025-04-20 15:29:59,332:INFO:Uploading model into container now
2025-04-20 15:29:59,332:INFO:_master_model_container: 5
2025-04-20 15:29:59,333:INFO:_display_container: 2
2025-04-20 15:29:59,335:INFO:Lars(random_state=123)
2025-04-20 15:29:59,336:INFO:create_model() successfully completed......................................
2025-04-20 15:29:59,585:INFO:SubProcess create_model() end ==================================
2025-04-20 15:29:59,585:INFO:Creating metrics dataframe
2025-04-20 15:29:59,589:INFO:Initializing Lasso Least Angle Regression
2025-04-20 15:29:59,589:INFO:Total runtime is 0.6992779572804767 minutes
2025-04-20 15:29:59,589:INFO:SubProcess create_model() called ==================================
2025-04-20 15:29:59,590:INFO:Initializing create_model()
2025-04-20 15:29:59,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:29:59,590:INFO:Checking exceptions
2025-04-20 15:29:59,590:INFO:Importing libraries
2025-04-20 15:29:59,590:INFO:Copying training dataset
2025-04-20 15:29:59,626:INFO:Defining folds
2025-04-20 15:29:59,627:INFO:Declaring metric variables
2025-04-20 15:29:59,627:INFO:Importing untrained model
2025-04-20 15:29:59,627:INFO:Lasso Least Angle Regression Imported successfully
2025-04-20 15:29:59,628:INFO:Starting cross validation
2025-04-20 15:29:59,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:03,650:INFO:Calculating mean and std
2025-04-20 15:30:03,651:INFO:Creating metrics dataframe
2025-04-20 15:30:03,655:INFO:Uploading results into container
2025-04-20 15:30:03,655:INFO:Uploading model into container now
2025-04-20 15:30:03,656:INFO:_master_model_container: 6
2025-04-20 15:30:03,656:INFO:_display_container: 2
2025-04-20 15:30:03,657:INFO:LassoLars(random_state=123)
2025-04-20 15:30:03,657:INFO:create_model() successfully completed......................................
2025-04-20 15:30:03,910:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:03,910:INFO:Creating metrics dataframe
2025-04-20 15:30:03,913:INFO:Initializing Orthogonal Matching Pursuit
2025-04-20 15:30:03,913:INFO:Total runtime is 0.7713468909263609 minutes
2025-04-20 15:30:03,914:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:03,914:INFO:Initializing create_model()
2025-04-20 15:30:03,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:03,914:INFO:Checking exceptions
2025-04-20 15:30:03,914:INFO:Importing libraries
2025-04-20 15:30:03,914:INFO:Copying training dataset
2025-04-20 15:30:03,953:INFO:Defining folds
2025-04-20 15:30:03,954:INFO:Declaring metric variables
2025-04-20 15:30:03,954:INFO:Importing untrained model
2025-04-20 15:30:03,954:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-20 15:30:03,954:INFO:Starting cross validation
2025-04-20 15:30:03,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:07,785:INFO:Calculating mean and std
2025-04-20 15:30:07,786:INFO:Creating metrics dataframe
2025-04-20 15:30:07,789:INFO:Uploading results into container
2025-04-20 15:30:07,790:INFO:Uploading model into container now
2025-04-20 15:30:07,790:INFO:_master_model_container: 7
2025-04-20 15:30:07,791:INFO:_display_container: 2
2025-04-20 15:30:07,791:INFO:OrthogonalMatchingPursuit()
2025-04-20 15:30:07,791:INFO:create_model() successfully completed......................................
2025-04-20 15:30:08,038:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:08,039:INFO:Creating metrics dataframe
2025-04-20 15:30:08,043:INFO:Initializing Bayesian Ridge
2025-04-20 15:30:08,044:INFO:Total runtime is 0.8401922464370726 minutes
2025-04-20 15:30:08,044:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:08,045:INFO:Initializing create_model()
2025-04-20 15:30:08,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:08,045:INFO:Checking exceptions
2025-04-20 15:30:08,045:INFO:Importing libraries
2025-04-20 15:30:08,045:INFO:Copying training dataset
2025-04-20 15:30:08,089:INFO:Defining folds
2025-04-20 15:30:08,090:INFO:Declaring metric variables
2025-04-20 15:30:08,090:INFO:Importing untrained model
2025-04-20 15:30:08,091:INFO:Bayesian Ridge Imported successfully
2025-04-20 15:30:08,091:INFO:Starting cross validation
2025-04-20 15:30:08,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:11,905:INFO:Calculating mean and std
2025-04-20 15:30:11,906:INFO:Creating metrics dataframe
2025-04-20 15:30:11,910:INFO:Uploading results into container
2025-04-20 15:30:11,911:INFO:Uploading model into container now
2025-04-20 15:30:11,911:INFO:_master_model_container: 8
2025-04-20 15:30:11,911:INFO:_display_container: 2
2025-04-20 15:30:11,911:INFO:BayesianRidge()
2025-04-20 15:30:11,912:INFO:create_model() successfully completed......................................
2025-04-20 15:30:12,159:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:12,159:INFO:Creating metrics dataframe
2025-04-20 15:30:12,162:INFO:Initializing Passive Aggressive Regressor
2025-04-20 15:30:12,163:INFO:Total runtime is 0.9088489333788552 minutes
2025-04-20 15:30:12,163:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:12,164:INFO:Initializing create_model()
2025-04-20 15:30:12,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:12,164:INFO:Checking exceptions
2025-04-20 15:30:12,164:INFO:Importing libraries
2025-04-20 15:30:12,164:INFO:Copying training dataset
2025-04-20 15:30:12,199:INFO:Defining folds
2025-04-20 15:30:12,200:INFO:Declaring metric variables
2025-04-20 15:30:12,200:INFO:Importing untrained model
2025-04-20 15:30:12,200:INFO:Passive Aggressive Regressor Imported successfully
2025-04-20 15:30:12,200:INFO:Starting cross validation
2025-04-20 15:30:12,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:16,744:INFO:Calculating mean and std
2025-04-20 15:30:16,744:INFO:Creating metrics dataframe
2025-04-20 15:30:16,747:INFO:Uploading results into container
2025-04-20 15:30:16,749:INFO:Uploading model into container now
2025-04-20 15:30:16,749:INFO:_master_model_container: 9
2025-04-20 15:30:16,750:INFO:_display_container: 2
2025-04-20 15:30:16,750:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-20 15:30:16,750:INFO:create_model() successfully completed......................................
2025-04-20 15:30:17,017:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:17,017:INFO:Creating metrics dataframe
2025-04-20 15:30:17,021:INFO:Initializing Huber Regressor
2025-04-20 15:30:17,022:INFO:Total runtime is 0.989831741650899 minutes
2025-04-20 15:30:17,022:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:17,023:INFO:Initializing create_model()
2025-04-20 15:30:17,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:17,023:INFO:Checking exceptions
2025-04-20 15:30:17,024:INFO:Importing libraries
2025-04-20 15:30:17,024:INFO:Copying training dataset
2025-04-20 15:30:17,067:INFO:Defining folds
2025-04-20 15:30:17,067:INFO:Declaring metric variables
2025-04-20 15:30:17,068:INFO:Importing untrained model
2025-04-20 15:30:17,068:INFO:Huber Regressor Imported successfully
2025-04-20 15:30:17,068:INFO:Starting cross validation
2025-04-20 15:30:17,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:19,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:19,970:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:20,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:21,230:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:21,671:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:21,953:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:22,022:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:22,296:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-20 15:30:22,520:INFO:Calculating mean and std
2025-04-20 15:30:22,521:INFO:Creating metrics dataframe
2025-04-20 15:30:22,525:INFO:Uploading results into container
2025-04-20 15:30:22,525:INFO:Uploading model into container now
2025-04-20 15:30:22,526:INFO:_master_model_container: 10
2025-04-20 15:30:22,527:INFO:_display_container: 2
2025-04-20 15:30:22,527:INFO:HuberRegressor()
2025-04-20 15:30:22,527:INFO:create_model() successfully completed......................................
2025-04-20 15:30:22,783:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:22,784:INFO:Creating metrics dataframe
2025-04-20 15:30:22,786:INFO:Initializing K Neighbors Regressor
2025-04-20 15:30:22,787:INFO:Total runtime is 1.0859116156895954 minutes
2025-04-20 15:30:22,787:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:22,788:INFO:Initializing create_model()
2025-04-20 15:30:22,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:22,788:INFO:Checking exceptions
2025-04-20 15:30:22,788:INFO:Importing libraries
2025-04-20 15:30:22,788:INFO:Copying training dataset
2025-04-20 15:30:22,826:INFO:Defining folds
2025-04-20 15:30:22,827:INFO:Declaring metric variables
2025-04-20 15:30:22,827:INFO:Importing untrained model
2025-04-20 15:30:22,827:INFO:K Neighbors Regressor Imported successfully
2025-04-20 15:30:22,827:INFO:Starting cross validation
2025-04-20 15:30:22,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:27,281:INFO:Calculating mean and std
2025-04-20 15:30:27,282:INFO:Creating metrics dataframe
2025-04-20 15:30:27,286:INFO:Uploading results into container
2025-04-20 15:30:27,287:INFO:Uploading model into container now
2025-04-20 15:30:27,288:INFO:_master_model_container: 11
2025-04-20 15:30:27,288:INFO:_display_container: 2
2025-04-20 15:30:27,288:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-20 15:30:27,288:INFO:create_model() successfully completed......................................
2025-04-20 15:30:27,538:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:27,538:INFO:Creating metrics dataframe
2025-04-20 15:30:27,542:INFO:Initializing Decision Tree Regressor
2025-04-20 15:30:27,543:INFO:Total runtime is 1.1651821891466776 minutes
2025-04-20 15:30:27,543:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:27,544:INFO:Initializing create_model()
2025-04-20 15:30:27,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:27,544:INFO:Checking exceptions
2025-04-20 15:30:27,544:INFO:Importing libraries
2025-04-20 15:30:27,544:INFO:Copying training dataset
2025-04-20 15:30:27,584:INFO:Defining folds
2025-04-20 15:30:27,585:INFO:Declaring metric variables
2025-04-20 15:30:27,585:INFO:Importing untrained model
2025-04-20 15:30:27,585:INFO:Decision Tree Regressor Imported successfully
2025-04-20 15:30:27,585:INFO:Starting cross validation
2025-04-20 15:30:27,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:30:32,210:INFO:Calculating mean and std
2025-04-20 15:30:32,211:INFO:Creating metrics dataframe
2025-04-20 15:30:32,215:INFO:Uploading results into container
2025-04-20 15:30:32,217:INFO:Uploading model into container now
2025-04-20 15:30:32,218:INFO:_master_model_container: 12
2025-04-20 15:30:32,218:INFO:_display_container: 2
2025-04-20 15:30:32,218:INFO:DecisionTreeRegressor(random_state=123)
2025-04-20 15:30:32,218:INFO:create_model() successfully completed......................................
2025-04-20 15:30:32,469:INFO:SubProcess create_model() end ==================================
2025-04-20 15:30:32,470:INFO:Creating metrics dataframe
2025-04-20 15:30:32,475:INFO:Initializing Random Forest Regressor
2025-04-20 15:30:32,476:INFO:Total runtime is 1.2474022229512531 minutes
2025-04-20 15:30:32,476:INFO:SubProcess create_model() called ==================================
2025-04-20 15:30:32,477:INFO:Initializing create_model()
2025-04-20 15:30:32,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:30:32,477:INFO:Checking exceptions
2025-04-20 15:30:32,477:INFO:Importing libraries
2025-04-20 15:30:32,477:INFO:Copying training dataset
2025-04-20 15:30:32,517:INFO:Defining folds
2025-04-20 15:30:32,517:INFO:Declaring metric variables
2025-04-20 15:30:32,517:INFO:Importing untrained model
2025-04-20 15:30:32,519:INFO:Random Forest Regressor Imported successfully
2025-04-20 15:30:32,520:INFO:Starting cross validation
2025-04-20 15:30:32,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:31:21,474:INFO:Calculating mean and std
2025-04-20 15:31:21,475:INFO:Creating metrics dataframe
2025-04-20 15:31:21,480:INFO:Uploading results into container
2025-04-20 15:31:21,481:INFO:Uploading model into container now
2025-04-20 15:31:21,482:INFO:_master_model_container: 13
2025-04-20 15:31:21,482:INFO:_display_container: 2
2025-04-20 15:31:21,482:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-20 15:31:21,484:INFO:create_model() successfully completed......................................
2025-04-20 15:31:21,840:INFO:SubProcess create_model() end ==================================
2025-04-20 15:31:21,841:INFO:Creating metrics dataframe
2025-04-20 15:31:21,847:INFO:Initializing Extra Trees Regressor
2025-04-20 15:31:21,848:INFO:Total runtime is 2.0702634414037067 minutes
2025-04-20 15:31:21,849:INFO:SubProcess create_model() called ==================================
2025-04-20 15:31:21,850:INFO:Initializing create_model()
2025-04-20 15:31:21,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:31:21,850:INFO:Checking exceptions
2025-04-20 15:31:21,850:INFO:Importing libraries
2025-04-20 15:31:21,850:INFO:Copying training dataset
2025-04-20 15:31:21,933:INFO:Defining folds
2025-04-20 15:31:21,933:INFO:Declaring metric variables
2025-04-20 15:31:21,934:INFO:Importing untrained model
2025-04-20 15:31:21,935:INFO:Extra Trees Regressor Imported successfully
2025-04-20 15:31:21,937:INFO:Starting cross validation
2025-04-20 15:31:21,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:31:41,786:INFO:Calculating mean and std
2025-04-20 15:31:41,789:INFO:Creating metrics dataframe
2025-04-20 15:31:41,796:INFO:Uploading results into container
2025-04-20 15:31:41,799:INFO:Uploading model into container now
2025-04-20 15:31:41,800:INFO:_master_model_container: 14
2025-04-20 15:31:41,800:INFO:_display_container: 2
2025-04-20 15:31:41,800:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-20 15:31:41,800:INFO:create_model() successfully completed......................................
2025-04-20 15:31:42,111:INFO:SubProcess create_model() end ==================================
2025-04-20 15:31:42,111:INFO:Creating metrics dataframe
2025-04-20 15:31:42,122:INFO:Initializing AdaBoost Regressor
2025-04-20 15:31:42,124:INFO:Total runtime is 2.4081938902537026 minutes
2025-04-20 15:31:42,124:INFO:SubProcess create_model() called ==================================
2025-04-20 15:31:42,124:INFO:Initializing create_model()
2025-04-20 15:31:42,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:31:42,124:INFO:Checking exceptions
2025-04-20 15:31:42,125:INFO:Importing libraries
2025-04-20 15:31:42,126:INFO:Copying training dataset
2025-04-20 15:31:42,173:INFO:Defining folds
2025-04-20 15:31:42,173:INFO:Declaring metric variables
2025-04-20 15:31:42,174:INFO:Importing untrained model
2025-04-20 15:31:42,174:INFO:AdaBoost Regressor Imported successfully
2025-04-20 15:31:42,174:INFO:Starting cross validation
2025-04-20 15:31:42,180:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:31:49,696:INFO:Calculating mean and std
2025-04-20 15:31:49,699:INFO:Creating metrics dataframe
2025-04-20 15:31:49,702:INFO:Uploading results into container
2025-04-20 15:31:49,704:INFO:Uploading model into container now
2025-04-20 15:31:49,705:INFO:_master_model_container: 15
2025-04-20 15:31:49,707:INFO:_display_container: 2
2025-04-20 15:31:49,707:INFO:AdaBoostRegressor(random_state=123)
2025-04-20 15:31:49,707:INFO:create_model() successfully completed......................................
2025-04-20 15:31:49,965:INFO:SubProcess create_model() end ==================================
2025-04-20 15:31:49,966:INFO:Creating metrics dataframe
2025-04-20 15:31:50,002:INFO:Initializing Gradient Boosting Regressor
2025-04-20 15:31:50,004:INFO:Total runtime is 2.5395386934280393 minutes
2025-04-20 15:31:50,004:INFO:SubProcess create_model() called ==================================
2025-04-20 15:31:50,004:INFO:Initializing create_model()
2025-04-20 15:31:50,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:31:50,004:INFO:Checking exceptions
2025-04-20 15:31:50,004:INFO:Importing libraries
2025-04-20 15:31:50,004:INFO:Copying training dataset
2025-04-20 15:31:50,064:INFO:Defining folds
2025-04-20 15:31:50,064:INFO:Declaring metric variables
2025-04-20 15:31:50,064:INFO:Importing untrained model
2025-04-20 15:31:50,065:INFO:Gradient Boosting Regressor Imported successfully
2025-04-20 15:31:50,065:INFO:Starting cross validation
2025-04-20 15:31:50,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:32:06,990:INFO:Calculating mean and std
2025-04-20 15:32:06,992:INFO:Creating metrics dataframe
2025-04-20 15:32:06,997:INFO:Uploading results into container
2025-04-20 15:32:06,997:INFO:Uploading model into container now
2025-04-20 15:32:06,998:INFO:_master_model_container: 16
2025-04-20 15:32:06,998:INFO:_display_container: 2
2025-04-20 15:32:06,999:INFO:GradientBoostingRegressor(random_state=123)
2025-04-20 15:32:06,999:INFO:create_model() successfully completed......................................
2025-04-20 15:32:07,308:INFO:SubProcess create_model() end ==================================
2025-04-20 15:32:07,308:INFO:Creating metrics dataframe
2025-04-20 15:32:07,312:INFO:Initializing Light Gradient Boosting Machine
2025-04-20 15:32:07,312:INFO:Total runtime is 2.827999973297119 minutes
2025-04-20 15:32:07,312:INFO:SubProcess create_model() called ==================================
2025-04-20 15:32:07,313:INFO:Initializing create_model()
2025-04-20 15:32:07,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:32:07,313:INFO:Checking exceptions
2025-04-20 15:32:07,313:INFO:Importing libraries
2025-04-20 15:32:07,313:INFO:Copying training dataset
2025-04-20 15:32:07,343:INFO:Defining folds
2025-04-20 15:32:07,343:INFO:Declaring metric variables
2025-04-20 15:32:07,344:INFO:Importing untrained model
2025-04-20 15:32:07,345:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-20 15:32:07,345:INFO:Starting cross validation
2025-04-20 15:32:07,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:32:14,594:INFO:Calculating mean and std
2025-04-20 15:32:14,596:INFO:Creating metrics dataframe
2025-04-20 15:32:14,600:INFO:Uploading results into container
2025-04-20 15:32:14,601:INFO:Uploading model into container now
2025-04-20 15:32:14,601:INFO:_master_model_container: 17
2025-04-20 15:32:14,601:INFO:_display_container: 2
2025-04-20 15:32:14,602:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-20 15:32:14,602:INFO:create_model() successfully completed......................................
2025-04-20 15:32:14,937:INFO:SubProcess create_model() end ==================================
2025-04-20 15:32:14,938:INFO:Creating metrics dataframe
2025-04-20 15:32:14,943:INFO:Initializing CatBoost Regressor
2025-04-20 15:32:14,943:INFO:Total runtime is 2.955187475681305 minutes
2025-04-20 15:32:14,943:INFO:SubProcess create_model() called ==================================
2025-04-20 15:32:14,943:INFO:Initializing create_model()
2025-04-20 15:32:14,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:32:14,943:INFO:Checking exceptions
2025-04-20 15:32:14,943:INFO:Importing libraries
2025-04-20 15:32:14,944:INFO:Copying training dataset
2025-04-20 15:32:14,980:INFO:Defining folds
2025-04-20 15:32:14,980:INFO:Declaring metric variables
2025-04-20 15:32:14,980:INFO:Importing untrained model
2025-04-20 15:32:14,999:INFO:CatBoost Regressor Imported successfully
2025-04-20 15:32:14,999:INFO:Starting cross validation
2025-04-20 15:32:15,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:32:44,995:INFO:Calculating mean and std
2025-04-20 15:32:44,999:INFO:Creating metrics dataframe
2025-04-20 15:32:45,004:INFO:Uploading results into container
2025-04-20 15:32:45,005:INFO:Uploading model into container now
2025-04-20 15:32:45,005:INFO:_master_model_container: 18
2025-04-20 15:32:45,005:INFO:_display_container: 2
2025-04-20 15:32:45,005:INFO:<catboost.core.CatBoostRegressor object at 0x0000026934143910>
2025-04-20 15:32:45,005:INFO:create_model() successfully completed......................................
2025-04-20 15:32:45,344:INFO:SubProcess create_model() end ==================================
2025-04-20 15:32:45,345:INFO:Creating metrics dataframe
2025-04-20 15:32:45,355:INFO:Initializing Dummy Regressor
2025-04-20 15:32:45,356:INFO:Total runtime is 3.462073318163554 minutes
2025-04-20 15:32:45,356:INFO:SubProcess create_model() called ==================================
2025-04-20 15:32:45,357:INFO:Initializing create_model()
2025-04-20 15:32:45,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000264B551B150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:32:45,357:INFO:Checking exceptions
2025-04-20 15:32:45,358:INFO:Importing libraries
2025-04-20 15:32:45,358:INFO:Copying training dataset
2025-04-20 15:32:45,417:INFO:Defining folds
2025-04-20 15:32:45,417:INFO:Declaring metric variables
2025-04-20 15:32:45,417:INFO:Importing untrained model
2025-04-20 15:32:45,418:INFO:Dummy Regressor Imported successfully
2025-04-20 15:32:45,418:INFO:Starting cross validation
2025-04-20 15:32:45,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 15:32:50,276:INFO:Calculating mean and std
2025-04-20 15:32:50,277:INFO:Creating metrics dataframe
2025-04-20 15:32:50,281:INFO:Uploading results into container
2025-04-20 15:32:50,282:INFO:Uploading model into container now
2025-04-20 15:32:50,283:INFO:_master_model_container: 19
2025-04-20 15:32:50,283:INFO:_display_container: 2
2025-04-20 15:32:50,283:INFO:DummyRegressor()
2025-04-20 15:32:50,283:INFO:create_model() successfully completed......................................
2025-04-20 15:32:50,564:INFO:SubProcess create_model() end ==================================
2025-04-20 15:32:50,564:INFO:Creating metrics dataframe
2025-04-20 15:32:50,691:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-20 15:32:50,696:INFO:Initializing create_model()
2025-04-20 15:32:50,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-20 15:32:50,698:INFO:Checking exceptions
2025-04-20 15:32:50,699:INFO:Importing libraries
2025-04-20 15:32:50,699:INFO:Copying training dataset
2025-04-20 15:32:50,737:INFO:Defining folds
2025-04-20 15:32:50,737:INFO:Declaring metric variables
2025-04-20 15:32:50,737:INFO:Importing untrained model
2025-04-20 15:32:50,738:INFO:Declaring custom model
2025-04-20 15:32:50,738:INFO:Extra Trees Regressor Imported successfully
2025-04-20 15:32:50,742:INFO:Cross validation set to False
2025-04-20 15:32:50,742:INFO:Fitting Model
2025-04-20 15:32:55,900:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-20 15:32:55,901:INFO:create_model() successfully completed......................................
2025-04-20 15:32:56,293:INFO:_master_model_container: 19
2025-04-20 15:32:56,293:INFO:_display_container: 2
2025-04-20 15:32:56,293:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-20 15:32:56,294:INFO:compare_models() successfully completed......................................
2025-04-20 15:36:15,403:INFO:Initializing predict_model()
2025-04-20 15:36:15,403:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000264B60DDB10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002692B0AC360>)
2025-04-20 15:36:15,403:INFO:Checking exceptions
2025-04-20 15:36:15,403:INFO:Preloading libraries
2025-04-20 15:36:15,409:INFO:Set up data.
2025-04-20 15:36:15,733:INFO:Set up index.
2025-04-20 15:36:19,629:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-20 15:36:20,165:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-20 15:36:20,623:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-20 16:32:02,892:INFO:PyCaret ClassificationExperiment
2025-04-20 16:32:02,893:INFO:Logging name: clf-default-name
2025-04-20 16:32:02,893:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-20 16:32:02,893:INFO:version 3.3.2
2025-04-20 16:32:02,893:INFO:Initializing setup()
2025-04-20 16:32:02,893:INFO:self.USI: 0462
2025-04-20 16:32:02,893:INFO:self._variable_keys: {'log_plots_param', 'seed', '_available_plots', 'memory', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'n_jobs_param', 'logging_param', 'fold_generator', 'exp_id', 'fold_groups_param', 'pipeline', 'X', 'data', 'fix_imbalance', 'y_train', 'y', 'fold_shuffle_param', 'idx', 'X_test', 'USI', 'is_multiclass', 'exp_name_log', 'y_test', 'X_train', '_ml_usecase', 'target_param'}
2025-04-20 16:32:02,893:INFO:Checking environment
2025-04-20 16:32:02,893:INFO:python_version: 3.11.4
2025-04-20 16:32:02,893:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-20 16:32:02,893:INFO:machine: AMD64
2025-04-20 16:32:02,893:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-20 16:32:02,901:INFO:Memory: svmem(total=17127211008, available=7400751104, percent=56.8, used=9726459904, free=7400751104)
2025-04-20 16:32:02,901:INFO:Physical Core: 6
2025-04-20 16:32:02,901:INFO:Logical Core: 12
2025-04-20 16:32:02,901:INFO:Checking libraries
2025-04-20 16:32:02,901:INFO:System:
2025-04-20 16:32:02,901:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-20 16:32:02,901:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-20 16:32:02,901:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-20 16:32:02,901:INFO:PyCaret required dependencies:
2025-04-20 16:32:02,901:INFO:                 pip: 25.0.1
2025-04-20 16:32:02,901:INFO:          setuptools: 65.5.0
2025-04-20 16:32:02,901:INFO:             pycaret: 3.3.2
2025-04-20 16:32:02,901:INFO:             IPython: 8.12.3
2025-04-20 16:32:02,902:INFO:          ipywidgets: 8.1.5
2025-04-20 16:32:02,902:INFO:                tqdm: 4.67.1
2025-04-20 16:32:02,902:INFO:               numpy: 1.26.4
2025-04-20 16:32:02,902:INFO:              pandas: 2.1.4
2025-04-20 16:32:02,902:INFO:              jinja2: 3.1.2
2025-04-20 16:32:02,902:INFO:               scipy: 1.11.4
2025-04-20 16:32:02,902:INFO:              joblib: 1.3.2
2025-04-20 16:32:02,902:INFO:             sklearn: 1.4.2
2025-04-20 16:32:02,902:INFO:                pyod: 2.0.3
2025-04-20 16:32:02,902:INFO:            imblearn: 0.13.0
2025-04-20 16:32:02,902:INFO:   category_encoders: 2.7.0
2025-04-20 16:32:02,902:INFO:            lightgbm: 4.6.0
2025-04-20 16:32:02,902:INFO:               numba: 0.61.0
2025-04-20 16:32:02,902:INFO:            requests: 2.32.3
2025-04-20 16:32:02,902:INFO:          matplotlib: 3.7.5
2025-04-20 16:32:02,902:INFO:          scikitplot: 0.3.7
2025-04-20 16:32:02,902:INFO:         yellowbrick: 1.5
2025-04-20 16:32:02,902:INFO:              plotly: 5.24.1
2025-04-20 16:32:02,903:INFO:    plotly-resampler: Not installed
2025-04-20 16:32:02,903:INFO:             kaleido: 0.2.1
2025-04-20 16:32:02,903:INFO:           schemdraw: 0.15
2025-04-20 16:32:02,903:INFO:         statsmodels: 0.14.4
2025-04-20 16:32:02,903:INFO:              sktime: 0.26.0
2025-04-20 16:32:02,903:INFO:               tbats: 1.1.3
2025-04-20 16:32:02,903:INFO:            pmdarima: 2.0.4
2025-04-20 16:32:02,903:INFO:              psutil: 7.0.0
2025-04-20 16:32:02,903:INFO:          markupsafe: 2.1.3
2025-04-20 16:32:02,903:INFO:             pickle5: Not installed
2025-04-20 16:32:02,903:INFO:         cloudpickle: 3.1.1
2025-04-20 16:32:02,903:INFO:         deprecation: 2.1.0
2025-04-20 16:32:02,903:INFO:              xxhash: 3.5.0
2025-04-20 16:32:02,903:INFO:           wurlitzer: Not installed
2025-04-20 16:32:02,903:INFO:PyCaret optional dependencies:
2025-04-20 16:32:02,903:INFO:                shap: 0.44.1
2025-04-20 16:32:02,903:INFO:           interpret: 0.6.9
2025-04-20 16:32:02,903:INFO:                umap: 0.5.7
2025-04-20 16:32:02,903:INFO:     ydata_profiling: 4.14.0
2025-04-20 16:32:02,904:INFO:  explainerdashboard: 0.4.8
2025-04-20 16:32:02,904:INFO:             autoviz: Not installed
2025-04-20 16:32:02,904:INFO:           fairlearn: 0.7.0
2025-04-20 16:32:02,904:INFO:          deepchecks: Not installed
2025-04-20 16:32:02,904:INFO:             xgboost: Not installed
2025-04-20 16:32:02,904:INFO:            catboost: 1.2.7
2025-04-20 16:32:02,904:INFO:              kmodes: 0.12.2
2025-04-20 16:32:02,904:INFO:             mlxtend: 0.23.4
2025-04-20 16:32:02,904:INFO:       statsforecast: 1.5.0
2025-04-20 16:32:02,904:INFO:        tune_sklearn: Not installed
2025-04-20 16:32:02,904:INFO:                 ray: Not installed
2025-04-20 16:32:02,904:INFO:            hyperopt: 0.2.7
2025-04-20 16:32:02,904:INFO:              optuna: 4.2.1
2025-04-20 16:32:02,904:INFO:               skopt: 0.10.2
2025-04-20 16:32:02,904:INFO:              mlflow: 2.21.0
2025-04-20 16:32:02,904:INFO:              gradio: 5.21.0
2025-04-20 16:32:02,904:INFO:             fastapi: 0.115.11
2025-04-20 16:32:02,904:INFO:             uvicorn: 0.34.0
2025-04-20 16:32:02,904:INFO:              m2cgen: 0.10.0
2025-04-20 16:32:02,904:INFO:           evidently: 0.4.40
2025-04-20 16:32:02,905:INFO:               fugue: 0.8.7
2025-04-20 16:32:02,905:INFO:           streamlit: 1.42.2
2025-04-20 16:32:02,905:INFO:             prophet: Not installed
2025-04-20 16:32:02,905:INFO:None
2025-04-20 16:32:02,905:INFO:Set up data.
2025-04-20 16:32:03,196:INFO:Set up folding strategy.
2025-04-20 16:32:03,196:INFO:Set up train/test split.
2025-04-20 16:32:24,362:INFO:PyCaret ClusteringExperiment
2025-04-20 16:32:24,362:INFO:Logging name: cluster-default-name
2025-04-20 16:32:24,362:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-20 16:32:24,362:INFO:version 3.3.2
2025-04-20 16:32:24,362:INFO:Initializing setup()
2025-04-20 16:32:24,362:INFO:self.USI: 5df2
2025-04-20 16:32:24,362:INFO:self._variable_keys: {'log_plots_param', 'seed', '_available_plots', 'memory', 'html_param', 'gpu_n_jobs_param', 'gpu_param', 'n_jobs_param', 'logging_param', 'exp_id', 'pipeline', 'X', 'data', 'idx', 'USI', 'exp_name_log', '_ml_usecase'}
2025-04-20 16:32:24,362:INFO:Checking environment
2025-04-20 16:32:24,362:INFO:python_version: 3.11.4
2025-04-20 16:32:24,362:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-20 16:32:24,362:INFO:machine: AMD64
2025-04-20 16:32:24,362:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-20 16:32:24,371:INFO:Memory: svmem(total=17127211008, available=7239602176, percent=57.7, used=9887608832, free=7239602176)
2025-04-20 16:32:24,371:INFO:Physical Core: 6
2025-04-20 16:32:24,371:INFO:Logical Core: 12
2025-04-20 16:32:24,371:INFO:Checking libraries
2025-04-20 16:32:24,371:INFO:System:
2025-04-20 16:32:24,371:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-20 16:32:24,371:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-20 16:32:24,371:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-20 16:32:24,372:INFO:PyCaret required dependencies:
2025-04-20 16:32:24,372:INFO:                 pip: 25.0.1
2025-04-20 16:32:24,372:INFO:          setuptools: 65.5.0
2025-04-20 16:32:24,372:INFO:             pycaret: 3.3.2
2025-04-20 16:32:24,372:INFO:             IPython: 8.12.3
2025-04-20 16:32:24,372:INFO:          ipywidgets: 8.1.5
2025-04-20 16:32:24,372:INFO:                tqdm: 4.67.1
2025-04-20 16:32:24,372:INFO:               numpy: 1.26.4
2025-04-20 16:32:24,372:INFO:              pandas: 2.1.4
2025-04-20 16:32:24,372:INFO:              jinja2: 3.1.2
2025-04-20 16:32:24,372:INFO:               scipy: 1.11.4
2025-04-20 16:32:24,372:INFO:              joblib: 1.3.2
2025-04-20 16:32:24,372:INFO:             sklearn: 1.4.2
2025-04-20 16:32:24,372:INFO:                pyod: 2.0.3
2025-04-20 16:32:24,372:INFO:            imblearn: 0.13.0
2025-04-20 16:32:24,372:INFO:   category_encoders: 2.7.0
2025-04-20 16:32:24,372:INFO:            lightgbm: 4.6.0
2025-04-20 16:32:24,372:INFO:               numba: 0.61.0
2025-04-20 16:32:24,373:INFO:            requests: 2.32.3
2025-04-20 16:32:24,373:INFO:          matplotlib: 3.7.5
2025-04-20 16:32:24,373:INFO:          scikitplot: 0.3.7
2025-04-20 16:32:24,373:INFO:         yellowbrick: 1.5
2025-04-20 16:32:24,373:INFO:              plotly: 5.24.1
2025-04-20 16:32:24,373:INFO:    plotly-resampler: Not installed
2025-04-20 16:32:24,373:INFO:             kaleido: 0.2.1
2025-04-20 16:32:24,373:INFO:           schemdraw: 0.15
2025-04-20 16:32:24,373:INFO:         statsmodels: 0.14.4
2025-04-20 16:32:24,373:INFO:              sktime: 0.26.0
2025-04-20 16:32:24,373:INFO:               tbats: 1.1.3
2025-04-20 16:32:24,373:INFO:            pmdarima: 2.0.4
2025-04-20 16:32:24,373:INFO:              psutil: 7.0.0
2025-04-20 16:32:24,373:INFO:          markupsafe: 2.1.3
2025-04-20 16:32:24,373:INFO:             pickle5: Not installed
2025-04-20 16:32:24,373:INFO:         cloudpickle: 3.1.1
2025-04-20 16:32:24,373:INFO:         deprecation: 2.1.0
2025-04-20 16:32:24,373:INFO:              xxhash: 3.5.0
2025-04-20 16:32:24,373:INFO:           wurlitzer: Not installed
2025-04-20 16:32:24,374:INFO:PyCaret optional dependencies:
2025-04-20 16:32:24,374:INFO:                shap: 0.44.1
2025-04-20 16:32:24,374:INFO:           interpret: 0.6.9
2025-04-20 16:32:24,374:INFO:                umap: 0.5.7
2025-04-20 16:32:24,374:INFO:     ydata_profiling: 4.14.0
2025-04-20 16:32:24,374:INFO:  explainerdashboard: 0.4.8
2025-04-20 16:32:24,374:INFO:             autoviz: Not installed
2025-04-20 16:32:24,374:INFO:           fairlearn: 0.7.0
2025-04-20 16:32:24,374:INFO:          deepchecks: Not installed
2025-04-20 16:32:24,374:INFO:             xgboost: Not installed
2025-04-20 16:32:24,374:INFO:            catboost: 1.2.7
2025-04-20 16:32:24,374:INFO:              kmodes: 0.12.2
2025-04-20 16:32:24,374:INFO:             mlxtend: 0.23.4
2025-04-20 16:32:24,374:INFO:       statsforecast: 1.5.0
2025-04-20 16:32:24,374:INFO:        tune_sklearn: Not installed
2025-04-20 16:32:24,374:INFO:                 ray: Not installed
2025-04-20 16:32:24,374:INFO:            hyperopt: 0.2.7
2025-04-20 16:32:24,374:INFO:              optuna: 4.2.1
2025-04-20 16:32:24,375:INFO:               skopt: 0.10.2
2025-04-20 16:32:24,375:INFO:              mlflow: 2.21.0
2025-04-20 16:32:24,375:INFO:              gradio: 5.21.0
2025-04-20 16:32:24,375:INFO:             fastapi: 0.115.11
2025-04-20 16:32:24,375:INFO:             uvicorn: 0.34.0
2025-04-20 16:32:24,375:INFO:              m2cgen: 0.10.0
2025-04-20 16:32:24,375:INFO:           evidently: 0.4.40
2025-04-20 16:32:24,375:INFO:               fugue: 0.8.7
2025-04-20 16:32:24,375:INFO:           streamlit: 1.42.2
2025-04-20 16:32:24,375:INFO:             prophet: Not installed
2025-04-20 16:32:24,375:INFO:None
2025-04-20 16:32:24,376:INFO:Set up data.
2025-04-20 16:32:24,667:INFO:Set up index.
2025-04-20 16:32:24,668:INFO:Assigning column types.
2025-04-20 16:32:24,678:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-20 16:32:24,678:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-20 16:32:24,678:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 16:32:24,679:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-20 16:32:24,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 16:32:24,679:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-20 16:32:24,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 16:32:24,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-20 16:32:24,680:INFO:Preparing preprocessing pipeline...
2025-04-20 16:32:24,681:INFO:Set up simple imputation.
2025-04-20 16:32:24,697:INFO:Set up encoding of categorical features.
2025-04-20 16:59:23,683:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-20 16:59:23,706:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-20 16:59:24,057:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:10:28,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:10:28,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:10:28,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:10:28,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:10:38,592:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:10:38,610:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:10:38,956:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:23:20,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:23:20,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:23:20,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:23:20,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:23:28,849:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:23:28,869:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:23:29,201:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:31:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:31:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:31:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:31:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 21:31:40,225:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:31:40,246:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:31:40,602:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:34:20,924:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:34:20,940:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:34:21,263:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:40:07,542:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:40:07,565:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:40:07,901:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:41:27,424:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:41:27,442:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:41:27,772:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:57:22,441:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:57:22,459:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:57:22,789:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:58:08,252:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:58:08,270:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:58:08,602:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:58:35,808:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:58:35,825:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:58:36,162:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:58:36,755:INFO:PyCaret ClassificationExperiment
2025-06-15 21:58:36,755:INFO:Logging name: clf-default-name
2025-06-15 21:58:36,755:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 21:58:36,755:INFO:version 3.3.2
2025-06-15 21:58:36,756:INFO:Initializing setup()
2025-06-15 21:58:36,756:INFO:self.USI: 420f
2025-06-15 21:58:36,756:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 21:58:36,756:INFO:Checking environment
2025-06-15 21:58:36,756:INFO:python_version: 3.11.4
2025-06-15 21:58:36,756:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 21:58:36,756:INFO:machine: AMD64
2025-06-15 21:58:36,766:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 21:58:36,771:INFO:Memory: svmem(total=17127211008, available=5963464704, percent=65.2, used=11163746304, free=5963464704)
2025-06-15 21:58:36,772:INFO:Physical Core: 6
2025-06-15 21:58:36,772:INFO:Logical Core: 12
2025-06-15 21:58:36,772:INFO:Checking libraries
2025-06-15 21:58:36,772:INFO:System:
2025-06-15 21:58:36,772:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 21:58:36,772:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 21:58:36,772:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 21:58:36,772:INFO:PyCaret required dependencies:
2025-06-15 21:58:36,809:INFO:                 pip: 25.1.1
2025-06-15 21:58:36,809:INFO:          setuptools: 65.5.0
2025-06-15 21:58:36,809:INFO:             pycaret: 3.3.2
2025-06-15 21:58:36,809:INFO:             IPython: 9.3.0
2025-06-15 21:58:36,810:INFO:          ipywidgets: 8.1.7
2025-06-15 21:58:36,810:INFO:                tqdm: 4.67.1
2025-06-15 21:58:36,810:INFO:               numpy: 1.26.4
2025-06-15 21:58:36,810:INFO:              pandas: 2.1.4
2025-06-15 21:58:36,810:INFO:              jinja2: 3.1.6
2025-06-15 21:58:36,810:INFO:               scipy: 1.11.4
2025-06-15 21:58:36,810:INFO:              joblib: 1.3.2
2025-06-15 21:58:36,810:INFO:             sklearn: 1.4.2
2025-06-15 21:58:36,810:INFO:                pyod: 2.0.5
2025-06-15 21:58:36,810:INFO:            imblearn: 0.13.0
2025-06-15 21:58:36,810:INFO:   category_encoders: 2.7.0
2025-06-15 21:58:36,810:INFO:            lightgbm: 4.6.0
2025-06-15 21:58:36,810:INFO:               numba: 0.61.2
2025-06-15 21:58:36,810:INFO:            requests: 2.32.4
2025-06-15 21:58:36,810:INFO:          matplotlib: 3.7.5
2025-06-15 21:58:36,810:INFO:          scikitplot: 0.3.7
2025-06-15 21:58:36,810:INFO:         yellowbrick: 1.5
2025-06-15 21:58:36,810:INFO:              plotly: 5.24.1
2025-06-15 21:58:36,810:INFO:    plotly-resampler: Not installed
2025-06-15 21:58:36,810:INFO:             kaleido: 0.2.1
2025-06-15 21:58:36,811:INFO:           schemdraw: 0.15
2025-06-15 21:58:36,811:INFO:         statsmodels: 0.14.4
2025-06-15 21:58:36,811:INFO:              sktime: 0.26.0
2025-06-15 21:58:36,811:INFO:               tbats: 1.1.3
2025-06-15 21:58:36,811:INFO:            pmdarima: 2.0.4
2025-06-15 21:58:36,811:INFO:              psutil: 7.0.0
2025-06-15 21:58:36,811:INFO:          markupsafe: 3.0.2
2025-06-15 21:58:36,811:INFO:             pickle5: Not installed
2025-06-15 21:58:36,811:INFO:         cloudpickle: 3.1.1
2025-06-15 21:58:36,811:INFO:         deprecation: 2.1.0
2025-06-15 21:58:36,811:INFO:              xxhash: 3.5.0
2025-06-15 21:58:36,811:INFO:           wurlitzer: Not installed
2025-06-15 21:58:36,811:INFO:PyCaret optional dependencies:
2025-06-15 21:58:36,846:INFO:                shap: Not installed
2025-06-15 21:58:36,846:INFO:           interpret: Not installed
2025-06-15 21:58:36,846:INFO:                umap: Not installed
2025-06-15 21:58:36,846:INFO:     ydata_profiling: Not installed
2025-06-15 21:58:36,846:INFO:  explainerdashboard: Not installed
2025-06-15 21:58:36,846:INFO:             autoviz: Not installed
2025-06-15 21:58:36,846:INFO:           fairlearn: Not installed
2025-06-15 21:58:36,846:INFO:          deepchecks: Not installed
2025-06-15 21:58:36,846:INFO:             xgboost: Not installed
2025-06-15 21:58:36,846:INFO:            catboost: Not installed
2025-06-15 21:58:36,846:INFO:              kmodes: Not installed
2025-06-15 21:58:36,846:INFO:             mlxtend: Not installed
2025-06-15 21:58:36,846:INFO:       statsforecast: Not installed
2025-06-15 21:58:36,846:INFO:        tune_sklearn: Not installed
2025-06-15 21:58:36,846:INFO:                 ray: Not installed
2025-06-15 21:58:36,846:INFO:            hyperopt: Not installed
2025-06-15 21:58:36,847:INFO:              optuna: Not installed
2025-06-15 21:58:36,847:INFO:               skopt: Not installed
2025-06-15 21:58:36,847:INFO:              mlflow: Not installed
2025-06-15 21:58:36,847:INFO:              gradio: Not installed
2025-06-15 21:58:36,847:INFO:             fastapi: Not installed
2025-06-15 21:58:36,847:INFO:             uvicorn: Not installed
2025-06-15 21:58:36,847:INFO:              m2cgen: Not installed
2025-06-15 21:58:36,847:INFO:           evidently: Not installed
2025-06-15 21:58:36,847:INFO:               fugue: Not installed
2025-06-15 21:58:36,847:INFO:           streamlit: 1.42.2
2025-06-15 21:58:36,847:INFO:             prophet: Not installed
2025-06-15 21:58:36,847:INFO:None
2025-06-15 21:58:36,847:INFO:Set up data.
2025-06-15 21:58:37,025:INFO:Set up folding strategy.
2025-06-15 21:58:37,025:INFO:Set up train/test split.
2025-06-15 21:58:44,511:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:58:44,531:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:58:44,885:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:58:53,450:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:58:53,467:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:58:53,789:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:58:54,368:INFO:PyCaret ClassificationExperiment
2025-06-15 21:58:54,368:INFO:Logging name: clf-default-name
2025-06-15 21:58:54,368:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 21:58:54,368:INFO:version 3.3.2
2025-06-15 21:58:54,368:INFO:Initializing setup()
2025-06-15 21:58:54,368:INFO:self.USI: fb78
2025-06-15 21:58:54,368:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 21:58:54,369:INFO:Checking environment
2025-06-15 21:58:54,369:INFO:python_version: 3.11.4
2025-06-15 21:58:54,369:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 21:58:54,369:INFO:machine: AMD64
2025-06-15 21:58:54,369:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 21:58:54,373:INFO:Memory: svmem(total=17127211008, available=5930061824, percent=65.4, used=11197149184, free=5930061824)
2025-06-15 21:58:54,373:INFO:Physical Core: 6
2025-06-15 21:58:54,373:INFO:Logical Core: 12
2025-06-15 21:58:54,373:INFO:Checking libraries
2025-06-15 21:58:54,373:INFO:System:
2025-06-15 21:58:54,373:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 21:58:54,373:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 21:58:54,374:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 21:58:54,374:INFO:PyCaret required dependencies:
2025-06-15 21:58:54,374:INFO:                 pip: 25.1.1
2025-06-15 21:58:54,374:INFO:          setuptools: 65.5.0
2025-06-15 21:58:54,374:INFO:             pycaret: 3.3.2
2025-06-15 21:58:54,374:INFO:             IPython: 9.3.0
2025-06-15 21:58:54,374:INFO:          ipywidgets: 8.1.7
2025-06-15 21:58:54,374:INFO:                tqdm: 4.67.1
2025-06-15 21:58:54,374:INFO:               numpy: 1.26.4
2025-06-15 21:58:54,374:INFO:              pandas: 2.1.4
2025-06-15 21:58:54,374:INFO:              jinja2: 3.1.6
2025-06-15 21:58:54,374:INFO:               scipy: 1.11.4
2025-06-15 21:58:54,374:INFO:              joblib: 1.3.2
2025-06-15 21:58:54,374:INFO:             sklearn: 1.4.2
2025-06-15 21:58:54,374:INFO:                pyod: 2.0.5
2025-06-15 21:58:54,374:INFO:            imblearn: 0.13.0
2025-06-15 21:58:54,375:INFO:   category_encoders: 2.7.0
2025-06-15 21:58:54,375:INFO:            lightgbm: 4.6.0
2025-06-15 21:58:54,375:INFO:               numba: 0.61.2
2025-06-15 21:58:54,375:INFO:            requests: 2.32.4
2025-06-15 21:58:54,375:INFO:          matplotlib: 3.7.5
2025-06-15 21:58:54,375:INFO:          scikitplot: 0.3.7
2025-06-15 21:58:54,375:INFO:         yellowbrick: 1.5
2025-06-15 21:58:54,375:INFO:              plotly: 5.24.1
2025-06-15 21:58:54,375:INFO:    plotly-resampler: Not installed
2025-06-15 21:58:54,375:INFO:             kaleido: 0.2.1
2025-06-15 21:58:54,375:INFO:           schemdraw: 0.15
2025-06-15 21:58:54,375:INFO:         statsmodels: 0.14.4
2025-06-15 21:58:54,375:INFO:              sktime: 0.26.0
2025-06-15 21:58:54,375:INFO:               tbats: 1.1.3
2025-06-15 21:58:54,375:INFO:            pmdarima: 2.0.4
2025-06-15 21:58:54,375:INFO:              psutil: 7.0.0
2025-06-15 21:58:54,375:INFO:          markupsafe: 3.0.2
2025-06-15 21:58:54,375:INFO:             pickle5: Not installed
2025-06-15 21:58:54,375:INFO:         cloudpickle: 3.1.1
2025-06-15 21:58:54,376:INFO:         deprecation: 2.1.0
2025-06-15 21:58:54,376:INFO:              xxhash: 3.5.0
2025-06-15 21:58:54,376:INFO:           wurlitzer: Not installed
2025-06-15 21:58:54,376:INFO:PyCaret optional dependencies:
2025-06-15 21:58:54,376:INFO:                shap: Not installed
2025-06-15 21:58:54,376:INFO:           interpret: Not installed
2025-06-15 21:58:54,376:INFO:                umap: Not installed
2025-06-15 21:58:54,376:INFO:     ydata_profiling: Not installed
2025-06-15 21:58:54,376:INFO:  explainerdashboard: Not installed
2025-06-15 21:58:54,376:INFO:             autoviz: Not installed
2025-06-15 21:58:54,376:INFO:           fairlearn: Not installed
2025-06-15 21:58:54,376:INFO:          deepchecks: Not installed
2025-06-15 21:58:54,376:INFO:             xgboost: Not installed
2025-06-15 21:58:54,376:INFO:            catboost: Not installed
2025-06-15 21:58:54,376:INFO:              kmodes: Not installed
2025-06-15 21:58:54,376:INFO:             mlxtend: Not installed
2025-06-15 21:58:54,376:INFO:       statsforecast: Not installed
2025-06-15 21:58:54,377:INFO:        tune_sklearn: Not installed
2025-06-15 21:58:54,377:INFO:                 ray: Not installed
2025-06-15 21:58:54,377:INFO:            hyperopt: Not installed
2025-06-15 21:58:54,377:INFO:              optuna: Not installed
2025-06-15 21:58:54,377:INFO:               skopt: Not installed
2025-06-15 21:58:54,377:INFO:              mlflow: Not installed
2025-06-15 21:58:54,377:INFO:              gradio: Not installed
2025-06-15 21:58:54,377:INFO:             fastapi: Not installed
2025-06-15 21:58:54,377:INFO:             uvicorn: Not installed
2025-06-15 21:58:54,377:INFO:              m2cgen: Not installed
2025-06-15 21:58:54,377:INFO:           evidently: Not installed
2025-06-15 21:58:54,378:INFO:               fugue: Not installed
2025-06-15 21:58:54,378:INFO:           streamlit: 1.42.2
2025-06-15 21:58:54,378:INFO:             prophet: Not installed
2025-06-15 21:58:54,378:INFO:None
2025-06-15 21:58:54,378:INFO:Set up data.
2025-06-15 21:58:54,557:INFO:Set up folding strategy.
2025-06-15 21:58:54,557:INFO:Set up train/test split.
2025-06-15 21:59:04,088:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:04,107:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:04,428:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:15,220:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:15,238:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:15,563:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:29,107:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:29,123:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:29,478:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:38,890:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:38,906:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:39,248:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:46,056:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:46,072:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:46,391:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:53,033:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 21:59:53,050:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 21:59:53,371:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 21:59:53,951:INFO:PyCaret ClassificationExperiment
2025-06-15 21:59:53,951:INFO:Logging name: clf-default-name
2025-06-15 21:59:53,951:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 21:59:53,951:INFO:version 3.3.2
2025-06-15 21:59:53,951:INFO:Initializing setup()
2025-06-15 21:59:53,951:INFO:self.USI: 8ca9
2025-06-15 21:59:53,951:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 21:59:53,951:INFO:Checking environment
2025-06-15 21:59:53,952:INFO:python_version: 3.11.4
2025-06-15 21:59:53,952:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 21:59:53,952:INFO:machine: AMD64
2025-06-15 21:59:53,952:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 21:59:53,956:INFO:Memory: svmem(total=17127211008, available=5905309696, percent=65.5, used=11221901312, free=5905309696)
2025-06-15 21:59:53,956:INFO:Physical Core: 6
2025-06-15 21:59:53,956:INFO:Logical Core: 12
2025-06-15 21:59:53,956:INFO:Checking libraries
2025-06-15 21:59:53,956:INFO:System:
2025-06-15 21:59:53,956:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 21:59:53,956:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 21:59:53,957:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 21:59:53,957:INFO:PyCaret required dependencies:
2025-06-15 21:59:53,957:INFO:                 pip: 25.1.1
2025-06-15 21:59:53,957:INFO:          setuptools: 65.5.0
2025-06-15 21:59:53,957:INFO:             pycaret: 3.3.2
2025-06-15 21:59:53,957:INFO:             IPython: 9.3.0
2025-06-15 21:59:53,957:INFO:          ipywidgets: 8.1.7
2025-06-15 21:59:53,957:INFO:                tqdm: 4.67.1
2025-06-15 21:59:53,957:INFO:               numpy: 1.26.4
2025-06-15 21:59:53,957:INFO:              pandas: 2.1.4
2025-06-15 21:59:53,957:INFO:              jinja2: 3.1.6
2025-06-15 21:59:53,957:INFO:               scipy: 1.11.4
2025-06-15 21:59:53,957:INFO:              joblib: 1.3.2
2025-06-15 21:59:53,957:INFO:             sklearn: 1.4.2
2025-06-15 21:59:53,957:INFO:                pyod: 2.0.5
2025-06-15 21:59:53,957:INFO:            imblearn: 0.13.0
2025-06-15 21:59:53,957:INFO:   category_encoders: 2.7.0
2025-06-15 21:59:53,957:INFO:            lightgbm: 4.6.0
2025-06-15 21:59:53,958:INFO:               numba: 0.61.2
2025-06-15 21:59:53,958:INFO:            requests: 2.32.4
2025-06-15 21:59:53,958:INFO:          matplotlib: 3.7.5
2025-06-15 21:59:53,958:INFO:          scikitplot: 0.3.7
2025-06-15 21:59:53,958:INFO:         yellowbrick: 1.5
2025-06-15 21:59:53,958:INFO:              plotly: 5.24.1
2025-06-15 21:59:53,958:INFO:    plotly-resampler: Not installed
2025-06-15 21:59:53,958:INFO:             kaleido: 0.2.1
2025-06-15 21:59:53,958:INFO:           schemdraw: 0.15
2025-06-15 21:59:53,958:INFO:         statsmodels: 0.14.4
2025-06-15 21:59:53,958:INFO:              sktime: 0.26.0
2025-06-15 21:59:53,958:INFO:               tbats: 1.1.3
2025-06-15 21:59:53,958:INFO:            pmdarima: 2.0.4
2025-06-15 21:59:53,958:INFO:              psutil: 7.0.0
2025-06-15 21:59:53,958:INFO:          markupsafe: 3.0.2
2025-06-15 21:59:53,958:INFO:             pickle5: Not installed
2025-06-15 21:59:53,958:INFO:         cloudpickle: 3.1.1
2025-06-15 21:59:53,958:INFO:         deprecation: 2.1.0
2025-06-15 21:59:53,958:INFO:              xxhash: 3.5.0
2025-06-15 21:59:53,959:INFO:           wurlitzer: Not installed
2025-06-15 21:59:53,959:INFO:PyCaret optional dependencies:
2025-06-15 21:59:53,959:INFO:                shap: Not installed
2025-06-15 21:59:53,959:INFO:           interpret: Not installed
2025-06-15 21:59:53,959:INFO:                umap: Not installed
2025-06-15 21:59:53,959:INFO:     ydata_profiling: Not installed
2025-06-15 21:59:53,959:INFO:  explainerdashboard: Not installed
2025-06-15 21:59:53,959:INFO:             autoviz: Not installed
2025-06-15 21:59:53,959:INFO:           fairlearn: Not installed
2025-06-15 21:59:53,959:INFO:          deepchecks: Not installed
2025-06-15 21:59:53,959:INFO:             xgboost: Not installed
2025-06-15 21:59:53,959:INFO:            catboost: Not installed
2025-06-15 21:59:53,959:INFO:              kmodes: Not installed
2025-06-15 21:59:53,959:INFO:             mlxtend: Not installed
2025-06-15 21:59:53,959:INFO:       statsforecast: Not installed
2025-06-15 21:59:53,959:INFO:        tune_sklearn: Not installed
2025-06-15 21:59:53,959:INFO:                 ray: Not installed
2025-06-15 21:59:53,959:INFO:            hyperopt: Not installed
2025-06-15 21:59:53,959:INFO:              optuna: Not installed
2025-06-15 21:59:53,960:INFO:               skopt: Not installed
2025-06-15 21:59:53,960:INFO:              mlflow: Not installed
2025-06-15 21:59:53,960:INFO:              gradio: Not installed
2025-06-15 21:59:53,960:INFO:             fastapi: Not installed
2025-06-15 21:59:53,960:INFO:             uvicorn: Not installed
2025-06-15 21:59:53,960:INFO:              m2cgen: Not installed
2025-06-15 21:59:53,960:INFO:           evidently: Not installed
2025-06-15 21:59:53,960:INFO:               fugue: Not installed
2025-06-15 21:59:53,960:INFO:           streamlit: 1.42.2
2025-06-15 21:59:53,960:INFO:             prophet: Not installed
2025-06-15 21:59:53,960:INFO:None
2025-06-15 21:59:53,960:INFO:Set up data.
2025-06-15 21:59:54,075:INFO:Set up folding strategy.
2025-06-15 21:59:54,075:INFO:Set up train/test split.
2025-06-15 22:02:31,986:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:02:32,002:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:02:32,351:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:02:39,635:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:02:39,651:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:02:39,976:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:02:40,549:INFO:PyCaret ClassificationExperiment
2025-06-15 22:02:40,550:INFO:Logging name: clf-default-name
2025-06-15 22:02:40,550:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:02:40,550:INFO:version 3.3.2
2025-06-15 22:02:40,550:INFO:Initializing setup()
2025-06-15 22:02:40,550:INFO:self.USI: 282d
2025-06-15 22:02:40,550:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:02:40,550:INFO:Checking environment
2025-06-15 22:02:40,550:INFO:python_version: 3.11.4
2025-06-15 22:02:40,550:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:02:40,550:INFO:machine: AMD64
2025-06-15 22:02:40,550:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:02:40,554:INFO:Memory: svmem(total=17127211008, available=5508521984, percent=67.8, used=11618689024, free=5508521984)
2025-06-15 22:02:40,554:INFO:Physical Core: 6
2025-06-15 22:02:40,554:INFO:Logical Core: 12
2025-06-15 22:02:40,555:INFO:Checking libraries
2025-06-15 22:02:40,555:INFO:System:
2025-06-15 22:02:40,555:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:02:40,555:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:02:40,555:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:02:40,555:INFO:PyCaret required dependencies:
2025-06-15 22:02:40,555:INFO:                 pip: 25.1.1
2025-06-15 22:02:40,555:INFO:          setuptools: 65.5.0
2025-06-15 22:02:40,555:INFO:             pycaret: 3.3.2
2025-06-15 22:02:40,555:INFO:             IPython: 9.3.0
2025-06-15 22:02:40,555:INFO:          ipywidgets: 8.1.7
2025-06-15 22:02:40,555:INFO:                tqdm: 4.67.1
2025-06-15 22:02:40,555:INFO:               numpy: 1.26.4
2025-06-15 22:02:40,555:INFO:              pandas: 2.1.4
2025-06-15 22:02:40,555:INFO:              jinja2: 3.1.6
2025-06-15 22:02:40,556:INFO:               scipy: 1.11.4
2025-06-15 22:02:40,556:INFO:              joblib: 1.3.2
2025-06-15 22:02:40,556:INFO:             sklearn: 1.4.2
2025-06-15 22:02:40,556:INFO:                pyod: 2.0.5
2025-06-15 22:02:40,556:INFO:            imblearn: 0.13.0
2025-06-15 22:02:40,556:INFO:   category_encoders: 2.7.0
2025-06-15 22:02:40,556:INFO:            lightgbm: 4.6.0
2025-06-15 22:02:40,556:INFO:               numba: 0.61.2
2025-06-15 22:02:40,556:INFO:            requests: 2.32.4
2025-06-15 22:02:40,556:INFO:          matplotlib: 3.7.5
2025-06-15 22:02:40,556:INFO:          scikitplot: 0.3.7
2025-06-15 22:02:40,556:INFO:         yellowbrick: 1.5
2025-06-15 22:02:40,556:INFO:              plotly: 5.24.1
2025-06-15 22:02:40,556:INFO:    plotly-resampler: Not installed
2025-06-15 22:02:40,556:INFO:             kaleido: 0.2.1
2025-06-15 22:02:40,556:INFO:           schemdraw: 0.15
2025-06-15 22:02:40,556:INFO:         statsmodels: 0.14.4
2025-06-15 22:02:40,556:INFO:              sktime: 0.26.0
2025-06-15 22:02:40,556:INFO:               tbats: 1.1.3
2025-06-15 22:02:40,557:INFO:            pmdarima: 2.0.4
2025-06-15 22:02:40,557:INFO:              psutil: 7.0.0
2025-06-15 22:02:40,557:INFO:          markupsafe: 3.0.2
2025-06-15 22:02:40,557:INFO:             pickle5: Not installed
2025-06-15 22:02:40,557:INFO:         cloudpickle: 3.1.1
2025-06-15 22:02:40,557:INFO:         deprecation: 2.1.0
2025-06-15 22:02:40,557:INFO:              xxhash: 3.5.0
2025-06-15 22:02:40,557:INFO:           wurlitzer: Not installed
2025-06-15 22:02:40,557:INFO:PyCaret optional dependencies:
2025-06-15 22:02:40,557:INFO:                shap: Not installed
2025-06-15 22:02:40,557:INFO:           interpret: Not installed
2025-06-15 22:02:40,557:INFO:                umap: Not installed
2025-06-15 22:02:40,557:INFO:     ydata_profiling: Not installed
2025-06-15 22:02:40,557:INFO:  explainerdashboard: Not installed
2025-06-15 22:02:40,557:INFO:             autoviz: Not installed
2025-06-15 22:02:40,557:INFO:           fairlearn: Not installed
2025-06-15 22:02:40,557:INFO:          deepchecks: Not installed
2025-06-15 22:02:40,557:INFO:             xgboost: Not installed
2025-06-15 22:02:40,557:INFO:            catboost: Not installed
2025-06-15 22:02:40,558:INFO:              kmodes: Not installed
2025-06-15 22:02:40,558:INFO:             mlxtend: Not installed
2025-06-15 22:02:40,558:INFO:       statsforecast: Not installed
2025-06-15 22:02:40,558:INFO:        tune_sklearn: Not installed
2025-06-15 22:02:40,558:INFO:                 ray: Not installed
2025-06-15 22:02:40,558:INFO:            hyperopt: Not installed
2025-06-15 22:02:40,558:INFO:              optuna: Not installed
2025-06-15 22:02:40,558:INFO:               skopt: Not installed
2025-06-15 22:02:40,558:INFO:              mlflow: Not installed
2025-06-15 22:02:40,558:INFO:              gradio: Not installed
2025-06-15 22:02:40,558:INFO:             fastapi: Not installed
2025-06-15 22:02:40,558:INFO:             uvicorn: Not installed
2025-06-15 22:02:40,558:INFO:              m2cgen: Not installed
2025-06-15 22:02:40,558:INFO:           evidently: Not installed
2025-06-15 22:02:40,558:INFO:               fugue: Not installed
2025-06-15 22:02:40,558:INFO:           streamlit: 1.42.2
2025-06-15 22:02:40,558:INFO:             prophet: Not installed
2025-06-15 22:02:40,558:INFO:None
2025-06-15 22:02:40,559:INFO:Set up data.
2025-06-15 22:02:40,674:INFO:Set up folding strategy.
2025-06-15 22:02:40,674:INFO:Set up train/test split.
2025-06-15 22:02:49,819:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:02:49,836:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:02:50,182:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:02:58,227:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:02:58,244:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:02:58,566:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:02:59,139:INFO:PyCaret ClassificationExperiment
2025-06-15 22:02:59,139:INFO:Logging name: clf-default-name
2025-06-15 22:02:59,140:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:02:59,140:INFO:version 3.3.2
2025-06-15 22:02:59,140:INFO:Initializing setup()
2025-06-15 22:02:59,140:INFO:self.USI: 9c2a
2025-06-15 22:02:59,140:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:02:59,140:INFO:Checking environment
2025-06-15 22:02:59,140:INFO:python_version: 3.11.4
2025-06-15 22:02:59,140:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:02:59,140:INFO:machine: AMD64
2025-06-15 22:02:59,140:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:02:59,144:INFO:Memory: svmem(total=17127211008, available=5497212928, percent=67.9, used=11629998080, free=5497212928)
2025-06-15 22:02:59,144:INFO:Physical Core: 6
2025-06-15 22:02:59,144:INFO:Logical Core: 12
2025-06-15 22:02:59,144:INFO:Checking libraries
2025-06-15 22:02:59,144:INFO:System:
2025-06-15 22:02:59,145:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:02:59,145:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:02:59,145:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:02:59,145:INFO:PyCaret required dependencies:
2025-06-15 22:02:59,145:INFO:                 pip: 25.1.1
2025-06-15 22:02:59,145:INFO:          setuptools: 65.5.0
2025-06-15 22:02:59,145:INFO:             pycaret: 3.3.2
2025-06-15 22:02:59,145:INFO:             IPython: 9.3.0
2025-06-15 22:02:59,145:INFO:          ipywidgets: 8.1.7
2025-06-15 22:02:59,145:INFO:                tqdm: 4.67.1
2025-06-15 22:02:59,145:INFO:               numpy: 1.26.4
2025-06-15 22:02:59,145:INFO:              pandas: 2.1.4
2025-06-15 22:02:59,145:INFO:              jinja2: 3.1.6
2025-06-15 22:02:59,145:INFO:               scipy: 1.11.4
2025-06-15 22:02:59,145:INFO:              joblib: 1.3.2
2025-06-15 22:02:59,145:INFO:             sklearn: 1.4.2
2025-06-15 22:02:59,145:INFO:                pyod: 2.0.5
2025-06-15 22:02:59,145:INFO:            imblearn: 0.13.0
2025-06-15 22:02:59,146:INFO:   category_encoders: 2.7.0
2025-06-15 22:02:59,146:INFO:            lightgbm: 4.6.0
2025-06-15 22:02:59,146:INFO:               numba: 0.61.2
2025-06-15 22:02:59,146:INFO:            requests: 2.32.4
2025-06-15 22:02:59,146:INFO:          matplotlib: 3.7.5
2025-06-15 22:02:59,146:INFO:          scikitplot: 0.3.7
2025-06-15 22:02:59,146:INFO:         yellowbrick: 1.5
2025-06-15 22:02:59,146:INFO:              plotly: 5.24.1
2025-06-15 22:02:59,146:INFO:    plotly-resampler: Not installed
2025-06-15 22:02:59,146:INFO:             kaleido: 0.2.1
2025-06-15 22:02:59,146:INFO:           schemdraw: 0.15
2025-06-15 22:02:59,146:INFO:         statsmodels: 0.14.4
2025-06-15 22:02:59,146:INFO:              sktime: 0.26.0
2025-06-15 22:02:59,146:INFO:               tbats: 1.1.3
2025-06-15 22:02:59,146:INFO:            pmdarima: 2.0.4
2025-06-15 22:02:59,146:INFO:              psutil: 7.0.0
2025-06-15 22:02:59,146:INFO:          markupsafe: 3.0.2
2025-06-15 22:02:59,146:INFO:             pickle5: Not installed
2025-06-15 22:02:59,146:INFO:         cloudpickle: 3.1.1
2025-06-15 22:02:59,146:INFO:         deprecation: 2.1.0
2025-06-15 22:02:59,146:INFO:              xxhash: 3.5.0
2025-06-15 22:02:59,147:INFO:           wurlitzer: Not installed
2025-06-15 22:02:59,147:INFO:PyCaret optional dependencies:
2025-06-15 22:02:59,147:INFO:                shap: Not installed
2025-06-15 22:02:59,147:INFO:           interpret: Not installed
2025-06-15 22:02:59,147:INFO:                umap: Not installed
2025-06-15 22:02:59,147:INFO:     ydata_profiling: Not installed
2025-06-15 22:02:59,147:INFO:  explainerdashboard: Not installed
2025-06-15 22:02:59,147:INFO:             autoviz: Not installed
2025-06-15 22:02:59,147:INFO:           fairlearn: Not installed
2025-06-15 22:02:59,147:INFO:          deepchecks: Not installed
2025-06-15 22:02:59,147:INFO:             xgboost: Not installed
2025-06-15 22:02:59,147:INFO:            catboost: Not installed
2025-06-15 22:02:59,147:INFO:              kmodes: Not installed
2025-06-15 22:02:59,147:INFO:             mlxtend: Not installed
2025-06-15 22:02:59,147:INFO:       statsforecast: Not installed
2025-06-15 22:02:59,147:INFO:        tune_sklearn: Not installed
2025-06-15 22:02:59,147:INFO:                 ray: Not installed
2025-06-15 22:02:59,147:INFO:            hyperopt: Not installed
2025-06-15 22:02:59,147:INFO:              optuna: Not installed
2025-06-15 22:02:59,148:INFO:               skopt: Not installed
2025-06-15 22:02:59,148:INFO:              mlflow: Not installed
2025-06-15 22:02:59,148:INFO:              gradio: Not installed
2025-06-15 22:02:59,148:INFO:             fastapi: Not installed
2025-06-15 22:02:59,148:INFO:             uvicorn: Not installed
2025-06-15 22:02:59,148:INFO:              m2cgen: Not installed
2025-06-15 22:02:59,148:INFO:           evidently: Not installed
2025-06-15 22:02:59,148:INFO:               fugue: Not installed
2025-06-15 22:02:59,148:INFO:           streamlit: 1.42.2
2025-06-15 22:02:59,148:INFO:             prophet: Not installed
2025-06-15 22:02:59,148:INFO:None
2025-06-15 22:02:59,148:INFO:Set up data.
2025-06-15 22:02:59,219:INFO:Set up folding strategy.
2025-06-15 22:02:59,219:INFO:Set up train/test split.
2025-06-15 22:03:15,597:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:03:15,614:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:03:15,934:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:03:36,912:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:03:36,929:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:03:37,260:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:03:44,174:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:03:44,191:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:03:44,515:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:03:45,079:INFO:PyCaret ClassificationExperiment
2025-06-15 22:03:45,079:INFO:Logging name: clf-default-name
2025-06-15 22:03:45,079:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:03:45,079:INFO:version 3.3.2
2025-06-15 22:03:45,079:INFO:Initializing setup()
2025-06-15 22:03:45,079:INFO:self.USI: ac47
2025-06-15 22:03:45,079:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:03:45,079:INFO:Checking environment
2025-06-15 22:03:45,079:INFO:python_version: 3.11.4
2025-06-15 22:03:45,079:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:03:45,079:INFO:machine: AMD64
2025-06-15 22:03:45,080:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:03:45,084:INFO:Memory: svmem(total=17127211008, available=5546889216, percent=67.6, used=11580321792, free=5546889216)
2025-06-15 22:03:45,084:INFO:Physical Core: 6
2025-06-15 22:03:45,084:INFO:Logical Core: 12
2025-06-15 22:03:45,084:INFO:Checking libraries
2025-06-15 22:03:45,084:INFO:System:
2025-06-15 22:03:45,084:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:03:45,084:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:03:45,084:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:03:45,084:INFO:PyCaret required dependencies:
2025-06-15 22:03:45,084:INFO:                 pip: 25.1.1
2025-06-15 22:03:45,084:INFO:          setuptools: 65.5.0
2025-06-15 22:03:45,084:INFO:             pycaret: 3.3.2
2025-06-15 22:03:45,084:INFO:             IPython: 9.3.0
2025-06-15 22:03:45,084:INFO:          ipywidgets: 8.1.7
2025-06-15 22:03:45,085:INFO:                tqdm: 4.67.1
2025-06-15 22:03:45,085:INFO:               numpy: 1.26.4
2025-06-15 22:03:45,085:INFO:              pandas: 2.1.4
2025-06-15 22:03:45,085:INFO:              jinja2: 3.1.6
2025-06-15 22:03:45,085:INFO:               scipy: 1.11.4
2025-06-15 22:03:45,085:INFO:              joblib: 1.3.2
2025-06-15 22:03:45,085:INFO:             sklearn: 1.4.2
2025-06-15 22:03:45,085:INFO:                pyod: 2.0.5
2025-06-15 22:03:45,085:INFO:            imblearn: 0.13.0
2025-06-15 22:03:45,085:INFO:   category_encoders: 2.7.0
2025-06-15 22:03:45,085:INFO:            lightgbm: 4.6.0
2025-06-15 22:03:45,085:INFO:               numba: 0.61.2
2025-06-15 22:03:45,085:INFO:            requests: 2.32.4
2025-06-15 22:03:45,085:INFO:          matplotlib: 3.7.5
2025-06-15 22:03:45,085:INFO:          scikitplot: 0.3.7
2025-06-15 22:03:45,085:INFO:         yellowbrick: 1.5
2025-06-15 22:03:45,085:INFO:              plotly: 5.24.1
2025-06-15 22:03:45,085:INFO:    plotly-resampler: Not installed
2025-06-15 22:03:45,085:INFO:             kaleido: 0.2.1
2025-06-15 22:03:45,086:INFO:           schemdraw: 0.15
2025-06-15 22:03:45,086:INFO:         statsmodels: 0.14.4
2025-06-15 22:03:45,086:INFO:              sktime: 0.26.0
2025-06-15 22:03:45,086:INFO:               tbats: 1.1.3
2025-06-15 22:03:45,086:INFO:            pmdarima: 2.0.4
2025-06-15 22:03:45,086:INFO:              psutil: 7.0.0
2025-06-15 22:03:45,086:INFO:          markupsafe: 3.0.2
2025-06-15 22:03:45,086:INFO:             pickle5: Not installed
2025-06-15 22:03:45,086:INFO:         cloudpickle: 3.1.1
2025-06-15 22:03:45,086:INFO:         deprecation: 2.1.0
2025-06-15 22:03:45,086:INFO:              xxhash: 3.5.0
2025-06-15 22:03:45,086:INFO:           wurlitzer: Not installed
2025-06-15 22:03:45,086:INFO:PyCaret optional dependencies:
2025-06-15 22:03:45,086:INFO:                shap: Not installed
2025-06-15 22:03:45,086:INFO:           interpret: Not installed
2025-06-15 22:03:45,086:INFO:                umap: Not installed
2025-06-15 22:03:45,086:INFO:     ydata_profiling: Not installed
2025-06-15 22:03:45,086:INFO:  explainerdashboard: Not installed
2025-06-15 22:03:45,086:INFO:             autoviz: Not installed
2025-06-15 22:03:45,087:INFO:           fairlearn: Not installed
2025-06-15 22:03:45,087:INFO:          deepchecks: Not installed
2025-06-15 22:03:45,087:INFO:             xgboost: Not installed
2025-06-15 22:03:45,087:INFO:            catboost: Not installed
2025-06-15 22:03:45,087:INFO:              kmodes: Not installed
2025-06-15 22:03:45,087:INFO:             mlxtend: Not installed
2025-06-15 22:03:45,087:INFO:       statsforecast: Not installed
2025-06-15 22:03:45,087:INFO:        tune_sklearn: Not installed
2025-06-15 22:03:45,087:INFO:                 ray: Not installed
2025-06-15 22:03:45,087:INFO:            hyperopt: Not installed
2025-06-15 22:03:45,087:INFO:              optuna: Not installed
2025-06-15 22:03:45,087:INFO:               skopt: Not installed
2025-06-15 22:03:45,087:INFO:              mlflow: Not installed
2025-06-15 22:03:45,087:INFO:              gradio: Not installed
2025-06-15 22:03:45,087:INFO:             fastapi: Not installed
2025-06-15 22:03:45,087:INFO:             uvicorn: Not installed
2025-06-15 22:03:45,087:INFO:              m2cgen: Not installed
2025-06-15 22:03:45,087:INFO:           evidently: Not installed
2025-06-15 22:03:45,088:INFO:               fugue: Not installed
2025-06-15 22:03:45,088:INFO:           streamlit: 1.42.2
2025-06-15 22:03:45,088:INFO:             prophet: Not installed
2025-06-15 22:03:45,088:INFO:None
2025-06-15 22:03:45,088:INFO:Set up data.
2025-06-15 22:03:45,113:INFO:Set up folding strategy.
2025-06-15 22:03:45,114:INFO:Set up train/test split.
2025-06-15 22:03:54,121:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:03:54,138:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:03:54,490:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:04:01,922:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:04:01,939:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:04:02,264:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:04:02,830:INFO:PyCaret ClassificationExperiment
2025-06-15 22:04:02,830:INFO:Logging name: clf-default-name
2025-06-15 22:04:02,830:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:04:02,830:INFO:version 3.3.2
2025-06-15 22:04:02,830:INFO:Initializing setup()
2025-06-15 22:04:02,830:INFO:self.USI: 7290
2025-06-15 22:04:02,831:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:04:02,831:INFO:Checking environment
2025-06-15 22:04:02,831:INFO:python_version: 3.11.4
2025-06-15 22:04:02,831:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:04:02,831:INFO:machine: AMD64
2025-06-15 22:04:02,831:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:04:02,835:INFO:Memory: svmem(total=17127211008, available=5634084864, percent=67.1, used=11493126144, free=5634084864)
2025-06-15 22:04:02,835:INFO:Physical Core: 6
2025-06-15 22:04:02,835:INFO:Logical Core: 12
2025-06-15 22:04:02,835:INFO:Checking libraries
2025-06-15 22:04:02,835:INFO:System:
2025-06-15 22:04:02,835:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:04:02,835:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:04:02,835:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:04:02,835:INFO:PyCaret required dependencies:
2025-06-15 22:04:02,836:INFO:                 pip: 25.1.1
2025-06-15 22:04:02,836:INFO:          setuptools: 65.5.0
2025-06-15 22:04:02,836:INFO:             pycaret: 3.3.2
2025-06-15 22:04:02,836:INFO:             IPython: 9.3.0
2025-06-15 22:04:02,836:INFO:          ipywidgets: 8.1.7
2025-06-15 22:04:02,836:INFO:                tqdm: 4.67.1
2025-06-15 22:04:02,836:INFO:               numpy: 1.26.4
2025-06-15 22:04:02,836:INFO:              pandas: 2.1.4
2025-06-15 22:04:02,836:INFO:              jinja2: 3.1.6
2025-06-15 22:04:02,836:INFO:               scipy: 1.11.4
2025-06-15 22:04:02,836:INFO:              joblib: 1.3.2
2025-06-15 22:04:02,836:INFO:             sklearn: 1.4.2
2025-06-15 22:04:02,836:INFO:                pyod: 2.0.5
2025-06-15 22:04:02,836:INFO:            imblearn: 0.13.0
2025-06-15 22:04:02,836:INFO:   category_encoders: 2.7.0
2025-06-15 22:04:02,836:INFO:            lightgbm: 4.6.0
2025-06-15 22:04:02,836:INFO:               numba: 0.61.2
2025-06-15 22:04:02,836:INFO:            requests: 2.32.4
2025-06-15 22:04:02,836:INFO:          matplotlib: 3.7.5
2025-06-15 22:04:02,837:INFO:          scikitplot: 0.3.7
2025-06-15 22:04:02,837:INFO:         yellowbrick: 1.5
2025-06-15 22:04:02,837:INFO:              plotly: 5.24.1
2025-06-15 22:04:02,837:INFO:    plotly-resampler: Not installed
2025-06-15 22:04:02,837:INFO:             kaleido: 0.2.1
2025-06-15 22:04:02,837:INFO:           schemdraw: 0.15
2025-06-15 22:04:02,837:INFO:         statsmodels: 0.14.4
2025-06-15 22:04:02,837:INFO:              sktime: 0.26.0
2025-06-15 22:04:02,837:INFO:               tbats: 1.1.3
2025-06-15 22:04:02,837:INFO:            pmdarima: 2.0.4
2025-06-15 22:04:02,837:INFO:              psutil: 7.0.0
2025-06-15 22:04:02,837:INFO:          markupsafe: 3.0.2
2025-06-15 22:04:02,837:INFO:             pickle5: Not installed
2025-06-15 22:04:02,837:INFO:         cloudpickle: 3.1.1
2025-06-15 22:04:02,837:INFO:         deprecation: 2.1.0
2025-06-15 22:04:02,837:INFO:              xxhash: 3.5.0
2025-06-15 22:04:02,837:INFO:           wurlitzer: Not installed
2025-06-15 22:04:02,837:INFO:PyCaret optional dependencies:
2025-06-15 22:04:02,837:INFO:                shap: Not installed
2025-06-15 22:04:02,837:INFO:           interpret: Not installed
2025-06-15 22:04:02,838:INFO:                umap: Not installed
2025-06-15 22:04:02,838:INFO:     ydata_profiling: Not installed
2025-06-15 22:04:02,838:INFO:  explainerdashboard: Not installed
2025-06-15 22:04:02,838:INFO:             autoviz: Not installed
2025-06-15 22:04:02,838:INFO:           fairlearn: Not installed
2025-06-15 22:04:02,838:INFO:          deepchecks: Not installed
2025-06-15 22:04:02,838:INFO:             xgboost: Not installed
2025-06-15 22:04:02,838:INFO:            catboost: Not installed
2025-06-15 22:04:02,838:INFO:              kmodes: Not installed
2025-06-15 22:04:02,838:INFO:             mlxtend: Not installed
2025-06-15 22:04:02,838:INFO:       statsforecast: Not installed
2025-06-15 22:04:02,838:INFO:        tune_sklearn: Not installed
2025-06-15 22:04:02,838:INFO:                 ray: Not installed
2025-06-15 22:04:02,838:INFO:            hyperopt: Not installed
2025-06-15 22:04:02,838:INFO:              optuna: Not installed
2025-06-15 22:04:02,838:INFO:               skopt: Not installed
2025-06-15 22:04:02,838:INFO:              mlflow: Not installed
2025-06-15 22:04:02,838:INFO:              gradio: Not installed
2025-06-15 22:04:02,839:INFO:             fastapi: Not installed
2025-06-15 22:04:02,839:INFO:             uvicorn: Not installed
2025-06-15 22:04:02,839:INFO:              m2cgen: Not installed
2025-06-15 22:04:02,839:INFO:           evidently: Not installed
2025-06-15 22:04:02,839:INFO:               fugue: Not installed
2025-06-15 22:04:02,839:INFO:           streamlit: 1.42.2
2025-06-15 22:04:02,839:INFO:             prophet: Not installed
2025-06-15 22:04:02,839:INFO:None
2025-06-15 22:04:02,839:INFO:Set up data.
2025-06-15 22:04:02,842:INFO:Set up folding strategy.
2025-06-15 22:04:02,842:INFO:Set up train/test split.
2025-06-15 22:04:11,894:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:04:11,911:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:04:12,243:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:06:16,915:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:06:16,933:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:06:17,253:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:06:36,005:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:06:36,021:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:06:36,352:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:07:25,431:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:07:25,449:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:07:25,765:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:07:33,444:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:07:33,461:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:07:33,804:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:07:34,435:INFO:PyCaret ClassificationExperiment
2025-06-15 22:07:34,435:INFO:Logging name: clf-default-name
2025-06-15 22:07:34,435:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:07:34,435:INFO:version 3.3.2
2025-06-15 22:07:34,435:INFO:Initializing setup()
2025-06-15 22:07:34,435:INFO:self.USI: cb43
2025-06-15 22:07:34,435:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:07:34,435:INFO:Checking environment
2025-06-15 22:07:34,435:INFO:python_version: 3.11.4
2025-06-15 22:07:34,435:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:07:34,436:INFO:machine: AMD64
2025-06-15 22:07:34,436:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:07:34,440:INFO:Memory: svmem(total=17127211008, available=5910482944, percent=65.5, used=11216728064, free=5910482944)
2025-06-15 22:07:34,440:INFO:Physical Core: 6
2025-06-15 22:07:34,440:INFO:Logical Core: 12
2025-06-15 22:07:34,440:INFO:Checking libraries
2025-06-15 22:07:34,440:INFO:System:
2025-06-15 22:07:34,440:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:07:34,440:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:07:34,440:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:07:34,440:INFO:PyCaret required dependencies:
2025-06-15 22:07:34,440:INFO:                 pip: 25.1.1
2025-06-15 22:07:34,440:INFO:          setuptools: 65.5.0
2025-06-15 22:07:34,440:INFO:             pycaret: 3.3.2
2025-06-15 22:07:34,440:INFO:             IPython: 9.3.0
2025-06-15 22:07:34,440:INFO:          ipywidgets: 8.1.7
2025-06-15 22:07:34,441:INFO:                tqdm: 4.67.1
2025-06-15 22:07:34,441:INFO:               numpy: 1.26.4
2025-06-15 22:07:34,441:INFO:              pandas: 2.1.4
2025-06-15 22:07:34,441:INFO:              jinja2: 3.1.6
2025-06-15 22:07:34,441:INFO:               scipy: 1.11.4
2025-06-15 22:07:34,441:INFO:              joblib: 1.3.2
2025-06-15 22:07:34,441:INFO:             sklearn: 1.4.2
2025-06-15 22:07:34,441:INFO:                pyod: 2.0.5
2025-06-15 22:07:34,441:INFO:            imblearn: 0.13.0
2025-06-15 22:07:34,441:INFO:   category_encoders: 2.7.0
2025-06-15 22:07:34,441:INFO:            lightgbm: 4.6.0
2025-06-15 22:07:34,441:INFO:               numba: 0.61.2
2025-06-15 22:07:34,441:INFO:            requests: 2.32.4
2025-06-15 22:07:34,441:INFO:          matplotlib: 3.7.5
2025-06-15 22:07:34,441:INFO:          scikitplot: 0.3.7
2025-06-15 22:07:34,441:INFO:         yellowbrick: 1.5
2025-06-15 22:07:34,441:INFO:              plotly: 5.24.1
2025-06-15 22:07:34,441:INFO:    plotly-resampler: Not installed
2025-06-15 22:07:34,441:INFO:             kaleido: 0.2.1
2025-06-15 22:07:34,441:INFO:           schemdraw: 0.15
2025-06-15 22:07:34,442:INFO:         statsmodels: 0.14.4
2025-06-15 22:07:34,442:INFO:              sktime: 0.26.0
2025-06-15 22:07:34,442:INFO:               tbats: 1.1.3
2025-06-15 22:07:34,442:INFO:            pmdarima: 2.0.4
2025-06-15 22:07:34,442:INFO:              psutil: 7.0.0
2025-06-15 22:07:34,442:INFO:          markupsafe: 3.0.2
2025-06-15 22:07:34,442:INFO:             pickle5: Not installed
2025-06-15 22:07:34,442:INFO:         cloudpickle: 3.1.1
2025-06-15 22:07:34,442:INFO:         deprecation: 2.1.0
2025-06-15 22:07:34,442:INFO:              xxhash: 3.5.0
2025-06-15 22:07:34,442:INFO:           wurlitzer: Not installed
2025-06-15 22:07:34,442:INFO:PyCaret optional dependencies:
2025-06-15 22:07:34,442:INFO:                shap: Not installed
2025-06-15 22:07:34,442:INFO:           interpret: Not installed
2025-06-15 22:07:34,442:INFO:                umap: Not installed
2025-06-15 22:07:34,442:INFO:     ydata_profiling: Not installed
2025-06-15 22:07:34,442:INFO:  explainerdashboard: Not installed
2025-06-15 22:07:34,442:INFO:             autoviz: Not installed
2025-06-15 22:07:34,442:INFO:           fairlearn: Not installed
2025-06-15 22:07:34,442:INFO:          deepchecks: Not installed
2025-06-15 22:07:34,443:INFO:             xgboost: Not installed
2025-06-15 22:07:34,443:INFO:            catboost: Not installed
2025-06-15 22:07:34,443:INFO:              kmodes: Not installed
2025-06-15 22:07:34,443:INFO:             mlxtend: Not installed
2025-06-15 22:07:34,443:INFO:       statsforecast: Not installed
2025-06-15 22:07:34,443:INFO:        tune_sklearn: Not installed
2025-06-15 22:07:34,443:INFO:                 ray: Not installed
2025-06-15 22:07:34,443:INFO:            hyperopt: Not installed
2025-06-15 22:07:34,443:INFO:              optuna: Not installed
2025-06-15 22:07:34,443:INFO:               skopt: Not installed
2025-06-15 22:07:34,443:INFO:              mlflow: Not installed
2025-06-15 22:07:34,443:INFO:              gradio: Not installed
2025-06-15 22:07:34,443:INFO:             fastapi: Not installed
2025-06-15 22:07:34,443:INFO:             uvicorn: Not installed
2025-06-15 22:07:34,443:INFO:              m2cgen: Not installed
2025-06-15 22:07:34,443:INFO:           evidently: Not installed
2025-06-15 22:07:34,443:INFO:               fugue: Not installed
2025-06-15 22:07:34,443:INFO:           streamlit: 1.42.2
2025-06-15 22:07:34,443:INFO:             prophet: Not installed
2025-06-15 22:07:34,443:INFO:None
2025-06-15 22:07:34,444:INFO:Set up data.
2025-06-15 22:07:34,455:INFO:Set up folding strategy.
2025-06-15 22:07:34,456:INFO:Set up train/test split.
2025-06-15 22:07:59,697:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:07:59,713:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:08:00,039:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:08:00,659:INFO:PyCaret ClassificationExperiment
2025-06-15 22:08:00,660:INFO:Logging name: clf-default-name
2025-06-15 22:08:00,660:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-15 22:08:00,660:INFO:version 3.3.2
2025-06-15 22:08:00,660:INFO:Initializing setup()
2025-06-15 22:08:00,660:INFO:self.USI: bdad
2025-06-15 22:08:00,660:INFO:self._variable_keys: {'y', 'idx', 'exp_name_log', 'data', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'memory', 'gpu_param', 'pipeline', 'html_param', 'X_test', 'n_jobs_param', 'exp_id', '_ml_usecase', 'logging_param', 'seed', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'USI', 'fold_groups_param', '_available_plots', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance'}
2025-06-15 22:08:00,660:INFO:Checking environment
2025-06-15 22:08:00,660:INFO:python_version: 3.11.4
2025-06-15 22:08:00,660:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:08:00,660:INFO:machine: AMD64
2025-06-15 22:08:00,660:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:08:00,664:INFO:Memory: svmem(total=17127211008, available=6047522816, percent=64.7, used=11079688192, free=6047522816)
2025-06-15 22:08:00,664:INFO:Physical Core: 6
2025-06-15 22:08:00,664:INFO:Logical Core: 12
2025-06-15 22:08:00,665:INFO:Checking libraries
2025-06-15 22:08:00,665:INFO:System:
2025-06-15 22:08:00,665:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:08:00,665:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:08:00,665:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:08:00,665:INFO:PyCaret required dependencies:
2025-06-15 22:08:00,665:INFO:                 pip: 25.1.1
2025-06-15 22:08:00,665:INFO:          setuptools: 65.5.0
2025-06-15 22:08:00,665:INFO:             pycaret: 3.3.2
2025-06-15 22:08:00,665:INFO:             IPython: 9.3.0
2025-06-15 22:08:00,665:INFO:          ipywidgets: 8.1.7
2025-06-15 22:08:00,665:INFO:                tqdm: 4.67.1
2025-06-15 22:08:00,665:INFO:               numpy: 1.26.4
2025-06-15 22:08:00,665:INFO:              pandas: 2.1.4
2025-06-15 22:08:00,665:INFO:              jinja2: 3.1.6
2025-06-15 22:08:00,665:INFO:               scipy: 1.11.4
2025-06-15 22:08:00,666:INFO:              joblib: 1.3.2
2025-06-15 22:08:00,666:INFO:             sklearn: 1.4.2
2025-06-15 22:08:00,666:INFO:                pyod: 2.0.5
2025-06-15 22:08:00,666:INFO:            imblearn: 0.13.0
2025-06-15 22:08:00,666:INFO:   category_encoders: 2.7.0
2025-06-15 22:08:00,666:INFO:            lightgbm: 4.6.0
2025-06-15 22:08:00,666:INFO:               numba: 0.61.2
2025-06-15 22:08:00,666:INFO:            requests: 2.32.4
2025-06-15 22:08:00,666:INFO:          matplotlib: 3.7.5
2025-06-15 22:08:00,666:INFO:          scikitplot: 0.3.7
2025-06-15 22:08:00,666:INFO:         yellowbrick: 1.5
2025-06-15 22:08:00,666:INFO:              plotly: 5.24.1
2025-06-15 22:08:00,666:INFO:    plotly-resampler: Not installed
2025-06-15 22:08:00,666:INFO:             kaleido: 0.2.1
2025-06-15 22:08:00,666:INFO:           schemdraw: 0.15
2025-06-15 22:08:00,666:INFO:         statsmodels: 0.14.4
2025-06-15 22:08:00,666:INFO:              sktime: 0.26.0
2025-06-15 22:08:00,666:INFO:               tbats: 1.1.3
2025-06-15 22:08:00,666:INFO:            pmdarima: 2.0.4
2025-06-15 22:08:00,667:INFO:              psutil: 7.0.0
2025-06-15 22:08:00,667:INFO:          markupsafe: 3.0.2
2025-06-15 22:08:00,667:INFO:             pickle5: Not installed
2025-06-15 22:08:00,667:INFO:         cloudpickle: 3.1.1
2025-06-15 22:08:00,667:INFO:         deprecation: 2.1.0
2025-06-15 22:08:00,667:INFO:              xxhash: 3.5.0
2025-06-15 22:08:00,667:INFO:           wurlitzer: Not installed
2025-06-15 22:08:00,667:INFO:PyCaret optional dependencies:
2025-06-15 22:08:00,667:INFO:                shap: Not installed
2025-06-15 22:08:00,667:INFO:           interpret: Not installed
2025-06-15 22:08:00,667:INFO:                umap: Not installed
2025-06-15 22:08:00,667:INFO:     ydata_profiling: Not installed
2025-06-15 22:08:00,667:INFO:  explainerdashboard: Not installed
2025-06-15 22:08:00,667:INFO:             autoviz: Not installed
2025-06-15 22:08:00,667:INFO:           fairlearn: Not installed
2025-06-15 22:08:00,667:INFO:          deepchecks: Not installed
2025-06-15 22:08:00,667:INFO:             xgboost: Not installed
2025-06-15 22:08:00,667:INFO:            catboost: Not installed
2025-06-15 22:08:00,667:INFO:              kmodes: Not installed
2025-06-15 22:08:00,668:INFO:             mlxtend: Not installed
2025-06-15 22:08:00,668:INFO:       statsforecast: Not installed
2025-06-15 22:08:00,668:INFO:        tune_sklearn: Not installed
2025-06-15 22:08:00,668:INFO:                 ray: Not installed
2025-06-15 22:08:00,668:INFO:            hyperopt: Not installed
2025-06-15 22:08:00,668:INFO:              optuna: Not installed
2025-06-15 22:08:00,668:INFO:               skopt: Not installed
2025-06-15 22:08:00,668:INFO:              mlflow: Not installed
2025-06-15 22:08:00,668:INFO:              gradio: Not installed
2025-06-15 22:08:00,668:INFO:             fastapi: Not installed
2025-06-15 22:08:00,668:INFO:             uvicorn: Not installed
2025-06-15 22:08:00,668:INFO:              m2cgen: Not installed
2025-06-15 22:08:00,668:INFO:           evidently: Not installed
2025-06-15 22:08:00,668:INFO:               fugue: Not installed
2025-06-15 22:08:00,668:INFO:           streamlit: 1.42.2
2025-06-15 22:08:00,668:INFO:             prophet: Not installed
2025-06-15 22:08:00,668:INFO:None
2025-06-15 22:08:00,668:INFO:Set up data.
2025-06-15 22:08:00,681:INFO:Set up folding strategy.
2025-06-15 22:08:00,681:INFO:Set up train/test split.
2025-06-15 22:09:55,755:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:09:55,775:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:09:56,112:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:10:06,373:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:10:06,389:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:10:06,710:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:10:48,685:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:10:48,700:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:10:49,028:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:10:59,967:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:10:59,983:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:00,314:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:11:11,958:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:11:11,975:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:12,321:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:11:32,339:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:11:32,355:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:32,669:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:11:38,256:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:11:38,273:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:38,590:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:11:47,209:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:11:47,225:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:47,540:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:11:53,809:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:11:53,826:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:11:54,143:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:12:08,245:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:12:08,262:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:12:08,573:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:12:13,479:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:12:13,496:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:12:13,806:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:12:21,566:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:12:21,583:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:12:21,907:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:12:31,632:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:12:31,648:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:12:31,963:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:12:37,197:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:12:37,213:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:12:37,531:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:04,812:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:04,829:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:05,147:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:10,698:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:10,715:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:11,035:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:21,202:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:21,218:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:21,536:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:28,595:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:28,611:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:28,939:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:34,215:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:34,232:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:34,550:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:47,673:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:47,690:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:48,013:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:13:53,502:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:13:53,518:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:13:53,834:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:06,292:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:06,309:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:06,636:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:14,740:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:14,757:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:15,091:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:31,253:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:31,273:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:31,597:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:37,433:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:37,451:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:37,778:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:45,521:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:45,540:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:45,864:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:14:50,568:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:14:50,585:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:14:50,909:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:15:04,986:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:15:05,003:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:15:05,337:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:15:09,951:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:15:09,969:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:15:10,307:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:16:06,341:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:16:06,359:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:16:06,686:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:16:11,366:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:16:11,384:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:16:11,705:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:16:16,036:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:16:16,053:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:16:16,378:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:17:44,740:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:17:44,758:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:17:45,086:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:17:50,789:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:17:50,806:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:17:51,129:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:19:33,762:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:19:33,779:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:19:34,108:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:19:39,374:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:19:39,391:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:19:39,713:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:19:47,052:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:19:47,068:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:19:47,385:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:19:53,437:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:19:53,453:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:19:53,769:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:20:00,392:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:20:00,408:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:20:00,728:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:20:06,592:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:20:06,609:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:20:06,926:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:24:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:24:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:24:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:24:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:24:30,355:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:24:30,372:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:24:30,704:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:24:41,580:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:24:41,598:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:24:41,915:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:24:52,597:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:24:52,613:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:24:52,950:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:25:07,425:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:25:07,441:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:25:07,780:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:25:12,373:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:25:12,390:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:25:12,737:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:25:18,337:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:25:18,354:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-06-15 22:25:18,672:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-06-15 22:31:32,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:31:32,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:31:32,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:31:32,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-15 22:31:40,489:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:31:40,506:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:31:40,821:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:00,696:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:32:00,713:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:01,051:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:08,443:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:32:08,461:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:08,788:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:44,623:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:32:44,641:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:44,983:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:49,919:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:32:49,936:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:32:50,264:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:30,892:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:33:30,910:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:31,241:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:39,539:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:33:39,554:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:39,881:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:44,266:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:33:44,285:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:33:44,609:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:00,784:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:00,802:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:01,132:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:05,573:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:05,590:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:06,013:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:15,605:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:15,624:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:15,968:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:24,933:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:24,950:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:25,288:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:30,991:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:31,008:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:31,333:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:44,644:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:44,662:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:44,989:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:50,000:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:34:50,017:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:34:50,373:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:05,128:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:35:05,146:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:05,476:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:32,774:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:35:32,792:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:33,116:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:42,033:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:35:42,051:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:42,371:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:47,059:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:35:47,078:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:47,418:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:56,079:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:35:56,098:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:35:56,427:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:36:00,693:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:199: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-06-15 22:36:00,711:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:202: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:36:01,039:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:240: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(

2025-06-15 22:36:01,571:INFO:PyCaret RegressionExperiment
2025-06-15 22:36:01,571:INFO:Logging name: reg-default-name
2025-06-15 22:36:01,571:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-15 22:36:01,571:INFO:version 3.3.2
2025-06-15 22:36:01,571:INFO:Initializing setup()
2025-06-15 22:36:01,571:INFO:self.USI: b186
2025-06-15 22:36:01,571:INFO:self._variable_keys: {'pipeline', 'y_train', 'X', 'y', 'USI', '_available_plots', 'idx', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'X_train', '_ml_usecase', 'fold_shuffle_param', 'gpu_param', 'html_param', 'log_plots_param', 'logging_param', 'fold_generator', 'transform_target_param', 'exp_id', 'y_test', 'memory', 'data', 'X_test', 'target_param', 'gpu_n_jobs_param', 'seed'}
2025-06-15 22:36:01,571:INFO:Checking environment
2025-06-15 22:36:01,571:INFO:python_version: 3.11.4
2025-06-15 22:36:01,571:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:36:01,572:INFO:machine: AMD64
2025-06-15 22:36:01,584:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:36:01,588:INFO:Memory: svmem(total=17127211008, available=6261133312, percent=63.4, used=10866077696, free=6261133312)
2025-06-15 22:36:01,588:INFO:Physical Core: 6
2025-06-15 22:36:01,588:INFO:Logical Core: 12
2025-06-15 22:36:01,588:INFO:Checking libraries
2025-06-15 22:36:01,588:INFO:System:
2025-06-15 22:36:01,588:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:36:01,588:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:36:01,588:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:36:01,588:INFO:PyCaret required dependencies:
2025-06-15 22:36:01,623:INFO:                 pip: 25.1.1
2025-06-15 22:36:01,623:INFO:          setuptools: 65.5.0
2025-06-15 22:36:01,623:INFO:             pycaret: 3.3.2
2025-06-15 22:36:01,623:INFO:             IPython: 9.3.0
2025-06-15 22:36:01,624:INFO:          ipywidgets: 8.1.7
2025-06-15 22:36:01,624:INFO:                tqdm: 4.67.1
2025-06-15 22:36:01,624:INFO:               numpy: 1.26.4
2025-06-15 22:36:01,624:INFO:              pandas: 2.1.4
2025-06-15 22:36:01,624:INFO:              jinja2: 3.1.6
2025-06-15 22:36:01,624:INFO:               scipy: 1.11.4
2025-06-15 22:36:01,624:INFO:              joblib: 1.3.2
2025-06-15 22:36:01,624:INFO:             sklearn: 1.4.2
2025-06-15 22:36:01,624:INFO:                pyod: 2.0.5
2025-06-15 22:36:01,624:INFO:            imblearn: 0.13.0
2025-06-15 22:36:01,624:INFO:   category_encoders: 2.7.0
2025-06-15 22:36:01,624:INFO:            lightgbm: 4.6.0
2025-06-15 22:36:01,624:INFO:               numba: 0.61.2
2025-06-15 22:36:01,624:INFO:            requests: 2.32.4
2025-06-15 22:36:01,624:INFO:          matplotlib: 3.7.5
2025-06-15 22:36:01,624:INFO:          scikitplot: 0.3.7
2025-06-15 22:36:01,624:INFO:         yellowbrick: 1.5
2025-06-15 22:36:01,624:INFO:              plotly: 5.24.1
2025-06-15 22:36:01,625:INFO:    plotly-resampler: Not installed
2025-06-15 22:36:01,625:INFO:             kaleido: 0.2.1
2025-06-15 22:36:01,625:INFO:           schemdraw: 0.15
2025-06-15 22:36:01,625:INFO:         statsmodels: 0.14.4
2025-06-15 22:36:01,625:INFO:              sktime: 0.26.0
2025-06-15 22:36:01,625:INFO:               tbats: 1.1.3
2025-06-15 22:36:01,625:INFO:            pmdarima: 2.0.4
2025-06-15 22:36:01,625:INFO:              psutil: 7.0.0
2025-06-15 22:36:01,625:INFO:          markupsafe: 3.0.2
2025-06-15 22:36:01,625:INFO:             pickle5: Not installed
2025-06-15 22:36:01,625:INFO:         cloudpickle: 3.1.1
2025-06-15 22:36:01,625:INFO:         deprecation: 2.1.0
2025-06-15 22:36:01,625:INFO:              xxhash: 3.5.0
2025-06-15 22:36:01,625:INFO:           wurlitzer: Not installed
2025-06-15 22:36:01,625:INFO:PyCaret optional dependencies:
2025-06-15 22:36:01,658:INFO:                shap: Not installed
2025-06-15 22:36:01,658:INFO:           interpret: Not installed
2025-06-15 22:36:01,658:INFO:                umap: Not installed
2025-06-15 22:36:01,658:INFO:     ydata_profiling: Not installed
2025-06-15 22:36:01,658:INFO:  explainerdashboard: Not installed
2025-06-15 22:36:01,658:INFO:             autoviz: Not installed
2025-06-15 22:36:01,658:INFO:           fairlearn: Not installed
2025-06-15 22:36:01,658:INFO:          deepchecks: Not installed
2025-06-15 22:36:01,659:INFO:             xgboost: Not installed
2025-06-15 22:36:01,659:INFO:            catboost: Not installed
2025-06-15 22:36:01,659:INFO:              kmodes: Not installed
2025-06-15 22:36:01,659:INFO:             mlxtend: Not installed
2025-06-15 22:36:01,659:INFO:       statsforecast: Not installed
2025-06-15 22:36:01,659:INFO:        tune_sklearn: Not installed
2025-06-15 22:36:01,659:INFO:                 ray: Not installed
2025-06-15 22:36:01,659:INFO:            hyperopt: Not installed
2025-06-15 22:36:01,659:INFO:              optuna: Not installed
2025-06-15 22:36:01,659:INFO:               skopt: Not installed
2025-06-15 22:36:01,659:INFO:              mlflow: Not installed
2025-06-15 22:36:01,659:INFO:              gradio: Not installed
2025-06-15 22:36:01,659:INFO:             fastapi: Not installed
2025-06-15 22:36:01,659:INFO:             uvicorn: Not installed
2025-06-15 22:36:01,659:INFO:              m2cgen: Not installed
2025-06-15 22:36:01,659:INFO:           evidently: Not installed
2025-06-15 22:36:01,659:INFO:               fugue: Not installed
2025-06-15 22:36:01,659:INFO:           streamlit: 1.42.2
2025-06-15 22:36:01,659:INFO:             prophet: Not installed
2025-06-15 22:36:01,659:INFO:None
2025-06-15 22:36:01,660:INFO:Set up data.
2025-06-15 22:36:01,666:INFO:Set up folding strategy.
2025-06-15 22:36:01,666:INFO:Set up train/test split.
2025-06-15 22:36:01,674:INFO:Set up index.
2025-06-15 22:36:01,674:INFO:Assigning column types.
2025-06-15 22:36:01,677:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-15 22:36:01,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,683:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:01,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:01,824:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,830:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:01,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:01,969:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-15 22:36:01,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:36:01,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,123:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,268:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-15 22:36:02,281:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,429:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,565:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-15 22:36:02,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:36:02,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:02,858:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-15 22:36:02,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:03,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:36:03,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,156:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-15 22:36:03,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:03,451:INFO:Preparing preprocessing pipeline...
2025-06-15 22:36:03,451:INFO:Set up simple imputation.
2025-06-15 22:36:03,454:INFO:Set up encoding of categorical features.
2025-06-15 22:36:03,591:INFO:Finished creating preprocessing pipeline.
2025-06-15 22:36:03,602:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['views', 'dislikes'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['trending_date', 'title',
                                             'channel_title', 'category_id',
                                             'publish_time', 'tags',
                                             'description', 'category_name'],
                                    transfor...
                                    transformer=OneHotEncoder(cols=['trending_date',
                                                                    'category_id',
                                                                    'category_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['title', 'channel_title',
                                             'publish_time', 'tags',
                                             'description'],
                                    transformer=TargetEncoder(cols=['title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-06-15 22:36:03,602:INFO:Creating final display dataframe.
2025-06-15 22:36:03,978:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             likes
2                   Target type        Regression
3           Original data shape         (100, 11)
4        Transformed data shape         (100, 34)
5   Transformed train set shape          (50, 34)
6    Transformed test set shape          (50, 34)
7              Numeric features                 2
8          Categorical features                 8
9      Rows with missing values              2.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                 2
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              b186
2025-06-15 22:36:04,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:04,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:04,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:04,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:36:04,275:INFO:setup() successfully completed in 2.72s...............
2025-06-15 22:36:04,275:INFO:Initializing compare_models()
2025-06-15 22:36:04,275:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-15 22:36:04,275:INFO:Checking exceptions
2025-06-15 22:36:04,276:INFO:Preparing display monitor
2025-06-15 22:36:04,280:INFO:Initializing Linear Regression
2025-06-15 22:36:04,280:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-06-15 22:36:04,280:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:04,280:INFO:Initializing create_model()
2025-06-15 22:36:04,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=lr, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:04,280:INFO:Checking exceptions
2025-06-15 22:36:04,280:INFO:Importing libraries
2025-06-15 22:36:04,280:INFO:Copying training dataset
2025-06-15 22:36:04,284:INFO:Defining folds
2025-06-15 22:36:04,284:INFO:Declaring metric variables
2025-06-15 22:36:04,284:INFO:Importing untrained model
2025-06-15 22:36:04,285:INFO:Linear Regression Imported successfully
2025-06-15 22:36:04,285:INFO:Starting cross validation
2025-06-15 22:36:04,294:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:08,430:INFO:Calculating mean and std
2025-06-15 22:36:08,431:INFO:Creating metrics dataframe
2025-06-15 22:36:08,433:INFO:Uploading results into container
2025-06-15 22:36:08,433:INFO:Uploading model into container now
2025-06-15 22:36:08,434:INFO:_master_model_container: 1
2025-06-15 22:36:08,434:INFO:_display_container: 2
2025-06-15 22:36:08,434:INFO:LinearRegression(n_jobs=-1)
2025-06-15 22:36:08,434:INFO:create_model() successfully completed......................................
2025-06-15 22:36:08,578:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:08,579:INFO:Creating metrics dataframe
2025-06-15 22:36:08,581:INFO:Initializing Lasso Regression
2025-06-15 22:36:08,581:INFO:Total runtime is 0.07169776757558187 minutes
2025-06-15 22:36:08,581:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:08,581:INFO:Initializing create_model()
2025-06-15 22:36:08,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=lasso, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:08,581:INFO:Checking exceptions
2025-06-15 22:36:08,581:INFO:Importing libraries
2025-06-15 22:36:08,581:INFO:Copying training dataset
2025-06-15 22:36:08,585:INFO:Defining folds
2025-06-15 22:36:08,585:INFO:Declaring metric variables
2025-06-15 22:36:08,585:INFO:Importing untrained model
2025-06-15 22:36:08,585:INFO:Lasso Regression Imported successfully
2025-06-15 22:36:08,585:INFO:Starting cross validation
2025-06-15 22:36:08,587:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:11,892:INFO:Calculating mean and std
2025-06-15 22:36:11,893:INFO:Creating metrics dataframe
2025-06-15 22:36:11,895:INFO:Uploading results into container
2025-06-15 22:36:11,895:INFO:Uploading model into container now
2025-06-15 22:36:11,895:INFO:_master_model_container: 2
2025-06-15 22:36:11,895:INFO:_display_container: 2
2025-06-15 22:36:11,896:INFO:Lasso(random_state=123)
2025-06-15 22:36:11,896:INFO:create_model() successfully completed......................................
2025-06-15 22:36:12,007:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:12,007:INFO:Creating metrics dataframe
2025-06-15 22:36:12,009:INFO:Initializing Ridge Regression
2025-06-15 22:36:12,010:INFO:Total runtime is 0.12883970737457276 minutes
2025-06-15 22:36:12,010:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:12,010:INFO:Initializing create_model()
2025-06-15 22:36:12,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=ridge, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:12,010:INFO:Checking exceptions
2025-06-15 22:36:12,010:INFO:Importing libraries
2025-06-15 22:36:12,010:INFO:Copying training dataset
2025-06-15 22:36:12,014:INFO:Defining folds
2025-06-15 22:36:12,014:INFO:Declaring metric variables
2025-06-15 22:36:12,014:INFO:Importing untrained model
2025-06-15 22:36:12,014:INFO:Ridge Regression Imported successfully
2025-06-15 22:36:12,015:INFO:Starting cross validation
2025-06-15 22:36:12,016:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:15,329:INFO:Calculating mean and std
2025-06-15 22:36:15,330:INFO:Creating metrics dataframe
2025-06-15 22:36:15,332:INFO:Uploading results into container
2025-06-15 22:36:15,332:INFO:Uploading model into container now
2025-06-15 22:36:15,332:INFO:_master_model_container: 3
2025-06-15 22:36:15,332:INFO:_display_container: 2
2025-06-15 22:36:15,333:INFO:Ridge(random_state=123)
2025-06-15 22:36:15,333:INFO:create_model() successfully completed......................................
2025-06-15 22:36:15,446:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:15,446:INFO:Creating metrics dataframe
2025-06-15 22:36:15,448:INFO:Initializing Elastic Net
2025-06-15 22:36:15,448:INFO:Total runtime is 0.1861440380414327 minutes
2025-06-15 22:36:15,449:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:15,449:INFO:Initializing create_model()
2025-06-15 22:36:15,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=en, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:15,449:INFO:Checking exceptions
2025-06-15 22:36:15,449:INFO:Importing libraries
2025-06-15 22:36:15,449:INFO:Copying training dataset
2025-06-15 22:36:15,453:INFO:Defining folds
2025-06-15 22:36:15,453:INFO:Declaring metric variables
2025-06-15 22:36:15,453:INFO:Importing untrained model
2025-06-15 22:36:15,454:INFO:Elastic Net Imported successfully
2025-06-15 22:36:15,454:INFO:Starting cross validation
2025-06-15 22:36:15,456:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:18,759:INFO:Calculating mean and std
2025-06-15 22:36:18,760:INFO:Creating metrics dataframe
2025-06-15 22:36:18,762:INFO:Uploading results into container
2025-06-15 22:36:18,762:INFO:Uploading model into container now
2025-06-15 22:36:18,762:INFO:_master_model_container: 4
2025-06-15 22:36:18,763:INFO:_display_container: 2
2025-06-15 22:36:18,763:INFO:ElasticNet(random_state=123)
2025-06-15 22:36:18,763:INFO:create_model() successfully completed......................................
2025-06-15 22:36:18,877:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:18,878:INFO:Creating metrics dataframe
2025-06-15 22:36:18,880:INFO:Initializing Least Angle Regression
2025-06-15 22:36:18,880:INFO:Total runtime is 0.2433415373166402 minutes
2025-06-15 22:36:18,880:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:18,880:INFO:Initializing create_model()
2025-06-15 22:36:18,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=lar, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:18,881:INFO:Checking exceptions
2025-06-15 22:36:18,881:INFO:Importing libraries
2025-06-15 22:36:18,881:INFO:Copying training dataset
2025-06-15 22:36:18,884:INFO:Defining folds
2025-06-15 22:36:18,885:INFO:Declaring metric variables
2025-06-15 22:36:18,885:INFO:Importing untrained model
2025-06-15 22:36:18,885:INFO:Least Angle Regression Imported successfully
2025-06-15 22:36:18,885:INFO:Starting cross validation
2025-06-15 22:36:18,887:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:22,262:INFO:Calculating mean and std
2025-06-15 22:36:22,263:INFO:Creating metrics dataframe
2025-06-15 22:36:22,266:INFO:Uploading results into container
2025-06-15 22:36:22,266:INFO:Uploading model into container now
2025-06-15 22:36:22,267:INFO:_master_model_container: 5
2025-06-15 22:36:22,267:INFO:_display_container: 2
2025-06-15 22:36:22,267:INFO:Lars(random_state=123)
2025-06-15 22:36:22,268:INFO:create_model() successfully completed......................................
2025-06-15 22:36:22,394:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:22,394:INFO:Creating metrics dataframe
2025-06-15 22:36:22,396:INFO:Initializing Lasso Least Angle Regression
2025-06-15 22:36:22,397:INFO:Total runtime is 0.30195528268814087 minutes
2025-06-15 22:36:22,397:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:22,397:INFO:Initializing create_model()
2025-06-15 22:36:22,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=llar, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:22,397:INFO:Checking exceptions
2025-06-15 22:36:22,397:INFO:Importing libraries
2025-06-15 22:36:22,397:INFO:Copying training dataset
2025-06-15 22:36:22,401:INFO:Defining folds
2025-06-15 22:36:22,401:INFO:Declaring metric variables
2025-06-15 22:36:22,401:INFO:Importing untrained model
2025-06-15 22:36:22,402:INFO:Lasso Least Angle Regression Imported successfully
2025-06-15 22:36:22,402:INFO:Starting cross validation
2025-06-15 22:36:22,404:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:25,703:INFO:Calculating mean and std
2025-06-15 22:36:25,704:INFO:Creating metrics dataframe
2025-06-15 22:36:25,706:INFO:Uploading results into container
2025-06-15 22:36:25,706:INFO:Uploading model into container now
2025-06-15 22:36:25,706:INFO:_master_model_container: 6
2025-06-15 22:36:25,706:INFO:_display_container: 2
2025-06-15 22:36:25,707:INFO:LassoLars(random_state=123)
2025-06-15 22:36:25,707:INFO:create_model() successfully completed......................................
2025-06-15 22:36:25,823:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:25,823:INFO:Creating metrics dataframe
2025-06-15 22:36:25,825:INFO:Initializing Orthogonal Matching Pursuit
2025-06-15 22:36:25,825:INFO:Total runtime is 0.3590921640396118 minutes
2025-06-15 22:36:25,826:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:25,826:INFO:Initializing create_model()
2025-06-15 22:36:25,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=omp, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:25,826:INFO:Checking exceptions
2025-06-15 22:36:25,826:INFO:Importing libraries
2025-06-15 22:36:25,826:INFO:Copying training dataset
2025-06-15 22:36:25,830:INFO:Defining folds
2025-06-15 22:36:25,830:INFO:Declaring metric variables
2025-06-15 22:36:25,830:INFO:Importing untrained model
2025-06-15 22:36:25,830:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-15 22:36:25,830:INFO:Starting cross validation
2025-06-15 22:36:25,832:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:25,966:INFO:Calculating mean and std
2025-06-15 22:36:25,967:INFO:Creating metrics dataframe
2025-06-15 22:36:25,968:INFO:Uploading results into container
2025-06-15 22:36:25,969:INFO:Uploading model into container now
2025-06-15 22:36:25,969:INFO:_master_model_container: 7
2025-06-15 22:36:25,969:INFO:_display_container: 2
2025-06-15 22:36:25,969:INFO:OrthogonalMatchingPursuit()
2025-06-15 22:36:25,969:INFO:create_model() successfully completed......................................
2025-06-15 22:36:26,072:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:26,073:INFO:Creating metrics dataframe
2025-06-15 22:36:26,075:INFO:Initializing Bayesian Ridge
2025-06-15 22:36:26,075:INFO:Total runtime is 0.36326444149017334 minutes
2025-06-15 22:36:26,075:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:26,075:INFO:Initializing create_model()
2025-06-15 22:36:26,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=br, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:26,075:INFO:Checking exceptions
2025-06-15 22:36:26,075:INFO:Importing libraries
2025-06-15 22:36:26,076:INFO:Copying training dataset
2025-06-15 22:36:26,079:INFO:Defining folds
2025-06-15 22:36:26,079:INFO:Declaring metric variables
2025-06-15 22:36:26,079:INFO:Importing untrained model
2025-06-15 22:36:26,080:INFO:Bayesian Ridge Imported successfully
2025-06-15 22:36:26,080:INFO:Starting cross validation
2025-06-15 22:36:26,081:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:26,228:INFO:Calculating mean and std
2025-06-15 22:36:26,229:INFO:Creating metrics dataframe
2025-06-15 22:36:26,230:INFO:Uploading results into container
2025-06-15 22:36:26,231:INFO:Uploading model into container now
2025-06-15 22:36:26,231:INFO:_master_model_container: 8
2025-06-15 22:36:26,231:INFO:_display_container: 2
2025-06-15 22:36:26,231:INFO:BayesianRidge()
2025-06-15 22:36:26,231:INFO:create_model() successfully completed......................................
2025-06-15 22:36:26,335:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:26,335:INFO:Creating metrics dataframe
2025-06-15 22:36:26,338:INFO:Initializing Passive Aggressive Regressor
2025-06-15 22:36:26,338:INFO:Total runtime is 0.3676371971766154 minutes
2025-06-15 22:36:26,338:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:26,338:INFO:Initializing create_model()
2025-06-15 22:36:26,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=par, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:26,338:INFO:Checking exceptions
2025-06-15 22:36:26,338:INFO:Importing libraries
2025-06-15 22:36:26,338:INFO:Copying training dataset
2025-06-15 22:36:26,342:INFO:Defining folds
2025-06-15 22:36:26,342:INFO:Declaring metric variables
2025-06-15 22:36:26,342:INFO:Importing untrained model
2025-06-15 22:36:26,342:INFO:Passive Aggressive Regressor Imported successfully
2025-06-15 22:36:26,343:INFO:Starting cross validation
2025-06-15 22:36:26,344:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:26,479:INFO:Calculating mean and std
2025-06-15 22:36:26,480:INFO:Creating metrics dataframe
2025-06-15 22:36:26,481:INFO:Uploading results into container
2025-06-15 22:36:26,482:INFO:Uploading model into container now
2025-06-15 22:36:26,482:INFO:_master_model_container: 9
2025-06-15 22:36:26,482:INFO:_display_container: 2
2025-06-15 22:36:26,482:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-15 22:36:26,482:INFO:create_model() successfully completed......................................
2025-06-15 22:36:26,586:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:26,586:INFO:Creating metrics dataframe
2025-06-15 22:36:26,588:INFO:Initializing Huber Regressor
2025-06-15 22:36:26,589:INFO:Total runtime is 0.3718119263648987 minutes
2025-06-15 22:36:26,589:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:26,589:INFO:Initializing create_model()
2025-06-15 22:36:26,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=huber, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:26,589:INFO:Checking exceptions
2025-06-15 22:36:26,589:INFO:Importing libraries
2025-06-15 22:36:26,589:INFO:Copying training dataset
2025-06-15 22:36:26,593:INFO:Defining folds
2025-06-15 22:36:26,593:INFO:Declaring metric variables
2025-06-15 22:36:26,593:INFO:Importing untrained model
2025-06-15 22:36:26,593:INFO:Huber Regressor Imported successfully
2025-06-15 22:36:26,593:INFO:Starting cross validation
2025-06-15 22:36:26,595:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:26,741:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 2.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-06-15 22:36:26,741:INFO:Calculating mean and std
2025-06-15 22:36:26,742:INFO:Creating metrics dataframe
2025-06-15 22:36:26,743:INFO:Uploading results into container
2025-06-15 22:36:26,743:INFO:Uploading model into container now
2025-06-15 22:36:26,744:INFO:_master_model_container: 10
2025-06-15 22:36:26,744:INFO:_display_container: 2
2025-06-15 22:36:26,744:INFO:HuberRegressor()
2025-06-15 22:36:26,744:INFO:create_model() successfully completed......................................
2025-06-15 22:36:26,847:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:26,847:INFO:Creating metrics dataframe
2025-06-15 22:36:26,849:INFO:Initializing K Neighbors Regressor
2025-06-15 22:36:26,849:INFO:Total runtime is 0.3761687437693278 minutes
2025-06-15 22:36:26,849:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:26,850:INFO:Initializing create_model()
2025-06-15 22:36:26,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=knn, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:26,850:INFO:Checking exceptions
2025-06-15 22:36:26,850:INFO:Importing libraries
2025-06-15 22:36:26,850:INFO:Copying training dataset
2025-06-15 22:36:26,853:INFO:Defining folds
2025-06-15 22:36:26,853:INFO:Declaring metric variables
2025-06-15 22:36:26,854:INFO:Importing untrained model
2025-06-15 22:36:26,854:INFO:K Neighbors Regressor Imported successfully
2025-06-15 22:36:26,854:INFO:Starting cross validation
2025-06-15 22:36:26,856:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:27,130:INFO:Calculating mean and std
2025-06-15 22:36:27,131:INFO:Creating metrics dataframe
2025-06-15 22:36:27,133:INFO:Uploading results into container
2025-06-15 22:36:27,133:INFO:Uploading model into container now
2025-06-15 22:36:27,133:INFO:_master_model_container: 11
2025-06-15 22:36:27,134:INFO:_display_container: 2
2025-06-15 22:36:27,134:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:36:27,134:INFO:create_model() successfully completed......................................
2025-06-15 22:36:27,237:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:27,237:INFO:Creating metrics dataframe
2025-06-15 22:36:27,239:INFO:Initializing Decision Tree Regressor
2025-06-15 22:36:27,239:INFO:Total runtime is 0.38266352415084837 minutes
2025-06-15 22:36:27,239:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:27,240:INFO:Initializing create_model()
2025-06-15 22:36:27,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=dt, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:27,240:INFO:Checking exceptions
2025-06-15 22:36:27,240:INFO:Importing libraries
2025-06-15 22:36:27,240:INFO:Copying training dataset
2025-06-15 22:36:27,243:INFO:Defining folds
2025-06-15 22:36:27,243:INFO:Declaring metric variables
2025-06-15 22:36:27,244:INFO:Importing untrained model
2025-06-15 22:36:27,244:INFO:Decision Tree Regressor Imported successfully
2025-06-15 22:36:27,244:INFO:Starting cross validation
2025-06-15 22:36:27,246:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:27,380:INFO:Calculating mean and std
2025-06-15 22:36:27,381:INFO:Creating metrics dataframe
2025-06-15 22:36:27,382:INFO:Uploading results into container
2025-06-15 22:36:27,383:INFO:Uploading model into container now
2025-06-15 22:36:27,383:INFO:_master_model_container: 12
2025-06-15 22:36:27,383:INFO:_display_container: 2
2025-06-15 22:36:27,383:INFO:DecisionTreeRegressor(random_state=123)
2025-06-15 22:36:27,383:INFO:create_model() successfully completed......................................
2025-06-15 22:36:27,487:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:27,488:INFO:Creating metrics dataframe
2025-06-15 22:36:27,490:INFO:Initializing Random Forest Regressor
2025-06-15 22:36:27,490:INFO:Total runtime is 0.386850368976593 minutes
2025-06-15 22:36:27,490:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:27,490:INFO:Initializing create_model()
2025-06-15 22:36:27,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=rf, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:27,490:INFO:Checking exceptions
2025-06-15 22:36:27,490:INFO:Importing libraries
2025-06-15 22:36:27,491:INFO:Copying training dataset
2025-06-15 22:36:27,494:INFO:Defining folds
2025-06-15 22:36:27,494:INFO:Declaring metric variables
2025-06-15 22:36:27,494:INFO:Importing untrained model
2025-06-15 22:36:27,495:INFO:Random Forest Regressor Imported successfully
2025-06-15 22:36:27,495:INFO:Starting cross validation
2025-06-15 22:36:27,497:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:27,774:INFO:Calculating mean and std
2025-06-15 22:36:27,775:INFO:Creating metrics dataframe
2025-06-15 22:36:27,776:INFO:Uploading results into container
2025-06-15 22:36:27,777:INFO:Uploading model into container now
2025-06-15 22:36:27,777:INFO:_master_model_container: 13
2025-06-15 22:36:27,777:INFO:_display_container: 2
2025-06-15 22:36:27,777:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:36:27,777:INFO:create_model() successfully completed......................................
2025-06-15 22:36:27,880:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:27,881:INFO:Creating metrics dataframe
2025-06-15 22:36:27,883:INFO:Initializing Extra Trees Regressor
2025-06-15 22:36:27,883:INFO:Total runtime is 0.39339445829391473 minutes
2025-06-15 22:36:27,883:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:27,883:INFO:Initializing create_model()
2025-06-15 22:36:27,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=et, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:27,883:INFO:Checking exceptions
2025-06-15 22:36:27,884:INFO:Importing libraries
2025-06-15 22:36:27,884:INFO:Copying training dataset
2025-06-15 22:36:27,887:INFO:Defining folds
2025-06-15 22:36:27,887:INFO:Declaring metric variables
2025-06-15 22:36:27,887:INFO:Importing untrained model
2025-06-15 22:36:27,888:INFO:Extra Trees Regressor Imported successfully
2025-06-15 22:36:27,888:INFO:Starting cross validation
2025-06-15 22:36:27,890:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:28,132:INFO:Calculating mean and std
2025-06-15 22:36:28,133:INFO:Creating metrics dataframe
2025-06-15 22:36:28,134:INFO:Uploading results into container
2025-06-15 22:36:28,135:INFO:Uploading model into container now
2025-06-15 22:36:28,135:INFO:_master_model_container: 14
2025-06-15 22:36:28,135:INFO:_display_container: 2
2025-06-15 22:36:28,135:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:36:28,135:INFO:create_model() successfully completed......................................
2025-06-15 22:36:28,241:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:28,241:INFO:Creating metrics dataframe
2025-06-15 22:36:28,243:INFO:Initializing AdaBoost Regressor
2025-06-15 22:36:28,243:INFO:Total runtime is 0.39938772519429516 minutes
2025-06-15 22:36:28,244:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:28,244:INFO:Initializing create_model()
2025-06-15 22:36:28,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=ada, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:28,244:INFO:Checking exceptions
2025-06-15 22:36:28,244:INFO:Importing libraries
2025-06-15 22:36:28,244:INFO:Copying training dataset
2025-06-15 22:36:28,248:INFO:Defining folds
2025-06-15 22:36:28,248:INFO:Declaring metric variables
2025-06-15 22:36:28,248:INFO:Importing untrained model
2025-06-15 22:36:28,248:INFO:AdaBoost Regressor Imported successfully
2025-06-15 22:36:28,249:INFO:Starting cross validation
2025-06-15 22:36:28,250:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:28,448:INFO:Calculating mean and std
2025-06-15 22:36:28,449:INFO:Creating metrics dataframe
2025-06-15 22:36:28,450:INFO:Uploading results into container
2025-06-15 22:36:28,450:INFO:Uploading model into container now
2025-06-15 22:36:28,451:INFO:_master_model_container: 15
2025-06-15 22:36:28,451:INFO:_display_container: 2
2025-06-15 22:36:28,451:INFO:AdaBoostRegressor(random_state=123)
2025-06-15 22:36:28,451:INFO:create_model() successfully completed......................................
2025-06-15 22:36:28,555:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:28,555:INFO:Creating metrics dataframe
2025-06-15 22:36:28,558:INFO:Initializing Gradient Boosting Regressor
2025-06-15 22:36:28,558:INFO:Total runtime is 0.4046400586764017 minutes
2025-06-15 22:36:28,558:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:28,558:INFO:Initializing create_model()
2025-06-15 22:36:28,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=gbr, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:28,558:INFO:Checking exceptions
2025-06-15 22:36:28,558:INFO:Importing libraries
2025-06-15 22:36:28,558:INFO:Copying training dataset
2025-06-15 22:36:28,562:INFO:Defining folds
2025-06-15 22:36:28,562:INFO:Declaring metric variables
2025-06-15 22:36:28,562:INFO:Importing untrained model
2025-06-15 22:36:28,563:INFO:Gradient Boosting Regressor Imported successfully
2025-06-15 22:36:28,563:INFO:Starting cross validation
2025-06-15 22:36:28,565:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:28,744:INFO:Calculating mean and std
2025-06-15 22:36:28,745:INFO:Creating metrics dataframe
2025-06-15 22:36:28,746:INFO:Uploading results into container
2025-06-15 22:36:28,747:INFO:Uploading model into container now
2025-06-15 22:36:28,747:INFO:_master_model_container: 16
2025-06-15 22:36:28,747:INFO:_display_container: 2
2025-06-15 22:36:28,747:INFO:GradientBoostingRegressor(random_state=123)
2025-06-15 22:36:28,747:INFO:create_model() successfully completed......................................
2025-06-15 22:36:28,851:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:28,851:INFO:Creating metrics dataframe
2025-06-15 22:36:28,853:INFO:Initializing Light Gradient Boosting Machine
2025-06-15 22:36:28,854:INFO:Total runtime is 0.4095777869224547 minutes
2025-06-15 22:36:28,854:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:28,854:INFO:Initializing create_model()
2025-06-15 22:36:28,854:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=lightgbm, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:28,854:INFO:Checking exceptions
2025-06-15 22:36:28,854:INFO:Importing libraries
2025-06-15 22:36:28,854:INFO:Copying training dataset
2025-06-15 22:36:28,858:INFO:Defining folds
2025-06-15 22:36:28,858:INFO:Declaring metric variables
2025-06-15 22:36:28,858:INFO:Importing untrained model
2025-06-15 22:36:28,858:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-15 22:36:28,859:INFO:Starting cross validation
2025-06-15 22:36:28,860:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:29,071:INFO:Calculating mean and std
2025-06-15 22:36:29,072:INFO:Creating metrics dataframe
2025-06-15 22:36:29,074:INFO:Uploading results into container
2025-06-15 22:36:29,074:INFO:Uploading model into container now
2025-06-15 22:36:29,075:INFO:_master_model_container: 17
2025-06-15 22:36:29,075:INFO:_display_container: 2
2025-06-15 22:36:29,075:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:36:29,076:INFO:create_model() successfully completed......................................
2025-06-15 22:36:29,203:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:29,203:INFO:Creating metrics dataframe
2025-06-15 22:36:29,206:INFO:Initializing Dummy Regressor
2025-06-15 22:36:29,206:INFO:Total runtime is 0.4154494047164916 minutes
2025-06-15 22:36:29,206:INFO:SubProcess create_model() called ==================================
2025-06-15 22:36:29,206:INFO:Initializing create_model()
2025-06-15 22:36:29,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=dummy, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4CF14790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:29,206:INFO:Checking exceptions
2025-06-15 22:36:29,206:INFO:Importing libraries
2025-06-15 22:36:29,207:INFO:Copying training dataset
2025-06-15 22:36:29,210:INFO:Defining folds
2025-06-15 22:36:29,210:INFO:Declaring metric variables
2025-06-15 22:36:29,211:INFO:Importing untrained model
2025-06-15 22:36:29,211:INFO:Dummy Regressor Imported successfully
2025-06-15 22:36:29,211:INFO:Starting cross validation
2025-06-15 22:36:29,213:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:36:29,347:INFO:Calculating mean and std
2025-06-15 22:36:29,348:INFO:Creating metrics dataframe
2025-06-15 22:36:29,349:INFO:Uploading results into container
2025-06-15 22:36:29,350:INFO:Uploading model into container now
2025-06-15 22:36:29,350:INFO:_master_model_container: 18
2025-06-15 22:36:29,350:INFO:_display_container: 2
2025-06-15 22:36:29,350:INFO:DummyRegressor()
2025-06-15 22:36:29,350:INFO:create_model() successfully completed......................................
2025-06-15 22:36:29,459:INFO:SubProcess create_model() end ==================================
2025-06-15 22:36:29,459:INFO:Creating metrics dataframe
2025-06-15 22:36:29,463:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-15 22:36:29,465:INFO:Initializing create_model()
2025-06-15 22:36:29,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:36:29,465:INFO:Checking exceptions
2025-06-15 22:36:29,466:INFO:Importing libraries
2025-06-15 22:36:29,466:INFO:Copying training dataset
2025-06-15 22:36:29,469:INFO:Defining folds
2025-06-15 22:36:29,470:INFO:Declaring metric variables
2025-06-15 22:36:29,470:INFO:Importing untrained model
2025-06-15 22:36:29,470:INFO:Declaring custom model
2025-06-15 22:36:29,470:INFO:K Neighbors Regressor Imported successfully
2025-06-15 22:36:29,473:INFO:Cross validation set to False
2025-06-15 22:36:29,473:INFO:Fitting Model
2025-06-15 22:36:29,553:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:36:29,553:INFO:create_model() successfully completed......................................
2025-06-15 22:36:29,674:INFO:_master_model_container: 18
2025-06-15 22:36:29,674:INFO:_display_container: 2
2025-06-15 22:36:29,674:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:36:29,674:INFO:compare_models() successfully completed......................................
2025-06-15 22:39:15,084:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  

2025-06-15 22:39:15,104:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  model = sm.OLS(y, X).fit()

2025-06-15 22:39:15,456:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  )

2025-06-15 22:39:15,999:INFO:Initializing plot_model()
2025-06-15 22:39:15,999:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=KNeighborsRegressor(n_jobs=-1), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:39:15,999:INFO:Checking exceptions
2025-06-15 22:39:15,999:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:39:16,001:INFO:Preloading libraries
2025-06-15 22:39:16,002:INFO:Copying training dataset
2025-06-15 22:39:16,002:INFO:Plot type: residuals
2025-06-15 22:39:16,455:INFO:Fitting Model
2025-06-15 22:39:16,456:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names
  warnings.warn(

2025-06-15 22:39:16,789:INFO:Scoring test/hold-out set
2025-06-15 22:39:17,555:INFO:Visual Rendered Successfully
2025-06-15 22:39:17,699:INFO:plot_model() successfully completed......................................
2025-06-15 22:39:17,699:INFO:Initializing plot_model()
2025-06-15 22:39:17,700:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=KNeighborsRegressor(n_jobs=-1), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:39:17,700:INFO:Checking exceptions
2025-06-15 22:39:17,700:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:39:17,701:INFO:Preloading libraries
2025-06-15 22:39:17,702:INFO:Copying training dataset
2025-06-15 22:39:17,702:INFO:Plot type: error
2025-06-15 22:39:18,081:INFO:Fitting Model
2025-06-15 22:39:18,081:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names
  warnings.warn(

2025-06-15 22:39:18,082:INFO:Scoring test/hold-out set
2025-06-15 22:39:18,345:INFO:Visual Rendered Successfully
2025-06-15 22:39:18,456:INFO:plot_model() successfully completed......................................
2025-06-15 22:39:37,565:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  

2025-06-15 22:39:37,581:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  model = sm.OLS(y, X).fit()

2025-06-15 22:39:37,910:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  )

2025-06-15 22:39:38,434:INFO:Initializing predict_model()
2025-06-15 22:39:38,434:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D50CC76D0>, estimator=KNeighborsRegressor(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024D4F84B240>)
2025-06-15 22:39:38,434:INFO:Checking exceptions
2025-06-15 22:39:38,434:INFO:Preloading libraries
2025-06-15 22:39:38,434:INFO:Set up data.
2025-06-15 22:39:38,438:INFO:Set up index.
2025-06-15 22:50:50,755:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:50:50,772:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:11,339:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:11,356:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:19,935:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:19,953:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:23,876:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:23,894:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:29,390:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:29,407:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:32,745:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:32,763:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:33,113:INFO:PyCaret ClusteringExperiment
2025-06-15 22:51:33,113:INFO:Logging name: cluster-default-name
2025-06-15 22:51:33,113:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-06-15 22:51:33,113:INFO:version 3.3.2
2025-06-15 22:51:33,113:INFO:Initializing setup()
2025-06-15 22:51:33,113:INFO:self.USI: d9f4
2025-06-15 22:51:33,113:INFO:self._variable_keys: {'pipeline', 'X', 'USI', '_available_plots', 'idx', 'exp_name_log', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'html_param', 'log_plots_param', 'logging_param', 'exp_id', 'memory', 'data', 'gpu_n_jobs_param', 'seed'}
2025-06-15 22:51:33,113:INFO:Checking environment
2025-06-15 22:51:33,114:INFO:python_version: 3.11.4
2025-06-15 22:51:33,114:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:51:33,114:INFO:machine: AMD64
2025-06-15 22:51:33,114:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:51:33,118:INFO:Memory: svmem(total=17127211008, available=5781774336, percent=66.2, used=11345436672, free=5781774336)
2025-06-15 22:51:33,118:INFO:Physical Core: 6
2025-06-15 22:51:33,118:INFO:Logical Core: 12
2025-06-15 22:51:33,118:INFO:Checking libraries
2025-06-15 22:51:33,118:INFO:System:
2025-06-15 22:51:33,118:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:51:33,119:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:51:33,119:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:51:33,119:INFO:PyCaret required dependencies:
2025-06-15 22:51:33,119:INFO:                 pip: 25.1.1
2025-06-15 22:51:33,119:INFO:          setuptools: 65.5.0
2025-06-15 22:51:33,119:INFO:             pycaret: 3.3.2
2025-06-15 22:51:33,119:INFO:             IPython: 9.3.0
2025-06-15 22:51:33,119:INFO:          ipywidgets: 8.1.7
2025-06-15 22:51:33,119:INFO:                tqdm: 4.67.1
2025-06-15 22:51:33,119:INFO:               numpy: 1.26.4
2025-06-15 22:51:33,119:INFO:              pandas: 2.1.4
2025-06-15 22:51:33,119:INFO:              jinja2: 3.1.6
2025-06-15 22:51:33,119:INFO:               scipy: 1.11.4
2025-06-15 22:51:33,119:INFO:              joblib: 1.3.2
2025-06-15 22:51:33,119:INFO:             sklearn: 1.4.2
2025-06-15 22:51:33,119:INFO:                pyod: 2.0.5
2025-06-15 22:51:33,119:INFO:            imblearn: 0.13.0
2025-06-15 22:51:33,120:INFO:   category_encoders: 2.7.0
2025-06-15 22:51:33,120:INFO:            lightgbm: 4.6.0
2025-06-15 22:51:33,120:INFO:               numba: 0.61.2
2025-06-15 22:51:33,120:INFO:            requests: 2.32.4
2025-06-15 22:51:33,120:INFO:          matplotlib: 3.7.5
2025-06-15 22:51:33,120:INFO:          scikitplot: 0.3.7
2025-06-15 22:51:33,120:INFO:         yellowbrick: 1.5
2025-06-15 22:51:33,120:INFO:              plotly: 5.24.1
2025-06-15 22:51:33,120:INFO:    plotly-resampler: Not installed
2025-06-15 22:51:33,120:INFO:             kaleido: 0.2.1
2025-06-15 22:51:33,120:INFO:           schemdraw: 0.15
2025-06-15 22:51:33,120:INFO:         statsmodels: 0.14.4
2025-06-15 22:51:33,120:INFO:              sktime: 0.26.0
2025-06-15 22:51:33,120:INFO:               tbats: 1.1.3
2025-06-15 22:51:33,120:INFO:            pmdarima: 2.0.4
2025-06-15 22:51:33,120:INFO:              psutil: 7.0.0
2025-06-15 22:51:33,120:INFO:          markupsafe: 3.0.2
2025-06-15 22:51:33,120:INFO:             pickle5: Not installed
2025-06-15 22:51:33,120:INFO:         cloudpickle: 3.1.1
2025-06-15 22:51:33,120:INFO:         deprecation: 2.1.0
2025-06-15 22:51:33,120:INFO:              xxhash: 3.5.0
2025-06-15 22:51:33,121:INFO:           wurlitzer: Not installed
2025-06-15 22:51:33,121:INFO:PyCaret optional dependencies:
2025-06-15 22:51:33,121:INFO:                shap: Not installed
2025-06-15 22:51:33,121:INFO:           interpret: Not installed
2025-06-15 22:51:33,121:INFO:                umap: Not installed
2025-06-15 22:51:33,121:INFO:     ydata_profiling: Not installed
2025-06-15 22:51:33,121:INFO:  explainerdashboard: Not installed
2025-06-15 22:51:33,121:INFO:             autoviz: Not installed
2025-06-15 22:51:33,121:INFO:           fairlearn: Not installed
2025-06-15 22:51:33,121:INFO:          deepchecks: Not installed
2025-06-15 22:51:33,121:INFO:             xgboost: Not installed
2025-06-15 22:51:33,121:INFO:            catboost: Not installed
2025-06-15 22:51:33,121:INFO:              kmodes: Not installed
2025-06-15 22:51:33,121:INFO:             mlxtend: Not installed
2025-06-15 22:51:33,121:INFO:       statsforecast: Not installed
2025-06-15 22:51:33,121:INFO:        tune_sklearn: Not installed
2025-06-15 22:51:33,121:INFO:                 ray: Not installed
2025-06-15 22:51:33,121:INFO:            hyperopt: Not installed
2025-06-15 22:51:33,121:INFO:              optuna: Not installed
2025-06-15 22:51:33,122:INFO:               skopt: Not installed
2025-06-15 22:51:33,122:INFO:              mlflow: Not installed
2025-06-15 22:51:33,122:INFO:              gradio: Not installed
2025-06-15 22:51:33,122:INFO:             fastapi: Not installed
2025-06-15 22:51:33,122:INFO:             uvicorn: Not installed
2025-06-15 22:51:33,122:INFO:              m2cgen: Not installed
2025-06-15 22:51:33,122:INFO:           evidently: Not installed
2025-06-15 22:51:33,122:INFO:               fugue: Not installed
2025-06-15 22:51:33,122:INFO:           streamlit: 1.42.2
2025-06-15 22:51:33,122:INFO:             prophet: Not installed
2025-06-15 22:51:33,122:INFO:None
2025-06-15 22:51:33,122:INFO:Set up data.
2025-06-15 22:51:33,127:INFO:Set up index.
2025-06-15 22:51:33,127:INFO:Assigning column types.
2025-06-15 22:51:33,130:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-06-15 22:51:33,130:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-06-15 22:51:33,130:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,130:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-06-15 22:51:33,130:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,130:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-06-15 22:51:33,131:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,131:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,132:INFO:Preparing preprocessing pipeline...
2025-06-15 22:51:33,132:INFO:Set up date feature engineering.
2025-06-15 22:51:33,132:INFO:Set up simple imputation.
2025-06-15 22:51:33,134:INFO:Set up encoding of categorical features.
2025-06-15 22:51:33,294:INFO:Finished creating preprocessing pipeline.
2025-06-15 22:51:33,302:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['trending_date', 'publish_time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'dislikes',
                                             'likes'],
                                    transformer=SimpleImputer())),
                ('categorical_impu...
                 TransformerWrapper(include=['title', 'channel_title', 'tags',
                                             'description', 'category_name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['title', 'channel_title', 'tags',
                                             'description', 'category_name'],
                                    transformer=OneHotEncoder(cols=['title',
                                                                    'channel_title',
                                                                    'tags',
                                                                    'description',
                                                                    'category_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-06-15 22:51:33,302:INFO:Creating final display dataframe.
2025-06-15 22:51:33,577:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape             (100, 11)
2     Transformed data shape            (100, 418)
3           Numeric features                     4
4              Date features                     2
5       Categorical features                     5
6   Rows with missing values                  1.0%
7                 Preprocess                  True
8            Imputation type                simple
9         Numeric imputation                  mean
10    Categorical imputation                  mode
11  Maximum one-hot encoding                    -1
12           Encoding method                  None
13                  CPU Jobs                    -1
14                   Use GPU                 False
15            Log Experiment                 False
16           Experiment Name  cluster-default-name
17                       USI                  d9f4
2025-06-15 22:51:33,581:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,581:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:51:33,582:INFO:setup() successfully completed in 0.49s...............
2025-06-15 22:51:33,582:INFO:Initializing create_model()
2025-06-15 22:51:33,582:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-06-15 22:51:33,582:INFO:Checking exceptions
2025-06-15 22:51:33,659:INFO:Importing untrained model
2025-06-15 22:51:33,659:INFO:K-Means Clustering Imported successfully
2025-06-15 22:51:33,664:INFO:Fitting Model
2025-06-15 22:51:33,831:INFO:KMeans(n_clusters=4, random_state=123)
2025-06-15 22:51:33,831:INFO:create_models() successfully completed......................................
2025-06-15 22:51:33,832:INFO:Uploading results into container
2025-06-15 22:51:33,832:INFO:Uploading model into container now
2025-06-15 22:51:33,838:INFO:_master_model_container: 1
2025-06-15 22:51:33,838:INFO:_display_container: 2
2025-06-15 22:51:33,839:INFO:KMeans(n_clusters=4, random_state=123)
2025-06-15 22:51:33,839:INFO:create_model() successfully completed......................................
2025-06-15 22:51:42,275:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  X = sm.add_constant(df_filtered["views"])

2025-06-15 22:51:42,291:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  

2025-06-15 22:51:42,622:INFO:Initializing plot_model()
2025-06-15 22:51:42,622:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), plot=elbow, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:51:42,622:INFO:Checking exceptions
2025-06-15 22:51:42,622:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:51:42,623:INFO:Preloading libraries
2025-06-15 22:51:42,623:INFO:Copying training dataset
2025-06-15 22:51:42,623:INFO:Plot type: elbow
2025-06-15 22:51:42,706:INFO:Fitting Model
2025-06-15 22:51:43,182:INFO:Visual Rendered Successfully
2025-06-15 22:51:43,322:INFO:plot_model() successfully completed......................................
2025-06-15 22:51:43,322:INFO:Initializing plot_model()
2025-06-15 22:51:43,322:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), plot=cluster, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:51:43,323:INFO:Checking exceptions
2025-06-15 22:51:43,323:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:51:43,324:INFO:Preloading libraries
2025-06-15 22:51:43,324:INFO:Copying training dataset
2025-06-15 22:51:43,324:INFO:Plot type: cluster
2025-06-15 22:51:43,325:INFO:SubProcess assign_model() called ==================================
2025-06-15 22:51:43,325:INFO:Initializing assign_model()
2025-06-15 22:51:43,325:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, model=KMeans(n_clusters=4, random_state=123), transformation=True, score=True, verbose=False)
2025-06-15 22:51:43,325:INFO:Checking exceptions
2025-06-15 22:51:43,325:INFO:Determining Trained Model
2025-06-15 22:51:43,325:INFO:Trained Model : K-Means Clustering
2025-06-15 22:51:43,325:INFO:Copying data
2025-06-15 22:51:43,398:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2025-06-15 22:51:43,399:INFO:(100, 419)
2025-06-15 22:51:43,399:INFO:assign_model() successfully completed......................................
2025-06-15 22:51:43,399:INFO:SubProcess assign_model() end ==================================
2025-06-15 22:51:43,400:INFO:Fitting PCA()
2025-06-15 22:51:43,434:INFO:Sorting dataframe
2025-06-15 22:51:43,435:INFO:Rendering Visual
2025-06-15 22:51:43,721:INFO:Visual Rendered Successfully
2025-06-15 22:51:43,842:INFO:plot_model() successfully completed......................................
2025-06-15 22:51:56,750:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:51:56,766:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:51:57,098:INFO:Initializing predict_model()
2025-06-15 22:51:57,099:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:52:07,338:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:52:07,355:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:52:07,696:INFO:Initializing predict_model()
2025-06-15 22:52:07,696:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:52:24,217:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:159: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:52:24,234:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:162: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:52:24,577:INFO:Initializing predict_model()
2025-06-15 22:52:24,577:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:56:51,168:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:56:51,186:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:56:55,501:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:56:55,519:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:56:55,867:INFO:Initializing predict_model()
2025-06-15 22:56:55,867:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:57:01,846:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:01,864:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:02,199:INFO:Initializing plot_model()
2025-06-15 22:57:02,199:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), plot=elbow, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:57:02,199:INFO:Checking exceptions
2025-06-15 22:57:02,199:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:57:02,200:INFO:Preloading libraries
2025-06-15 22:57:02,200:INFO:Copying training dataset
2025-06-15 22:57:02,200:INFO:Plot type: elbow
2025-06-15 22:57:02,273:INFO:Fitting Model
2025-06-15 22:57:02,771:INFO:Visual Rendered Successfully
2025-06-15 22:57:02,921:INFO:plot_model() successfully completed......................................
2025-06-15 22:57:02,921:INFO:Initializing plot_model()
2025-06-15 22:57:02,921:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), plot=cluster, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:57:02,921:INFO:Checking exceptions
2025-06-15 22:57:02,922:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:57:02,922:INFO:Preloading libraries
2025-06-15 22:57:02,923:INFO:Copying training dataset
2025-06-15 22:57:02,923:INFO:Plot type: cluster
2025-06-15 22:57:02,923:INFO:SubProcess assign_model() called ==================================
2025-06-15 22:57:02,923:INFO:Initializing assign_model()
2025-06-15 22:57:02,923:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, model=KMeans(n_clusters=4, random_state=123), transformation=True, score=True, verbose=False)
2025-06-15 22:57:02,923:INFO:Checking exceptions
2025-06-15 22:57:02,923:INFO:Determining Trained Model
2025-06-15 22:57:02,924:INFO:Trained Model : K-Means Clustering
2025-06-15 22:57:02,924:INFO:Copying data
2025-06-15 22:57:02,995:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2025-06-15 22:57:02,996:INFO:(100, 419)
2025-06-15 22:57:02,996:INFO:assign_model() successfully completed......................................
2025-06-15 22:57:02,996:INFO:SubProcess assign_model() end ==================================
2025-06-15 22:57:02,997:INFO:Fitting PCA()
2025-06-15 22:57:03,028:INFO:Sorting dataframe
2025-06-15 22:57:03,029:INFO:Rendering Visual
2025-06-15 22:57:03,082:INFO:Visual Rendered Successfully
2025-06-15 22:57:03,206:INFO:plot_model() successfully completed......................................
2025-06-15 22:57:08,203:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:08,221:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:08,561:INFO:Initializing predict_model()
2025-06-15 22:57:08,561:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4D6862D0>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:57:36,624:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:36,641:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:36,983:INFO:PyCaret ClusteringExperiment
2025-06-15 22:57:36,983:INFO:Logging name: cluster-default-name
2025-06-15 22:57:36,983:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-06-15 22:57:36,983:INFO:version 3.3.2
2025-06-15 22:57:36,984:INFO:Initializing setup()
2025-06-15 22:57:36,984:INFO:self.USI: 49ac
2025-06-15 22:57:36,984:INFO:self._variable_keys: {'pipeline', 'X', 'USI', '_available_plots', 'idx', 'exp_name_log', 'n_jobs_param', '_ml_usecase', 'gpu_param', 'html_param', 'log_plots_param', 'logging_param', 'exp_id', 'memory', 'data', 'gpu_n_jobs_param', 'seed'}
2025-06-15 22:57:36,984:INFO:Checking environment
2025-06-15 22:57:36,984:INFO:python_version: 3.11.4
2025-06-15 22:57:36,984:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:57:36,984:INFO:machine: AMD64
2025-06-15 22:57:36,984:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:57:36,988:INFO:Memory: svmem(total=17127211008, available=5974695936, percent=65.1, used=11152515072, free=5974695936)
2025-06-15 22:57:36,988:INFO:Physical Core: 6
2025-06-15 22:57:36,988:INFO:Logical Core: 12
2025-06-15 22:57:36,988:INFO:Checking libraries
2025-06-15 22:57:36,988:INFO:System:
2025-06-15 22:57:36,988:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:57:36,988:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:57:36,988:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:57:36,988:INFO:PyCaret required dependencies:
2025-06-15 22:57:36,989:INFO:                 pip: 25.1.1
2025-06-15 22:57:36,989:INFO:          setuptools: 65.5.0
2025-06-15 22:57:36,989:INFO:             pycaret: 3.3.2
2025-06-15 22:57:36,989:INFO:             IPython: 9.3.0
2025-06-15 22:57:36,989:INFO:          ipywidgets: 8.1.7
2025-06-15 22:57:36,989:INFO:                tqdm: 4.67.1
2025-06-15 22:57:36,989:INFO:               numpy: 1.26.4
2025-06-15 22:57:36,989:INFO:              pandas: 2.1.4
2025-06-15 22:57:36,989:INFO:              jinja2: 3.1.6
2025-06-15 22:57:36,989:INFO:               scipy: 1.11.4
2025-06-15 22:57:36,989:INFO:              joblib: 1.3.2
2025-06-15 22:57:36,989:INFO:             sklearn: 1.4.2
2025-06-15 22:57:36,989:INFO:                pyod: 2.0.5
2025-06-15 22:57:36,989:INFO:            imblearn: 0.13.0
2025-06-15 22:57:36,989:INFO:   category_encoders: 2.7.0
2025-06-15 22:57:36,989:INFO:            lightgbm: 4.6.0
2025-06-15 22:57:36,989:INFO:               numba: 0.61.2
2025-06-15 22:57:36,990:INFO:            requests: 2.32.4
2025-06-15 22:57:36,990:INFO:          matplotlib: 3.7.5
2025-06-15 22:57:36,990:INFO:          scikitplot: 0.3.7
2025-06-15 22:57:36,990:INFO:         yellowbrick: 1.5
2025-06-15 22:57:36,990:INFO:              plotly: 5.24.1
2025-06-15 22:57:36,990:INFO:    plotly-resampler: Not installed
2025-06-15 22:57:36,990:INFO:             kaleido: 0.2.1
2025-06-15 22:57:36,990:INFO:           schemdraw: 0.15
2025-06-15 22:57:36,990:INFO:         statsmodels: 0.14.4
2025-06-15 22:57:36,990:INFO:              sktime: 0.26.0
2025-06-15 22:57:36,990:INFO:               tbats: 1.1.3
2025-06-15 22:57:36,990:INFO:            pmdarima: 2.0.4
2025-06-15 22:57:36,990:INFO:              psutil: 7.0.0
2025-06-15 22:57:36,990:INFO:          markupsafe: 3.0.2
2025-06-15 22:57:36,990:INFO:             pickle5: Not installed
2025-06-15 22:57:36,990:INFO:         cloudpickle: 3.1.1
2025-06-15 22:57:36,990:INFO:         deprecation: 2.1.0
2025-06-15 22:57:36,990:INFO:              xxhash: 3.5.0
2025-06-15 22:57:36,990:INFO:           wurlitzer: Not installed
2025-06-15 22:57:36,990:INFO:PyCaret optional dependencies:
2025-06-15 22:57:36,991:INFO:                shap: Not installed
2025-06-15 22:57:36,991:INFO:           interpret: Not installed
2025-06-15 22:57:36,991:INFO:                umap: Not installed
2025-06-15 22:57:36,991:INFO:     ydata_profiling: Not installed
2025-06-15 22:57:36,991:INFO:  explainerdashboard: Not installed
2025-06-15 22:57:36,991:INFO:             autoviz: Not installed
2025-06-15 22:57:36,991:INFO:           fairlearn: Not installed
2025-06-15 22:57:36,991:INFO:          deepchecks: Not installed
2025-06-15 22:57:36,991:INFO:             xgboost: Not installed
2025-06-15 22:57:36,991:INFO:            catboost: Not installed
2025-06-15 22:57:36,991:INFO:              kmodes: Not installed
2025-06-15 22:57:36,991:INFO:             mlxtend: Not installed
2025-06-15 22:57:36,991:INFO:       statsforecast: Not installed
2025-06-15 22:57:36,991:INFO:        tune_sklearn: Not installed
2025-06-15 22:57:36,991:INFO:                 ray: Not installed
2025-06-15 22:57:36,991:INFO:            hyperopt: Not installed
2025-06-15 22:57:36,991:INFO:              optuna: Not installed
2025-06-15 22:57:36,991:INFO:               skopt: Not installed
2025-06-15 22:57:36,991:INFO:              mlflow: Not installed
2025-06-15 22:57:36,991:INFO:              gradio: Not installed
2025-06-15 22:57:36,992:INFO:             fastapi: Not installed
2025-06-15 22:57:36,992:INFO:             uvicorn: Not installed
2025-06-15 22:57:36,992:INFO:              m2cgen: Not installed
2025-06-15 22:57:36,992:INFO:           evidently: Not installed
2025-06-15 22:57:36,992:INFO:               fugue: Not installed
2025-06-15 22:57:36,992:INFO:           streamlit: 1.42.2
2025-06-15 22:57:36,992:INFO:             prophet: Not installed
2025-06-15 22:57:36,992:INFO:None
2025-06-15 22:57:36,992:INFO:Set up data.
2025-06-15 22:57:36,997:INFO:Set up index.
2025-06-15 22:57:36,997:INFO:Assigning column types.
2025-06-15 22:57:36,999:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-06-15 22:57:37,000:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-06-15 22:57:37,000:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,000:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-06-15 22:57:37,000:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,000:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-06-15 22:57:37,000:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,000:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,002:INFO:Preparing preprocessing pipeline...
2025-06-15 22:57:37,002:INFO:Set up date feature engineering.
2025-06-15 22:57:37,002:INFO:Set up simple imputation.
2025-06-15 22:57:37,003:INFO:Set up encoding of categorical features.
2025-06-15 22:57:37,170:INFO:Finished creating preprocessing pipeline.
2025-06-15 22:57:37,177:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['trending_date', 'publish_time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'dislikes',
                                             'likes'],
                                    transformer=SimpleImputer())),
                ('categorical_impu...
                 TransformerWrapper(include=['title', 'channel_title', 'tags',
                                             'description', 'category_name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['title', 'channel_title', 'tags',
                                             'description', 'category_name'],
                                    transformer=OneHotEncoder(cols=['title',
                                                                    'channel_title',
                                                                    'tags',
                                                                    'description',
                                                                    'category_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-06-15 22:57:37,177:INFO:Creating final display dataframe.
2025-06-15 22:57:37,245:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape             (100, 11)
2     Transformed data shape            (100, 418)
3           Numeric features                     4
4              Date features                     2
5       Categorical features                     5
6   Rows with missing values                  1.0%
7                 Preprocess                  True
8            Imputation type                simple
9         Numeric imputation                  mean
10    Categorical imputation                  mode
11  Maximum one-hot encoding                    -1
12           Encoding method                  None
13                  CPU Jobs                    -1
14                   Use GPU                 False
15            Log Experiment                 False
16           Experiment Name  cluster-default-name
17                       USI                  49ac
2025-06-15 22:57:37,250:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,250:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:57:37,250:INFO:setup() successfully completed in 0.29s...............
2025-06-15 22:57:37,250:INFO:Initializing create_model()
2025-06-15 22:57:37,250:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4F98A490>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-06-15 22:57:37,250:INFO:Checking exceptions
2025-06-15 22:57:37,317:INFO:Importing untrained model
2025-06-15 22:57:37,317:INFO:K-Means Clustering Imported successfully
2025-06-15 22:57:37,322:INFO:Fitting Model
2025-06-15 22:57:37,482:INFO:KMeans(n_clusters=4, random_state=123)
2025-06-15 22:57:37,482:INFO:create_models() successfully completed......................................
2025-06-15 22:57:37,483:INFO:Uploading results into container
2025-06-15 22:57:37,483:INFO:Uploading model into container now
2025-06-15 22:57:37,489:INFO:_master_model_container: 1
2025-06-15 22:57:37,489:INFO:_display_container: 2
2025-06-15 22:57:37,489:INFO:KMeans(n_clusters=4, random_state=123)
2025-06-15 22:57:37,489:INFO:create_model() successfully completed......................................
2025-06-15 22:57:44,502:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:44,521:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:44,880:INFO:Initializing plot_model()
2025-06-15 22:57:44,881:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4F98A490>, estimator=KMeans(n_clusters=4, random_state=123), plot=elbow, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:57:44,881:INFO:Checking exceptions
2025-06-15 22:57:44,881:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:57:44,882:INFO:Preloading libraries
2025-06-15 22:57:44,882:INFO:Copying training dataset
2025-06-15 22:57:44,882:INFO:Plot type: elbow
2025-06-15 22:57:44,956:INFO:Fitting Model
2025-06-15 22:57:45,484:INFO:Visual Rendered Successfully
2025-06-15 22:57:45,637:INFO:plot_model() successfully completed......................................
2025-06-15 22:57:45,637:INFO:Initializing plot_model()
2025-06-15 22:57:45,637:INFO:plot_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4F98A490>, estimator=KMeans(n_clusters=4, random_state=123), plot=cluster, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:57:45,637:INFO:Checking exceptions
2025-06-15 22:57:45,638:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:57:45,638:INFO:Preloading libraries
2025-06-15 22:57:45,639:INFO:Copying training dataset
2025-06-15 22:57:45,639:INFO:Plot type: cluster
2025-06-15 22:57:45,639:INFO:SubProcess assign_model() called ==================================
2025-06-15 22:57:45,639:INFO:Initializing assign_model()
2025-06-15 22:57:45,639:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4F98A490>, model=KMeans(n_clusters=4, random_state=123), transformation=True, score=True, verbose=False)
2025-06-15 22:57:45,639:INFO:Checking exceptions
2025-06-15 22:57:45,640:INFO:Determining Trained Model
2025-06-15 22:57:45,640:INFO:Trained Model : K-Means Clustering
2025-06-15 22:57:45,640:INFO:Copying data
2025-06-15 22:57:45,711:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2025-06-15 22:57:45,711:INFO:(100, 419)
2025-06-15 22:57:45,711:INFO:assign_model() successfully completed......................................
2025-06-15 22:57:45,711:INFO:SubProcess assign_model() end ==================================
2025-06-15 22:57:45,713:INFO:Fitting PCA()
2025-06-15 22:57:45,742:INFO:Sorting dataframe
2025-06-15 22:57:45,742:INFO:Rendering Visual
2025-06-15 22:57:45,794:INFO:Visual Rendered Successfully
2025-06-15 22:57:45,915:INFO:plot_model() successfully completed......................................
2025-06-15 22:57:49,204:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:49,224:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:49,614:INFO:Initializing predict_model()
2025-06-15 22:57:49,615:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4F98A490>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-06-15 22:57:56,271:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:56,289:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:59,590:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:57:59,609:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:57:59,987:INFO:PyCaret RegressionExperiment
2025-06-15 22:57:59,988:INFO:Logging name: reg-default-name
2025-06-15 22:57:59,988:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-15 22:57:59,988:INFO:version 3.3.2
2025-06-15 22:57:59,988:INFO:Initializing setup()
2025-06-15 22:57:59,988:INFO:self.USI: 1f4c
2025-06-15 22:57:59,988:INFO:self._variable_keys: {'pipeline', 'y_train', 'X', 'y', 'USI', '_available_plots', 'idx', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'X_train', '_ml_usecase', 'fold_shuffle_param', 'gpu_param', 'html_param', 'log_plots_param', 'logging_param', 'fold_generator', 'transform_target_param', 'exp_id', 'y_test', 'memory', 'data', 'X_test', 'target_param', 'gpu_n_jobs_param', 'seed'}
2025-06-15 22:57:59,988:INFO:Checking environment
2025-06-15 22:57:59,988:INFO:python_version: 3.11.4
2025-06-15 22:57:59,988:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-06-15 22:57:59,988:INFO:machine: AMD64
2025-06-15 22:57:59,988:INFO:platform: Windows-10-10.0.19045-SP0
2025-06-15 22:57:59,992:INFO:Memory: svmem(total=17127211008, available=5963853824, percent=65.2, used=11163357184, free=5963853824)
2025-06-15 22:57:59,993:INFO:Physical Core: 6
2025-06-15 22:57:59,993:INFO:Logical Core: 12
2025-06-15 22:57:59,993:INFO:Checking libraries
2025-06-15 22:57:59,993:INFO:System:
2025-06-15 22:57:59,993:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-06-15 22:57:59,993:INFO:executable: D:\VS Code\arquitetura\.venv\Scripts\python.exe
2025-06-15 22:57:59,993:INFO:   machine: Windows-10-10.0.19045-SP0
2025-06-15 22:57:59,993:INFO:PyCaret required dependencies:
2025-06-15 22:57:59,993:INFO:                 pip: 25.1.1
2025-06-15 22:57:59,993:INFO:          setuptools: 65.5.0
2025-06-15 22:57:59,993:INFO:             pycaret: 3.3.2
2025-06-15 22:57:59,993:INFO:             IPython: 9.3.0
2025-06-15 22:57:59,993:INFO:          ipywidgets: 8.1.7
2025-06-15 22:57:59,993:INFO:                tqdm: 4.67.1
2025-06-15 22:57:59,993:INFO:               numpy: 1.26.4
2025-06-15 22:57:59,993:INFO:              pandas: 2.1.4
2025-06-15 22:57:59,993:INFO:              jinja2: 3.1.6
2025-06-15 22:57:59,994:INFO:               scipy: 1.11.4
2025-06-15 22:57:59,994:INFO:              joblib: 1.3.2
2025-06-15 22:57:59,994:INFO:             sklearn: 1.4.2
2025-06-15 22:57:59,994:INFO:                pyod: 2.0.5
2025-06-15 22:57:59,994:INFO:            imblearn: 0.13.0
2025-06-15 22:57:59,994:INFO:   category_encoders: 2.7.0
2025-06-15 22:57:59,994:INFO:            lightgbm: 4.6.0
2025-06-15 22:57:59,994:INFO:               numba: 0.61.2
2025-06-15 22:57:59,994:INFO:            requests: 2.32.4
2025-06-15 22:57:59,994:INFO:          matplotlib: 3.7.5
2025-06-15 22:57:59,994:INFO:          scikitplot: 0.3.7
2025-06-15 22:57:59,994:INFO:         yellowbrick: 1.5
2025-06-15 22:57:59,994:INFO:              plotly: 5.24.1
2025-06-15 22:57:59,994:INFO:    plotly-resampler: Not installed
2025-06-15 22:57:59,994:INFO:             kaleido: 0.2.1
2025-06-15 22:57:59,994:INFO:           schemdraw: 0.15
2025-06-15 22:57:59,994:INFO:         statsmodels: 0.14.4
2025-06-15 22:57:59,994:INFO:              sktime: 0.26.0
2025-06-15 22:57:59,995:INFO:               tbats: 1.1.3
2025-06-15 22:57:59,995:INFO:            pmdarima: 2.0.4
2025-06-15 22:57:59,995:INFO:              psutil: 7.0.0
2025-06-15 22:57:59,995:INFO:          markupsafe: 3.0.2
2025-06-15 22:57:59,995:INFO:             pickle5: Not installed
2025-06-15 22:57:59,995:INFO:         cloudpickle: 3.1.1
2025-06-15 22:57:59,995:INFO:         deprecation: 2.1.0
2025-06-15 22:57:59,995:INFO:              xxhash: 3.5.0
2025-06-15 22:57:59,995:INFO:           wurlitzer: Not installed
2025-06-15 22:57:59,995:INFO:PyCaret optional dependencies:
2025-06-15 22:57:59,995:INFO:                shap: Not installed
2025-06-15 22:57:59,995:INFO:           interpret: Not installed
2025-06-15 22:57:59,995:INFO:                umap: Not installed
2025-06-15 22:57:59,995:INFO:     ydata_profiling: Not installed
2025-06-15 22:57:59,995:INFO:  explainerdashboard: Not installed
2025-06-15 22:57:59,995:INFO:             autoviz: Not installed
2025-06-15 22:57:59,995:INFO:           fairlearn: Not installed
2025-06-15 22:57:59,995:INFO:          deepchecks: Not installed
2025-06-15 22:57:59,995:INFO:             xgboost: Not installed
2025-06-15 22:57:59,996:INFO:            catboost: Not installed
2025-06-15 22:57:59,996:INFO:              kmodes: Not installed
2025-06-15 22:57:59,996:INFO:             mlxtend: Not installed
2025-06-15 22:57:59,996:INFO:       statsforecast: Not installed
2025-06-15 22:57:59,996:INFO:        tune_sklearn: Not installed
2025-06-15 22:57:59,996:INFO:                 ray: Not installed
2025-06-15 22:57:59,996:INFO:            hyperopt: Not installed
2025-06-15 22:57:59,996:INFO:              optuna: Not installed
2025-06-15 22:57:59,996:INFO:               skopt: Not installed
2025-06-15 22:57:59,996:INFO:              mlflow: Not installed
2025-06-15 22:57:59,996:INFO:              gradio: Not installed
2025-06-15 22:57:59,996:INFO:             fastapi: Not installed
2025-06-15 22:57:59,996:INFO:             uvicorn: Not installed
2025-06-15 22:57:59,996:INFO:              m2cgen: Not installed
2025-06-15 22:57:59,996:INFO:           evidently: Not installed
2025-06-15 22:57:59,996:INFO:               fugue: Not installed
2025-06-15 22:57:59,996:INFO:           streamlit: 1.42.2
2025-06-15 22:57:59,996:INFO:             prophet: Not installed
2025-06-15 22:57:59,996:INFO:None
2025-06-15 22:57:59,997:INFO:Set up data.
2025-06-15 22:58:00,002:INFO:Set up folding strategy.
2025-06-15 22:58:00,003:INFO:Set up train/test split.
2025-06-15 22:58:00,008:INFO:Set up index.
2025-06-15 22:58:00,008:INFO:Assigning column types.
2025-06-15 22:58:00,012:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-15 22:58:00,012:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,018:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,162:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,168:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,248:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,307:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-15 22:58:00,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,318:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,463:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,597:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-15 22:58:00,609:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:00,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:00,899:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-15 22:58:00,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,193:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-15 22:58:01,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-15 22:58:01,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,496:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-15 22:58:01,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:01,797:INFO:Preparing preprocessing pipeline...
2025-06-15 22:58:01,797:INFO:Set up date feature engineering.
2025-06-15 22:58:01,797:INFO:Set up simple imputation.
2025-06-15 22:58:01,800:INFO:Set up encoding of categorical features.
2025-06-15 22:58:01,922:INFO:Finished creating preprocessing pipeline.
2025-06-15 22:58:01,933:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['trending_date', 'publish_time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views',
                                             'dislikes'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Tra...
                ('onehot_encoding',
                 TransformerWrapper(include=['category_name'],
                                    transformer=OneHotEncoder(cols=['category_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['title', 'channel_title', 'tags',
                                             'description'],
                                    transformer=TargetEncoder(cols=['title',
                                                                    'channel_title',
                                                                    'tags',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-06-15 22:58:01,933:INFO:Creating final display dataframe.
2025-06-15 22:58:02,293:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             likes
2                   Target type        Regression
3           Original data shape         (100, 11)
4        Transformed data shape         (100, 28)
5   Transformed train set shape          (80, 28)
6    Transformed test set shape          (20, 28)
7              Numeric features                 3
8                 Date features                 2
9          Categorical features                 5
10     Rows with missing values              1.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                 2
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              1f4c
2025-06-15 22:58:02,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:02,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:02,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:02,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-15 22:58:02,592:INFO:setup() successfully completed in 2.62s...............
2025-06-15 22:58:02,592:INFO:Initializing compare_models()
2025-06-15 22:58:02,592:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-15 22:58:02,592:INFO:Checking exceptions
2025-06-15 22:58:02,594:INFO:Preparing display monitor
2025-06-15 22:58:02,596:INFO:Initializing Linear Regression
2025-06-15 22:58:02,596:INFO:Total runtime is 0.0 minutes
2025-06-15 22:58:02,596:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:02,596:INFO:Initializing create_model()
2025-06-15 22:58:02,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=lr, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:02,596:INFO:Checking exceptions
2025-06-15 22:58:02,597:INFO:Importing libraries
2025-06-15 22:58:02,597:INFO:Copying training dataset
2025-06-15 22:58:02,601:INFO:Defining folds
2025-06-15 22:58:02,601:INFO:Declaring metric variables
2025-06-15 22:58:02,601:INFO:Importing untrained model
2025-06-15 22:58:02,601:INFO:Linear Regression Imported successfully
2025-06-15 22:58:02,601:INFO:Starting cross validation
2025-06-15 22:58:02,603:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:06,588:INFO:Calculating mean and std
2025-06-15 22:58:06,589:INFO:Creating metrics dataframe
2025-06-15 22:58:06,591:INFO:Uploading results into container
2025-06-15 22:58:06,591:INFO:Uploading model into container now
2025-06-15 22:58:06,591:INFO:_master_model_container: 1
2025-06-15 22:58:06,591:INFO:_display_container: 2
2025-06-15 22:58:06,592:INFO:LinearRegression(n_jobs=-1)
2025-06-15 22:58:06,592:INFO:create_model() successfully completed......................................
2025-06-15 22:58:06,763:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:06,763:INFO:Creating metrics dataframe
2025-06-15 22:58:06,765:INFO:Initializing Lasso Regression
2025-06-15 22:58:06,765:INFO:Total runtime is 0.0694843053817749 minutes
2025-06-15 22:58:06,765:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:06,765:INFO:Initializing create_model()
2025-06-15 22:58:06,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=lasso, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:06,765:INFO:Checking exceptions
2025-06-15 22:58:06,765:INFO:Importing libraries
2025-06-15 22:58:06,765:INFO:Copying training dataset
2025-06-15 22:58:06,769:INFO:Defining folds
2025-06-15 22:58:06,770:INFO:Declaring metric variables
2025-06-15 22:58:06,770:INFO:Importing untrained model
2025-06-15 22:58:06,770:INFO:Lasso Regression Imported successfully
2025-06-15 22:58:06,770:INFO:Starting cross validation
2025-06-15 22:58:06,772:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:10,055:INFO:Calculating mean and std
2025-06-15 22:58:10,056:INFO:Creating metrics dataframe
2025-06-15 22:58:10,058:INFO:Uploading results into container
2025-06-15 22:58:10,058:INFO:Uploading model into container now
2025-06-15 22:58:10,058:INFO:_master_model_container: 2
2025-06-15 22:58:10,058:INFO:_display_container: 2
2025-06-15 22:58:10,059:INFO:Lasso(random_state=123)
2025-06-15 22:58:10,059:INFO:create_model() successfully completed......................................
2025-06-15 22:58:10,203:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:10,203:INFO:Creating metrics dataframe
2025-06-15 22:58:10,205:INFO:Initializing Ridge Regression
2025-06-15 22:58:10,205:INFO:Total runtime is 0.12681389649709066 minutes
2025-06-15 22:58:10,205:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:10,206:INFO:Initializing create_model()
2025-06-15 22:58:10,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=ridge, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:10,206:INFO:Checking exceptions
2025-06-15 22:58:10,206:INFO:Importing libraries
2025-06-15 22:58:10,206:INFO:Copying training dataset
2025-06-15 22:58:10,210:INFO:Defining folds
2025-06-15 22:58:10,210:INFO:Declaring metric variables
2025-06-15 22:58:10,210:INFO:Importing untrained model
2025-06-15 22:58:10,210:INFO:Ridge Regression Imported successfully
2025-06-15 22:58:10,211:INFO:Starting cross validation
2025-06-15 22:58:10,212:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:13,469:INFO:Calculating mean and std
2025-06-15 22:58:13,470:INFO:Creating metrics dataframe
2025-06-15 22:58:13,472:INFO:Uploading results into container
2025-06-15 22:58:13,472:INFO:Uploading model into container now
2025-06-15 22:58:13,473:INFO:_master_model_container: 3
2025-06-15 22:58:13,473:INFO:_display_container: 2
2025-06-15 22:58:13,473:INFO:Ridge(random_state=123)
2025-06-15 22:58:13,473:INFO:create_model() successfully completed......................................
2025-06-15 22:58:13,602:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:13,602:INFO:Creating metrics dataframe
2025-06-15 22:58:13,604:INFO:Initializing Elastic Net
2025-06-15 22:58:13,604:INFO:Total runtime is 0.18345663944880167 minutes
2025-06-15 22:58:13,605:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:13,605:INFO:Initializing create_model()
2025-06-15 22:58:13,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=en, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:13,605:INFO:Checking exceptions
2025-06-15 22:58:13,605:INFO:Importing libraries
2025-06-15 22:58:13,605:INFO:Copying training dataset
2025-06-15 22:58:13,610:INFO:Defining folds
2025-06-15 22:58:13,610:INFO:Declaring metric variables
2025-06-15 22:58:13,610:INFO:Importing untrained model
2025-06-15 22:58:13,610:INFO:Elastic Net Imported successfully
2025-06-15 22:58:13,611:INFO:Starting cross validation
2025-06-15 22:58:13,612:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:16,874:INFO:Calculating mean and std
2025-06-15 22:58:16,875:INFO:Creating metrics dataframe
2025-06-15 22:58:16,877:INFO:Uploading results into container
2025-06-15 22:58:16,877:INFO:Uploading model into container now
2025-06-15 22:58:16,878:INFO:_master_model_container: 4
2025-06-15 22:58:16,878:INFO:_display_container: 2
2025-06-15 22:58:16,878:INFO:ElasticNet(random_state=123)
2025-06-15 22:58:16,878:INFO:create_model() successfully completed......................................
2025-06-15 22:58:17,019:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:17,019:INFO:Creating metrics dataframe
2025-06-15 22:58:17,021:INFO:Initializing Least Angle Regression
2025-06-15 22:58:17,021:INFO:Total runtime is 0.2404131213823954 minutes
2025-06-15 22:58:17,021:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:17,022:INFO:Initializing create_model()
2025-06-15 22:58:17,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=lar, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:17,022:INFO:Checking exceptions
2025-06-15 22:58:17,022:INFO:Importing libraries
2025-06-15 22:58:17,022:INFO:Copying training dataset
2025-06-15 22:58:17,026:INFO:Defining folds
2025-06-15 22:58:17,026:INFO:Declaring metric variables
2025-06-15 22:58:17,026:INFO:Importing untrained model
2025-06-15 22:58:17,026:INFO:Least Angle Regression Imported successfully
2025-06-15 22:58:17,027:INFO:Starting cross validation
2025-06-15 22:58:17,028:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:20,291:INFO:Calculating mean and std
2025-06-15 22:58:20,292:INFO:Creating metrics dataframe
2025-06-15 22:58:20,293:INFO:Uploading results into container
2025-06-15 22:58:20,293:INFO:Uploading model into container now
2025-06-15 22:58:20,294:INFO:_master_model_container: 5
2025-06-15 22:58:20,294:INFO:_display_container: 2
2025-06-15 22:58:20,294:INFO:Lars(random_state=123)
2025-06-15 22:58:20,294:INFO:create_model() successfully completed......................................
2025-06-15 22:58:20,426:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:20,426:INFO:Creating metrics dataframe
2025-06-15 22:58:20,429:INFO:Initializing Lasso Least Angle Regression
2025-06-15 22:58:20,429:INFO:Total runtime is 0.2972034533818563 minutes
2025-06-15 22:58:20,429:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:20,429:INFO:Initializing create_model()
2025-06-15 22:58:20,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=llar, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:20,429:INFO:Checking exceptions
2025-06-15 22:58:20,429:INFO:Importing libraries
2025-06-15 22:58:20,429:INFO:Copying training dataset
2025-06-15 22:58:20,434:INFO:Defining folds
2025-06-15 22:58:20,434:INFO:Declaring metric variables
2025-06-15 22:58:20,434:INFO:Importing untrained model
2025-06-15 22:58:20,434:INFO:Lasso Least Angle Regression Imported successfully
2025-06-15 22:58:20,435:INFO:Starting cross validation
2025-06-15 22:58:20,436:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:23,724:INFO:Calculating mean and std
2025-06-15 22:58:23,725:INFO:Creating metrics dataframe
2025-06-15 22:58:23,726:INFO:Uploading results into container
2025-06-15 22:58:23,727:INFO:Uploading model into container now
2025-06-15 22:58:23,727:INFO:_master_model_container: 6
2025-06-15 22:58:23,727:INFO:_display_container: 2
2025-06-15 22:58:23,728:INFO:LassoLars(random_state=123)
2025-06-15 22:58:23,728:INFO:create_model() successfully completed......................................
2025-06-15 22:58:23,860:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:23,860:INFO:Creating metrics dataframe
2025-06-15 22:58:23,862:INFO:Initializing Orthogonal Matching Pursuit
2025-06-15 22:58:23,862:INFO:Total runtime is 0.3544271071751912 minutes
2025-06-15 22:58:23,863:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:23,863:INFO:Initializing create_model()
2025-06-15 22:58:23,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=omp, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:23,863:INFO:Checking exceptions
2025-06-15 22:58:23,863:INFO:Importing libraries
2025-06-15 22:58:23,863:INFO:Copying training dataset
2025-06-15 22:58:23,867:INFO:Defining folds
2025-06-15 22:58:23,867:INFO:Declaring metric variables
2025-06-15 22:58:23,867:INFO:Importing untrained model
2025-06-15 22:58:23,868:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-15 22:58:23,868:INFO:Starting cross validation
2025-06-15 22:58:23,869:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:23,993:INFO:Calculating mean and std
2025-06-15 22:58:23,994:INFO:Creating metrics dataframe
2025-06-15 22:58:23,995:INFO:Uploading results into container
2025-06-15 22:58:23,996:INFO:Uploading model into container now
2025-06-15 22:58:23,996:INFO:_master_model_container: 7
2025-06-15 22:58:23,996:INFO:_display_container: 2
2025-06-15 22:58:23,996:INFO:OrthogonalMatchingPursuit()
2025-06-15 22:58:23,996:INFO:create_model() successfully completed......................................
2025-06-15 22:58:24,127:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:24,127:INFO:Creating metrics dataframe
2025-06-15 22:58:24,130:INFO:Initializing Bayesian Ridge
2025-06-15 22:58:24,130:INFO:Total runtime is 0.35889898538589476 minutes
2025-06-15 22:58:24,130:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:24,130:INFO:Initializing create_model()
2025-06-15 22:58:24,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=br, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:24,130:INFO:Checking exceptions
2025-06-15 22:58:24,130:INFO:Importing libraries
2025-06-15 22:58:24,130:INFO:Copying training dataset
2025-06-15 22:58:24,134:INFO:Defining folds
2025-06-15 22:58:24,135:INFO:Declaring metric variables
2025-06-15 22:58:24,135:INFO:Importing untrained model
2025-06-15 22:58:24,135:INFO:Bayesian Ridge Imported successfully
2025-06-15 22:58:24,135:INFO:Starting cross validation
2025-06-15 22:58:24,137:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:24,273:INFO:Calculating mean and std
2025-06-15 22:58:24,274:INFO:Creating metrics dataframe
2025-06-15 22:58:24,275:INFO:Uploading results into container
2025-06-15 22:58:24,276:INFO:Uploading model into container now
2025-06-15 22:58:24,276:INFO:_master_model_container: 8
2025-06-15 22:58:24,276:INFO:_display_container: 2
2025-06-15 22:58:24,276:INFO:BayesianRidge()
2025-06-15 22:58:24,276:INFO:create_model() successfully completed......................................
2025-06-15 22:58:24,406:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:24,406:INFO:Creating metrics dataframe
2025-06-15 22:58:24,408:INFO:Initializing Passive Aggressive Regressor
2025-06-15 22:58:24,408:INFO:Total runtime is 0.36352362235387164 minutes
2025-06-15 22:58:24,409:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:24,409:INFO:Initializing create_model()
2025-06-15 22:58:24,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=par, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:24,409:INFO:Checking exceptions
2025-06-15 22:58:24,409:INFO:Importing libraries
2025-06-15 22:58:24,409:INFO:Copying training dataset
2025-06-15 22:58:24,413:INFO:Defining folds
2025-06-15 22:58:24,413:INFO:Declaring metric variables
2025-06-15 22:58:24,413:INFO:Importing untrained model
2025-06-15 22:58:24,414:INFO:Passive Aggressive Regressor Imported successfully
2025-06-15 22:58:24,414:INFO:Starting cross validation
2025-06-15 22:58:24,415:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:24,538:INFO:Calculating mean and std
2025-06-15 22:58:24,539:INFO:Creating metrics dataframe
2025-06-15 22:58:24,540:INFO:Uploading results into container
2025-06-15 22:58:24,541:INFO:Uploading model into container now
2025-06-15 22:58:24,541:INFO:_master_model_container: 9
2025-06-15 22:58:24,541:INFO:_display_container: 2
2025-06-15 22:58:24,541:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-15 22:58:24,541:INFO:create_model() successfully completed......................................
2025-06-15 22:58:24,669:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:24,669:INFO:Creating metrics dataframe
2025-06-15 22:58:24,672:INFO:Initializing Huber Regressor
2025-06-15 22:58:24,672:INFO:Total runtime is 0.367923100789388 minutes
2025-06-15 22:58:24,672:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:24,672:INFO:Initializing create_model()
2025-06-15 22:58:24,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=huber, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:24,672:INFO:Checking exceptions
2025-06-15 22:58:24,672:INFO:Importing libraries
2025-06-15 22:58:24,672:INFO:Copying training dataset
2025-06-15 22:58:24,677:INFO:Defining folds
2025-06-15 22:58:24,677:INFO:Declaring metric variables
2025-06-15 22:58:24,677:INFO:Importing untrained model
2025-06-15 22:58:24,677:INFO:Huber Regressor Imported successfully
2025-06-15 22:58:24,677:INFO:Starting cross validation
2025-06-15 22:58:24,679:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:24,806:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-15 22:58:24,815:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-15 22:58:24,856:INFO:Calculating mean and std
2025-06-15 22:58:24,857:INFO:Creating metrics dataframe
2025-06-15 22:58:24,858:INFO:Uploading results into container
2025-06-15 22:58:24,859:INFO:Uploading model into container now
2025-06-15 22:58:24,859:INFO:_master_model_container: 10
2025-06-15 22:58:24,859:INFO:_display_container: 2
2025-06-15 22:58:24,859:INFO:HuberRegressor()
2025-06-15 22:58:24,859:INFO:create_model() successfully completed......................................
2025-06-15 22:58:24,984:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:24,984:INFO:Creating metrics dataframe
2025-06-15 22:58:24,986:INFO:Initializing K Neighbors Regressor
2025-06-15 22:58:24,986:INFO:Total runtime is 0.3731547276178996 minutes
2025-06-15 22:58:24,986:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:24,987:INFO:Initializing create_model()
2025-06-15 22:58:24,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=knn, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:24,987:INFO:Checking exceptions
2025-06-15 22:58:24,987:INFO:Importing libraries
2025-06-15 22:58:24,987:INFO:Copying training dataset
2025-06-15 22:58:24,991:INFO:Defining folds
2025-06-15 22:58:24,991:INFO:Declaring metric variables
2025-06-15 22:58:24,991:INFO:Importing untrained model
2025-06-15 22:58:24,992:INFO:K Neighbors Regressor Imported successfully
2025-06-15 22:58:24,992:INFO:Starting cross validation
2025-06-15 22:58:24,993:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:25,263:INFO:Calculating mean and std
2025-06-15 22:58:25,264:INFO:Creating metrics dataframe
2025-06-15 22:58:25,266:INFO:Uploading results into container
2025-06-15 22:58:25,266:INFO:Uploading model into container now
2025-06-15 22:58:25,266:INFO:_master_model_container: 11
2025-06-15 22:58:25,266:INFO:_display_container: 2
2025-06-15 22:58:25,267:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:58:25,267:INFO:create_model() successfully completed......................................
2025-06-15 22:58:25,400:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:25,400:INFO:Creating metrics dataframe
2025-06-15 22:58:25,403:INFO:Initializing Decision Tree Regressor
2025-06-15 22:58:25,403:INFO:Total runtime is 0.3801129341125488 minutes
2025-06-15 22:58:25,403:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:25,403:INFO:Initializing create_model()
2025-06-15 22:58:25,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=dt, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:25,403:INFO:Checking exceptions
2025-06-15 22:58:25,403:INFO:Importing libraries
2025-06-15 22:58:25,403:INFO:Copying training dataset
2025-06-15 22:58:25,408:INFO:Defining folds
2025-06-15 22:58:25,408:INFO:Declaring metric variables
2025-06-15 22:58:25,408:INFO:Importing untrained model
2025-06-15 22:58:25,409:INFO:Decision Tree Regressor Imported successfully
2025-06-15 22:58:25,409:INFO:Starting cross validation
2025-06-15 22:58:25,410:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:25,523:INFO:Calculating mean and std
2025-06-15 22:58:25,524:INFO:Creating metrics dataframe
2025-06-15 22:58:25,525:INFO:Uploading results into container
2025-06-15 22:58:25,525:INFO:Uploading model into container now
2025-06-15 22:58:25,526:INFO:_master_model_container: 12
2025-06-15 22:58:25,526:INFO:_display_container: 2
2025-06-15 22:58:25,526:INFO:DecisionTreeRegressor(random_state=123)
2025-06-15 22:58:25,526:INFO:create_model() successfully completed......................................
2025-06-15 22:58:25,664:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:25,664:INFO:Creating metrics dataframe
2025-06-15 22:58:25,667:INFO:Initializing Random Forest Regressor
2025-06-15 22:58:25,667:INFO:Total runtime is 0.3845036705334981 minutes
2025-06-15 22:58:25,667:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:25,667:INFO:Initializing create_model()
2025-06-15 22:58:25,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=rf, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:25,668:INFO:Checking exceptions
2025-06-15 22:58:25,668:INFO:Importing libraries
2025-06-15 22:58:25,668:INFO:Copying training dataset
2025-06-15 22:58:25,674:INFO:Defining folds
2025-06-15 22:58:25,674:INFO:Declaring metric variables
2025-06-15 22:58:25,674:INFO:Importing untrained model
2025-06-15 22:58:25,675:INFO:Random Forest Regressor Imported successfully
2025-06-15 22:58:25,675:INFO:Starting cross validation
2025-06-15 22:58:25,677:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:25,967:INFO:Calculating mean and std
2025-06-15 22:58:25,968:INFO:Creating metrics dataframe
2025-06-15 22:58:25,969:INFO:Uploading results into container
2025-06-15 22:58:25,970:INFO:Uploading model into container now
2025-06-15 22:58:25,970:INFO:_master_model_container: 13
2025-06-15 22:58:25,970:INFO:_display_container: 2
2025-06-15 22:58:25,970:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:58:25,970:INFO:create_model() successfully completed......................................
2025-06-15 22:58:26,096:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:26,096:INFO:Creating metrics dataframe
2025-06-15 22:58:26,100:INFO:Initializing Extra Trees Regressor
2025-06-15 22:58:26,100:INFO:Total runtime is 0.39173260927200315 minutes
2025-06-15 22:58:26,100:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:26,100:INFO:Initializing create_model()
2025-06-15 22:58:26,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=et, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:26,100:INFO:Checking exceptions
2025-06-15 22:58:26,100:INFO:Importing libraries
2025-06-15 22:58:26,100:INFO:Copying training dataset
2025-06-15 22:58:26,105:INFO:Defining folds
2025-06-15 22:58:26,105:INFO:Declaring metric variables
2025-06-15 22:58:26,105:INFO:Importing untrained model
2025-06-15 22:58:26,105:INFO:Extra Trees Regressor Imported successfully
2025-06-15 22:58:26,106:INFO:Starting cross validation
2025-06-15 22:58:26,107:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:26,334:INFO:Calculating mean and std
2025-06-15 22:58:26,335:INFO:Creating metrics dataframe
2025-06-15 22:58:26,336:INFO:Uploading results into container
2025-06-15 22:58:26,336:INFO:Uploading model into container now
2025-06-15 22:58:26,337:INFO:_master_model_container: 14
2025-06-15 22:58:26,337:INFO:_display_container: 2
2025-06-15 22:58:26,337:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:58:26,337:INFO:create_model() successfully completed......................................
2025-06-15 22:58:26,457:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:26,457:INFO:Creating metrics dataframe
2025-06-15 22:58:26,460:INFO:Initializing AdaBoost Regressor
2025-06-15 22:58:26,460:INFO:Total runtime is 0.39773162206013996 minutes
2025-06-15 22:58:26,460:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:26,461:INFO:Initializing create_model()
2025-06-15 22:58:26,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=ada, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:26,461:INFO:Checking exceptions
2025-06-15 22:58:26,461:INFO:Importing libraries
2025-06-15 22:58:26,461:INFO:Copying training dataset
2025-06-15 22:58:26,466:INFO:Defining folds
2025-06-15 22:58:26,466:INFO:Declaring metric variables
2025-06-15 22:58:26,467:INFO:Importing untrained model
2025-06-15 22:58:26,467:INFO:AdaBoost Regressor Imported successfully
2025-06-15 22:58:26,467:INFO:Starting cross validation
2025-06-15 22:58:26,469:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:26,686:INFO:Calculating mean and std
2025-06-15 22:58:26,687:INFO:Creating metrics dataframe
2025-06-15 22:58:26,688:INFO:Uploading results into container
2025-06-15 22:58:26,689:INFO:Uploading model into container now
2025-06-15 22:58:26,689:INFO:_master_model_container: 15
2025-06-15 22:58:26,689:INFO:_display_container: 2
2025-06-15 22:58:26,689:INFO:AdaBoostRegressor(random_state=123)
2025-06-15 22:58:26,689:INFO:create_model() successfully completed......................................
2025-06-15 22:58:26,814:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:26,814:INFO:Creating metrics dataframe
2025-06-15 22:58:26,816:INFO:Initializing Gradient Boosting Regressor
2025-06-15 22:58:26,817:INFO:Total runtime is 0.403672448794047 minutes
2025-06-15 22:58:26,817:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:26,817:INFO:Initializing create_model()
2025-06-15 22:58:26,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=gbr, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:26,817:INFO:Checking exceptions
2025-06-15 22:58:26,817:INFO:Importing libraries
2025-06-15 22:58:26,817:INFO:Copying training dataset
2025-06-15 22:58:26,821:INFO:Defining folds
2025-06-15 22:58:26,821:INFO:Declaring metric variables
2025-06-15 22:58:26,821:INFO:Importing untrained model
2025-06-15 22:58:26,822:INFO:Gradient Boosting Regressor Imported successfully
2025-06-15 22:58:26,822:INFO:Starting cross validation
2025-06-15 22:58:26,823:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:27,003:INFO:Calculating mean and std
2025-06-15 22:58:27,003:INFO:Creating metrics dataframe
2025-06-15 22:58:27,005:INFO:Uploading results into container
2025-06-15 22:58:27,005:INFO:Uploading model into container now
2025-06-15 22:58:27,006:INFO:_master_model_container: 16
2025-06-15 22:58:27,006:INFO:_display_container: 2
2025-06-15 22:58:27,006:INFO:GradientBoostingRegressor(random_state=123)
2025-06-15 22:58:27,006:INFO:create_model() successfully completed......................................
2025-06-15 22:58:27,125:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:27,125:INFO:Creating metrics dataframe
2025-06-15 22:58:27,128:INFO:Initializing Light Gradient Boosting Machine
2025-06-15 22:58:27,128:INFO:Total runtime is 0.40886396169662476 minutes
2025-06-15 22:58:27,128:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:27,128:INFO:Initializing create_model()
2025-06-15 22:58:27,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=lightgbm, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:27,128:INFO:Checking exceptions
2025-06-15 22:58:27,128:INFO:Importing libraries
2025-06-15 22:58:27,128:INFO:Copying training dataset
2025-06-15 22:58:27,133:INFO:Defining folds
2025-06-15 22:58:27,133:INFO:Declaring metric variables
2025-06-15 22:58:27,133:INFO:Importing untrained model
2025-06-15 22:58:27,133:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-15 22:58:27,134:INFO:Starting cross validation
2025-06-15 22:58:27,135:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:27,320:INFO:Calculating mean and std
2025-06-15 22:58:27,321:INFO:Creating metrics dataframe
2025-06-15 22:58:27,323:INFO:Uploading results into container
2025-06-15 22:58:27,323:INFO:Uploading model into container now
2025-06-15 22:58:27,323:INFO:_master_model_container: 17
2025-06-15 22:58:27,324:INFO:_display_container: 2
2025-06-15 22:58:27,324:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-15 22:58:27,324:INFO:create_model() successfully completed......................................
2025-06-15 22:58:27,471:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:27,471:INFO:Creating metrics dataframe
2025-06-15 22:58:27,473:INFO:Initializing Dummy Regressor
2025-06-15 22:58:27,473:INFO:Total runtime is 0.4146103541056315 minutes
2025-06-15 22:58:27,474:INFO:SubProcess create_model() called ==================================
2025-06-15 22:58:27,474:INFO:Initializing create_model()
2025-06-15 22:58:27,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=dummy, fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024D4F84DC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:27,474:INFO:Checking exceptions
2025-06-15 22:58:27,474:INFO:Importing libraries
2025-06-15 22:58:27,474:INFO:Copying training dataset
2025-06-15 22:58:27,478:INFO:Defining folds
2025-06-15 22:58:27,479:INFO:Declaring metric variables
2025-06-15 22:58:27,479:INFO:Importing untrained model
2025-06-15 22:58:27,479:INFO:Dummy Regressor Imported successfully
2025-06-15 22:58:27,479:INFO:Starting cross validation
2025-06-15 22:58:27,481:INFO:Cross validating with KFold(n_splits=2, random_state=None, shuffle=False), n_jobs=-1
2025-06-15 22:58:27,598:INFO:Calculating mean and std
2025-06-15 22:58:27,599:INFO:Creating metrics dataframe
2025-06-15 22:58:27,600:INFO:Uploading results into container
2025-06-15 22:58:27,600:INFO:Uploading model into container now
2025-06-15 22:58:27,601:INFO:_master_model_container: 18
2025-06-15 22:58:27,601:INFO:_display_container: 2
2025-06-15 22:58:27,601:INFO:DummyRegressor()
2025-06-15 22:58:27,601:INFO:create_model() successfully completed......................................
2025-06-15 22:58:27,722:INFO:SubProcess create_model() end ==================================
2025-06-15 22:58:27,723:INFO:Creating metrics dataframe
2025-06-15 22:58:27,725:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-06-15 22:58:27,726:INFO:Initializing create_model()
2025-06-15 22:58:27,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=2, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-15 22:58:27,726:INFO:Checking exceptions
2025-06-15 22:58:27,727:INFO:Importing libraries
2025-06-15 22:58:27,727:INFO:Copying training dataset
2025-06-15 22:58:27,731:INFO:Defining folds
2025-06-15 22:58:27,731:INFO:Declaring metric variables
2025-06-15 22:58:27,731:INFO:Importing untrained model
2025-06-15 22:58:27,731:INFO:Declaring custom model
2025-06-15 22:58:27,732:INFO:K Neighbors Regressor Imported successfully
2025-06-15 22:58:27,733:INFO:Cross validation set to False
2025-06-15 22:58:27,733:INFO:Fitting Model
2025-06-15 22:58:27,796:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:58:27,796:INFO:create_model() successfully completed......................................
2025-06-15 22:58:27,930:INFO:_master_model_container: 18
2025-06-15 22:58:27,930:INFO:_display_container: 2
2025-06-15 22:58:27,930:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-15 22:58:27,931:INFO:compare_models() successfully completed......................................
2025-06-15 22:58:33,277:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:58:33,296:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:58:33,637:INFO:Initializing plot_model()
2025-06-15 22:58:33,637:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=KNeighborsRegressor(n_jobs=-1), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:58:33,637:INFO:Checking exceptions
2025-06-15 22:58:33,637:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:58:33,640:INFO:Preloading libraries
2025-06-15 22:58:33,640:INFO:Copying training dataset
2025-06-15 22:58:33,640:INFO:Plot type: residuals
2025-06-15 22:58:34,018:INFO:Fitting Model
2025-06-15 22:58:34,018:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but KNeighborsRegressor was fitted with feature names


2025-06-15 22:58:34,059:INFO:Scoring test/hold-out set
2025-06-15 22:58:34,577:INFO:Visual Rendered Successfully
2025-06-15 22:58:34,730:INFO:plot_model() successfully completed......................................
2025-06-15 22:58:34,730:INFO:Initializing plot_model()
2025-06-15 22:58:34,731:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=KNeighborsRegressor(n_jobs=-1), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-06-15 22:58:34,731:INFO:Checking exceptions
2025-06-15 22:58:34,731:INFO:Soft dependency imported: streamlit: 1.42.2
2025-06-15 22:58:34,733:INFO:Preloading libraries
2025-06-15 22:58:34,733:INFO:Copying training dataset
2025-06-15 22:58:34,733:INFO:Plot type: error
2025-06-15 22:58:35,086:INFO:Fitting Model
2025-06-15 22:58:35,086:WARNING:D:\VS Code\arquitetura\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but KNeighborsRegressor was fitted with feature names


2025-06-15 22:58:35,086:INFO:Scoring test/hold-out set
2025-06-15 22:58:35,322:INFO:Visual Rendered Successfully
2025-06-15 22:58:35,442:INFO:plot_model() successfully completed......................................
2025-06-15 22:58:38,363:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:160: FutureWarning:

The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.


2025-06-15 22:58:38,382:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:163: FutureWarning:



Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.



2025-06-15 22:58:38,737:INFO:Initializing predict_model()
2025-06-15 22:58:38,737:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024D4D7FE850>, estimator=KNeighborsRegressor(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024D4CF337E0>)
2025-06-15 22:58:38,737:INFO:Checking exceptions
2025-06-15 22:58:38,737:INFO:Preloading libraries
2025-06-15 22:58:38,737:INFO:Set up data.
2025-06-15 22:58:38,742:INFO:Set up index.
