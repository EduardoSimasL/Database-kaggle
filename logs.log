2025-04-06 21:05:33,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:33,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:05:52,196:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:05:52,221:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:05:52,592:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:06:32,303:INFO:PyCaret ClassificationExperiment
2025-04-06 21:06:32,303:INFO:Logging name: clf-default-name
2025-04-06 21:06:32,304:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-06 21:06:32,304:INFO:version 3.3.2
2025-04-06 21:06:32,304:INFO:Initializing setup()
2025-04-06 21:06:32,304:INFO:self.USI: b85d
2025-04-06 21:06:32,304:INFO:self._variable_keys: {'seed', 'exp_id', 'fix_imbalance', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'is_multiclass', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:06:32,304:INFO:Checking environment
2025-04-06 21:06:32,304:INFO:python_version: 3.11.4
2025-04-06 21:06:32,304:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:06:32,304:INFO:machine: AMD64
2025-04-06 21:06:32,334:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:06:32,340:INFO:Memory: svmem(total=17127211008, available=2428715008, percent=85.8, used=14698496000, free=2428715008)
2025-04-06 21:06:32,340:INFO:Physical Core: 6
2025-04-06 21:06:32,340:INFO:Logical Core: 12
2025-04-06 21:06:32,340:INFO:Checking libraries
2025-04-06 21:06:32,340:INFO:System:
2025-04-06 21:06:32,340:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:06:32,340:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:06:32,340:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:06:32,340:INFO:PyCaret required dependencies:
2025-04-06 21:06:35,356:INFO:                 pip: 25.0.1
2025-04-06 21:06:35,356:INFO:          setuptools: 65.5.0
2025-04-06 21:06:35,356:INFO:             pycaret: 3.3.2
2025-04-06 21:06:35,356:INFO:             IPython: 8.32.0
2025-04-06 21:06:35,356:INFO:          ipywidgets: 8.1.5
2025-04-06 21:06:35,356:INFO:                tqdm: 4.67.1
2025-04-06 21:06:35,356:INFO:               numpy: 1.26.4
2025-04-06 21:06:35,356:INFO:              pandas: 2.1.4
2025-04-06 21:06:35,356:INFO:              jinja2: 3.1.2
2025-04-06 21:06:35,356:INFO:               scipy: 1.11.4
2025-04-06 21:06:35,356:INFO:              joblib: 1.3.2
2025-04-06 21:06:35,356:INFO:             sklearn: 1.4.2
2025-04-06 21:06:35,356:INFO:                pyod: 2.0.3
2025-04-06 21:06:35,356:INFO:            imblearn: 0.13.0
2025-04-06 21:06:35,356:INFO:   category_encoders: 2.7.0
2025-04-06 21:06:35,356:INFO:            lightgbm: 4.6.0
2025-04-06 21:06:35,357:INFO:               numba: 0.61.0
2025-04-06 21:06:35,357:INFO:            requests: 2.32.3
2025-04-06 21:06:35,357:INFO:          matplotlib: 3.7.5
2025-04-06 21:06:35,357:INFO:          scikitplot: 0.3.7
2025-04-06 21:06:35,357:INFO:         yellowbrick: 1.5
2025-04-06 21:06:35,357:INFO:              plotly: 5.24.1
2025-04-06 21:06:35,357:INFO:    plotly-resampler: Not installed
2025-04-06 21:06:35,357:INFO:             kaleido: 0.2.1
2025-04-06 21:06:35,357:INFO:           schemdraw: 0.15
2025-04-06 21:06:35,357:INFO:         statsmodels: 0.14.4
2025-04-06 21:06:35,357:INFO:              sktime: 0.26.0
2025-04-06 21:06:35,357:INFO:               tbats: 1.1.3
2025-04-06 21:06:35,357:INFO:            pmdarima: 2.0.4
2025-04-06 21:06:35,357:INFO:              psutil: 7.0.0
2025-04-06 21:06:35,357:INFO:          markupsafe: 2.1.3
2025-04-06 21:06:35,357:INFO:             pickle5: Not installed
2025-04-06 21:06:35,357:INFO:         cloudpickle: 3.1.1
2025-04-06 21:06:35,357:INFO:         deprecation: 2.1.0
2025-04-06 21:06:35,357:INFO:              xxhash: 3.5.0
2025-04-06 21:06:35,357:INFO:           wurlitzer: Not installed
2025-04-06 21:06:35,358:INFO:PyCaret optional dependencies:
2025-04-06 21:06:42,516:INFO:                shap: 0.44.1
2025-04-06 21:06:42,516:INFO:           interpret: 0.6.9
2025-04-06 21:06:42,516:INFO:                umap: 0.5.7
2025-04-06 21:06:42,516:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:06:42,516:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:06:42,516:INFO:             autoviz: Not installed
2025-04-06 21:06:42,516:INFO:           fairlearn: 0.7.0
2025-04-06 21:06:42,516:INFO:          deepchecks: Not installed
2025-04-06 21:06:42,516:INFO:             xgboost: Not installed
2025-04-06 21:06:42,516:INFO:            catboost: 1.2.7
2025-04-06 21:06:42,516:INFO:              kmodes: 0.12.2
2025-04-06 21:06:42,516:INFO:             mlxtend: 0.23.4
2025-04-06 21:06:42,516:INFO:       statsforecast: 1.5.0
2025-04-06 21:06:42,516:INFO:        tune_sklearn: Not installed
2025-04-06 21:06:42,516:INFO:                 ray: Not installed
2025-04-06 21:06:42,517:INFO:            hyperopt: 0.2.7
2025-04-06 21:06:42,517:INFO:              optuna: 4.2.1
2025-04-06 21:06:42,517:INFO:               skopt: 0.10.2
2025-04-06 21:06:42,517:INFO:              mlflow: 2.21.0
2025-04-06 21:06:42,517:INFO:              gradio: 5.21.0
2025-04-06 21:06:42,517:INFO:             fastapi: 0.115.11
2025-04-06 21:06:42,517:INFO:             uvicorn: 0.34.0
2025-04-06 21:06:42,517:INFO:              m2cgen: 0.10.0
2025-04-06 21:06:42,517:INFO:           evidently: 0.4.40
2025-04-06 21:06:42,517:INFO:               fugue: 0.8.7
2025-04-06 21:06:42,517:INFO:           streamlit: 1.42.2
2025-04-06 21:06:42,517:INFO:             prophet: Not installed
2025-04-06 21:06:42,517:INFO:None
2025-04-06 21:06:42,517:INFO:Set up data.
2025-04-06 21:06:42,678:INFO:Set up folding strategy.
2025-04-06 21:06:42,679:INFO:Set up train/test split.
2025-04-06 21:06:56,241:INFO:PyCaret RegressionExperiment
2025-04-06 21:06:56,241:INFO:Logging name: reg-default-name
2025-04-06 21:06:56,241:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:06:56,241:INFO:version 3.3.2
2025-04-06 21:06:56,241:INFO:Initializing setup()
2025-04-06 21:06:56,242:INFO:self.USI: 1fbf
2025-04-06 21:06:56,242:INFO:self._variable_keys: {'seed', 'exp_id', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'data', 'USI', 'transform_target_param', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:06:56,242:INFO:Checking environment
2025-04-06 21:06:56,242:INFO:python_version: 3.11.4
2025-04-06 21:06:56,242:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:06:56,242:INFO:machine: AMD64
2025-04-06 21:06:56,242:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:06:56,247:INFO:Memory: svmem(total=17127211008, available=2227048448, percent=87.0, used=14900162560, free=2227048448)
2025-04-06 21:06:56,247:INFO:Physical Core: 6
2025-04-06 21:06:56,247:INFO:Logical Core: 12
2025-04-06 21:06:56,247:INFO:Checking libraries
2025-04-06 21:06:56,247:INFO:System:
2025-04-06 21:06:56,247:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:06:56,247:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:06:56,247:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:06:56,247:INFO:PyCaret required dependencies:
2025-04-06 21:06:56,248:INFO:                 pip: 25.0.1
2025-04-06 21:06:56,248:INFO:          setuptools: 65.5.0
2025-04-06 21:06:56,248:INFO:             pycaret: 3.3.2
2025-04-06 21:06:56,248:INFO:             IPython: 8.32.0
2025-04-06 21:06:56,248:INFO:          ipywidgets: 8.1.5
2025-04-06 21:06:56,248:INFO:                tqdm: 4.67.1
2025-04-06 21:06:56,248:INFO:               numpy: 1.26.4
2025-04-06 21:06:56,248:INFO:              pandas: 2.1.4
2025-04-06 21:06:56,248:INFO:              jinja2: 3.1.2
2025-04-06 21:06:56,248:INFO:               scipy: 1.11.4
2025-04-06 21:06:56,248:INFO:              joblib: 1.3.2
2025-04-06 21:06:56,248:INFO:             sklearn: 1.4.2
2025-04-06 21:06:56,248:INFO:                pyod: 2.0.3
2025-04-06 21:06:56,248:INFO:            imblearn: 0.13.0
2025-04-06 21:06:56,248:INFO:   category_encoders: 2.7.0
2025-04-06 21:06:56,248:INFO:            lightgbm: 4.6.0
2025-04-06 21:06:56,248:INFO:               numba: 0.61.0
2025-04-06 21:06:56,248:INFO:            requests: 2.32.3
2025-04-06 21:06:56,248:INFO:          matplotlib: 3.7.5
2025-04-06 21:06:56,249:INFO:          scikitplot: 0.3.7
2025-04-06 21:06:56,249:INFO:         yellowbrick: 1.5
2025-04-06 21:06:56,249:INFO:              plotly: 5.24.1
2025-04-06 21:06:56,249:INFO:    plotly-resampler: Not installed
2025-04-06 21:06:56,249:INFO:             kaleido: 0.2.1
2025-04-06 21:06:56,249:INFO:           schemdraw: 0.15
2025-04-06 21:06:56,249:INFO:         statsmodels: 0.14.4
2025-04-06 21:06:56,249:INFO:              sktime: 0.26.0
2025-04-06 21:06:56,249:INFO:               tbats: 1.1.3
2025-04-06 21:06:56,249:INFO:            pmdarima: 2.0.4
2025-04-06 21:06:56,249:INFO:              psutil: 7.0.0
2025-04-06 21:06:56,249:INFO:          markupsafe: 2.1.3
2025-04-06 21:06:56,249:INFO:             pickle5: Not installed
2025-04-06 21:06:56,249:INFO:         cloudpickle: 3.1.1
2025-04-06 21:06:56,249:INFO:         deprecation: 2.1.0
2025-04-06 21:06:56,249:INFO:              xxhash: 3.5.0
2025-04-06 21:06:56,249:INFO:           wurlitzer: Not installed
2025-04-06 21:06:56,249:INFO:PyCaret optional dependencies:
2025-04-06 21:06:56,249:INFO:                shap: 0.44.1
2025-04-06 21:06:56,249:INFO:           interpret: 0.6.9
2025-04-06 21:06:56,250:INFO:                umap: 0.5.7
2025-04-06 21:06:56,250:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:06:56,250:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:06:56,250:INFO:             autoviz: Not installed
2025-04-06 21:06:56,250:INFO:           fairlearn: 0.7.0
2025-04-06 21:06:56,250:INFO:          deepchecks: Not installed
2025-04-06 21:06:56,250:INFO:             xgboost: Not installed
2025-04-06 21:06:56,250:INFO:            catboost: 1.2.7
2025-04-06 21:06:56,250:INFO:              kmodes: 0.12.2
2025-04-06 21:06:56,250:INFO:             mlxtend: 0.23.4
2025-04-06 21:06:56,250:INFO:       statsforecast: 1.5.0
2025-04-06 21:06:56,250:INFO:        tune_sklearn: Not installed
2025-04-06 21:06:56,250:INFO:                 ray: Not installed
2025-04-06 21:06:56,250:INFO:            hyperopt: 0.2.7
2025-04-06 21:06:56,250:INFO:              optuna: 4.2.1
2025-04-06 21:06:56,250:INFO:               skopt: 0.10.2
2025-04-06 21:06:56,250:INFO:              mlflow: 2.21.0
2025-04-06 21:06:56,251:INFO:              gradio: 5.21.0
2025-04-06 21:06:56,251:INFO:             fastapi: 0.115.11
2025-04-06 21:06:56,251:INFO:             uvicorn: 0.34.0
2025-04-06 21:06:56,251:INFO:              m2cgen: 0.10.0
2025-04-06 21:06:56,251:INFO:           evidently: 0.4.40
2025-04-06 21:06:56,251:INFO:               fugue: 0.8.7
2025-04-06 21:06:56,251:INFO:           streamlit: 1.42.2
2025-04-06 21:06:56,251:INFO:             prophet: Not installed
2025-04-06 21:06:56,251:INFO:None
2025-04-06 21:06:56,251:INFO:Set up data.
2025-04-06 21:06:56,402:INFO:Set up folding strategy.
2025-04-06 21:06:56,402:INFO:Set up train/test split.
2025-04-06 21:06:56,499:INFO:Set up index.
2025-04-06 21:06:56,502:INFO:Assigning column types.
2025-04-06 21:06:56,508:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:06:56,508:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,514:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,520:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,664:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:56,665:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:56,884:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,889:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:56,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,032:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,033:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:06:57,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,044:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,182:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,195:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,333:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,333:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:06:57,345:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,483:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,573:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,631:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,631:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:06:57,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,787:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:06:57,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:57,934:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:57,935:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:06:58,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:58,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,084:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:06:58,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,238:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,239:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:06:58,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,386:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:06:58,533:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:06:58,542:INFO:Preparing preprocessing pipeline...
2025-04-06 21:06:58,542:INFO:Set up simple imputation.
2025-04-06 21:06:58,556:INFO:Set up encoding of categorical features.
2025-04-06 21:07:00,383:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:07:00,391:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:07:00,391:INFO:Creating final display dataframe.
2025-04-06 21:07:03,509:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape       (30000, 16)
4        Transformed data shape       (30000, 16)
5   Transformed train set shape       (21000, 16)
6    Transformed test set shape        (9000, 16)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              3.2%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              1fbf
2025-04-06 21:07:03,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:07:03,735:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:07:03,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:07:03,888:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:07:03,889:INFO:setup() successfully completed in 7.65s...............
2025-04-06 21:07:03,889:INFO:Initializing compare_models()
2025-04-06 21:07:03,889:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:07:03,889:INFO:Checking exceptions
2025-04-06 21:07:03,894:INFO:Preparing display monitor
2025-04-06 21:07:03,898:INFO:Initializing Linear Regression
2025-04-06 21:07:03,898:INFO:Total runtime is 0.0 minutes
2025-04-06 21:07:03,899:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:03,899:INFO:Initializing create_model()
2025-04-06 21:07:03,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:03,899:INFO:Checking exceptions
2025-04-06 21:07:03,899:INFO:Importing libraries
2025-04-06 21:07:03,899:INFO:Copying training dataset
2025-04-06 21:07:03,911:INFO:Defining folds
2025-04-06 21:07:03,911:INFO:Declaring metric variables
2025-04-06 21:07:03,911:INFO:Importing untrained model
2025-04-06 21:07:03,911:INFO:Linear Regression Imported successfully
2025-04-06 21:07:03,912:INFO:Starting cross validation
2025-04-06 21:07:03,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:16,399:INFO:Calculating mean and std
2025-04-06 21:07:16,400:INFO:Creating metrics dataframe
2025-04-06 21:07:16,403:INFO:Uploading results into container
2025-04-06 21:07:16,404:INFO:Uploading model into container now
2025-04-06 21:07:16,404:INFO:_master_model_container: 1
2025-04-06 21:07:16,404:INFO:_display_container: 2
2025-04-06 21:07:16,404:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:07:16,404:INFO:create_model() successfully completed......................................
2025-04-06 21:07:16,653:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:16,653:INFO:Creating metrics dataframe
2025-04-06 21:07:16,655:INFO:Initializing Lasso Regression
2025-04-06 21:07:16,655:INFO:Total runtime is 0.21262481609980266 minutes
2025-04-06 21:07:16,655:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:16,656:INFO:Initializing create_model()
2025-04-06 21:07:16,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:16,656:INFO:Checking exceptions
2025-04-06 21:07:16,656:INFO:Importing libraries
2025-04-06 21:07:16,656:INFO:Copying training dataset
2025-04-06 21:07:16,668:INFO:Defining folds
2025-04-06 21:07:16,668:INFO:Declaring metric variables
2025-04-06 21:07:16,668:INFO:Importing untrained model
2025-04-06 21:07:16,669:INFO:Lasso Regression Imported successfully
2025-04-06 21:07:16,669:INFO:Starting cross validation
2025-04-06 21:07:16,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:18,823:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.574e+15, tolerance: 2.175e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,120:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.767e+15, tolerance: 2.004e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,285:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.857e+15, tolerance: 2.141e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.569e+15, tolerance: 2.137e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,575:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.051e+15, tolerance: 2.057e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.895e+15, tolerance: 2.217e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,863:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.029e+15, tolerance: 2.021e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:19,995:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.293e+15, tolerance: 2.123e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,479:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.662e+15, tolerance: 2.076e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,523:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.006e+15, tolerance: 1.903e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:25,578:INFO:Calculating mean and std
2025-04-06 21:07:25,579:INFO:Creating metrics dataframe
2025-04-06 21:07:25,581:INFO:Uploading results into container
2025-04-06 21:07:25,581:INFO:Uploading model into container now
2025-04-06 21:07:25,582:INFO:_master_model_container: 2
2025-04-06 21:07:25,582:INFO:_display_container: 2
2025-04-06 21:07:25,582:INFO:Lasso(random_state=123)
2025-04-06 21:07:25,582:INFO:create_model() successfully completed......................................
2025-04-06 21:07:25,789:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:25,789:INFO:Creating metrics dataframe
2025-04-06 21:07:25,791:INFO:Initializing Ridge Regression
2025-04-06 21:07:25,792:INFO:Total runtime is 0.3649000644683838 minutes
2025-04-06 21:07:25,792:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:25,792:INFO:Initializing create_model()
2025-04-06 21:07:25,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:25,792:INFO:Checking exceptions
2025-04-06 21:07:25,792:INFO:Importing libraries
2025-04-06 21:07:25,792:INFO:Copying training dataset
2025-04-06 21:07:25,804:INFO:Defining folds
2025-04-06 21:07:25,804:INFO:Declaring metric variables
2025-04-06 21:07:25,804:INFO:Importing untrained model
2025-04-06 21:07:25,805:INFO:Ridge Regression Imported successfully
2025-04-06 21:07:25,805:INFO:Starting cross validation
2025-04-06 21:07:25,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:28,560:INFO:Calculating mean and std
2025-04-06 21:07:28,561:INFO:Creating metrics dataframe
2025-04-06 21:07:28,562:INFO:Uploading results into container
2025-04-06 21:07:28,563:INFO:Uploading model into container now
2025-04-06 21:07:28,563:INFO:_master_model_container: 3
2025-04-06 21:07:28,563:INFO:_display_container: 2
2025-04-06 21:07:28,563:INFO:Ridge(random_state=123)
2025-04-06 21:07:28,563:INFO:create_model() successfully completed......................................
2025-04-06 21:07:28,743:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:28,743:INFO:Creating metrics dataframe
2025-04-06 21:07:28,745:INFO:Initializing Elastic Net
2025-04-06 21:07:28,745:INFO:Total runtime is 0.4141197959582011 minutes
2025-04-06 21:07:28,746:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:28,746:INFO:Initializing create_model()
2025-04-06 21:07:28,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:28,746:INFO:Checking exceptions
2025-04-06 21:07:28,746:INFO:Importing libraries
2025-04-06 21:07:28,746:INFO:Copying training dataset
2025-04-06 21:07:28,759:INFO:Defining folds
2025-04-06 21:07:28,759:INFO:Declaring metric variables
2025-04-06 21:07:28,759:INFO:Importing untrained model
2025-04-06 21:07:28,760:INFO:Elastic Net Imported successfully
2025-04-06 21:07:28,760:INFO:Starting cross validation
2025-04-06 21:07:28,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:30,497:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.016e+15, tolerance: 1.903e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:30,828:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.673e+15, tolerance: 2.076e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,160:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.584e+15, tolerance: 2.175e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.774e+15, tolerance: 2.004e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,489:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.866e+15, tolerance: 2.141e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,652:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+15, tolerance: 2.137e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,745:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.061e+15, tolerance: 2.057e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,933:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.908e+15, tolerance: 2.217e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:31,948:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.037e+15, tolerance: 2.021e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:32,052:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e+15, tolerance: 2.123e+13
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:07:32,097:INFO:Calculating mean and std
2025-04-06 21:07:32,098:INFO:Creating metrics dataframe
2025-04-06 21:07:32,099:INFO:Uploading results into container
2025-04-06 21:07:32,100:INFO:Uploading model into container now
2025-04-06 21:07:32,100:INFO:_master_model_container: 4
2025-04-06 21:07:32,100:INFO:_display_container: 2
2025-04-06 21:07:32,101:INFO:ElasticNet(random_state=123)
2025-04-06 21:07:32,101:INFO:create_model() successfully completed......................................
2025-04-06 21:07:32,298:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:32,298:INFO:Creating metrics dataframe
2025-04-06 21:07:32,301:INFO:Initializing Least Angle Regression
2025-04-06 21:07:32,301:INFO:Total runtime is 0.4733945568402608 minutes
2025-04-06 21:07:32,301:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:32,302:INFO:Initializing create_model()
2025-04-06 21:07:32,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:32,302:INFO:Checking exceptions
2025-04-06 21:07:32,302:INFO:Importing libraries
2025-04-06 21:07:32,302:INFO:Copying training dataset
2025-04-06 21:07:32,315:INFO:Defining folds
2025-04-06 21:07:32,315:INFO:Declaring metric variables
2025-04-06 21:07:32,315:INFO:Importing untrained model
2025-04-06 21:07:32,315:INFO:Least Angle Regression Imported successfully
2025-04-06 21:07:32,316:INFO:Starting cross validation
2025-04-06 21:07:32,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:34,905:INFO:Calculating mean and std
2025-04-06 21:07:34,906:INFO:Creating metrics dataframe
2025-04-06 21:07:34,907:INFO:Uploading results into container
2025-04-06 21:07:34,908:INFO:Uploading model into container now
2025-04-06 21:07:34,908:INFO:_master_model_container: 5
2025-04-06 21:07:34,908:INFO:_display_container: 2
2025-04-06 21:07:34,908:INFO:Lars(random_state=123)
2025-04-06 21:07:34,909:INFO:create_model() successfully completed......................................
2025-04-06 21:07:35,099:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:35,099:INFO:Creating metrics dataframe
2025-04-06 21:07:35,101:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:07:35,101:INFO:Total runtime is 0.52005881468455 minutes
2025-04-06 21:07:35,102:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:35,102:INFO:Initializing create_model()
2025-04-06 21:07:35,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:35,102:INFO:Checking exceptions
2025-04-06 21:07:35,102:INFO:Importing libraries
2025-04-06 21:07:35,102:INFO:Copying training dataset
2025-04-06 21:07:35,113:INFO:Defining folds
2025-04-06 21:07:35,113:INFO:Declaring metric variables
2025-04-06 21:07:35,114:INFO:Importing untrained model
2025-04-06 21:07:35,114:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:07:35,114:INFO:Starting cross validation
2025-04-06 21:07:35,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:37,791:INFO:Calculating mean and std
2025-04-06 21:07:37,792:INFO:Creating metrics dataframe
2025-04-06 21:07:37,794:INFO:Uploading results into container
2025-04-06 21:07:37,794:INFO:Uploading model into container now
2025-04-06 21:07:37,794:INFO:_master_model_container: 6
2025-04-06 21:07:37,794:INFO:_display_container: 2
2025-04-06 21:07:37,795:INFO:LassoLars(random_state=123)
2025-04-06 21:07:37,795:INFO:create_model() successfully completed......................................
2025-04-06 21:07:37,981:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:37,981:INFO:Creating metrics dataframe
2025-04-06 21:07:37,983:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:07:37,983:INFO:Total runtime is 0.5680956323941548 minutes
2025-04-06 21:07:37,983:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:37,984:INFO:Initializing create_model()
2025-04-06 21:07:37,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:37,984:INFO:Checking exceptions
2025-04-06 21:07:37,984:INFO:Importing libraries
2025-04-06 21:07:37,984:INFO:Copying training dataset
2025-04-06 21:07:37,996:INFO:Defining folds
2025-04-06 21:07:37,997:INFO:Declaring metric variables
2025-04-06 21:07:37,997:INFO:Importing untrained model
2025-04-06 21:07:37,997:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:07:37,997:INFO:Starting cross validation
2025-04-06 21:07:37,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:40,559:INFO:Calculating mean and std
2025-04-06 21:07:40,560:INFO:Creating metrics dataframe
2025-04-06 21:07:40,561:INFO:Uploading results into container
2025-04-06 21:07:40,562:INFO:Uploading model into container now
2025-04-06 21:07:40,562:INFO:_master_model_container: 7
2025-04-06 21:07:40,562:INFO:_display_container: 2
2025-04-06 21:07:40,562:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:07:40,563:INFO:create_model() successfully completed......................................
2025-04-06 21:07:40,742:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:40,742:INFO:Creating metrics dataframe
2025-04-06 21:07:40,744:INFO:Initializing Bayesian Ridge
2025-04-06 21:07:40,745:INFO:Total runtime is 0.614098604520162 minutes
2025-04-06 21:07:40,745:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:40,745:INFO:Initializing create_model()
2025-04-06 21:07:40,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:40,746:INFO:Checking exceptions
2025-04-06 21:07:40,746:INFO:Importing libraries
2025-04-06 21:07:40,746:INFO:Copying training dataset
2025-04-06 21:07:40,757:INFO:Defining folds
2025-04-06 21:07:40,757:INFO:Declaring metric variables
2025-04-06 21:07:40,757:INFO:Importing untrained model
2025-04-06 21:07:40,758:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:07:40,758:INFO:Starting cross validation
2025-04-06 21:07:40,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:43,386:INFO:Calculating mean and std
2025-04-06 21:07:43,387:INFO:Creating metrics dataframe
2025-04-06 21:07:43,389:INFO:Uploading results into container
2025-04-06 21:07:43,389:INFO:Uploading model into container now
2025-04-06 21:07:43,389:INFO:_master_model_container: 8
2025-04-06 21:07:43,389:INFO:_display_container: 2
2025-04-06 21:07:43,390:INFO:BayesianRidge()
2025-04-06 21:07:43,390:INFO:create_model() successfully completed......................................
2025-04-06 21:07:43,595:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:43,595:INFO:Creating metrics dataframe
2025-04-06 21:07:43,597:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:07:43,597:INFO:Total runtime is 0.6616563200950623 minutes
2025-04-06 21:07:43,597:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:43,598:INFO:Initializing create_model()
2025-04-06 21:07:43,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:43,598:INFO:Checking exceptions
2025-04-06 21:07:43,598:INFO:Importing libraries
2025-04-06 21:07:43,598:INFO:Copying training dataset
2025-04-06 21:07:43,609:INFO:Defining folds
2025-04-06 21:07:43,610:INFO:Declaring metric variables
2025-04-06 21:07:43,610:INFO:Importing untrained model
2025-04-06 21:07:43,610:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:07:43,610:INFO:Starting cross validation
2025-04-06 21:07:43,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:46,297:INFO:Calculating mean and std
2025-04-06 21:07:46,298:INFO:Creating metrics dataframe
2025-04-06 21:07:46,299:INFO:Uploading results into container
2025-04-06 21:07:46,300:INFO:Uploading model into container now
2025-04-06 21:07:46,300:INFO:_master_model_container: 9
2025-04-06 21:07:46,300:INFO:_display_container: 2
2025-04-06 21:07:46,300:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:07:46,301:INFO:create_model() successfully completed......................................
2025-04-06 21:07:46,488:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:46,488:INFO:Creating metrics dataframe
2025-04-06 21:07:46,490:INFO:Initializing Huber Regressor
2025-04-06 21:07:46,491:INFO:Total runtime is 0.7098896821339925 minutes
2025-04-06 21:07:46,491:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:46,491:INFO:Initializing create_model()
2025-04-06 21:07:46,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:46,491:INFO:Checking exceptions
2025-04-06 21:07:46,491:INFO:Importing libraries
2025-04-06 21:07:46,491:INFO:Copying training dataset
2025-04-06 21:07:46,502:INFO:Defining folds
2025-04-06 21:07:46,503:INFO:Declaring metric variables
2025-04-06 21:07:46,503:INFO:Importing untrained model
2025-04-06 21:07:46,503:INFO:Huber Regressor Imported successfully
2025-04-06 21:07:46,503:INFO:Starting cross validation
2025-04-06 21:07:46,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:48,586:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,617:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,649:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:49,861:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,037:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,407:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,622:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,633:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:07:50,687:INFO:Calculating mean and std
2025-04-06 21:07:50,688:INFO:Creating metrics dataframe
2025-04-06 21:07:50,690:INFO:Uploading results into container
2025-04-06 21:07:50,690:INFO:Uploading model into container now
2025-04-06 21:07:50,691:INFO:_master_model_container: 10
2025-04-06 21:07:50,691:INFO:_display_container: 2
2025-04-06 21:07:50,691:INFO:HuberRegressor()
2025-04-06 21:07:50,691:INFO:create_model() successfully completed......................................
2025-04-06 21:07:50,876:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:50,876:INFO:Creating metrics dataframe
2025-04-06 21:07:50,878:INFO:Initializing K Neighbors Regressor
2025-04-06 21:07:50,878:INFO:Total runtime is 0.7830108602841696 minutes
2025-04-06 21:07:50,878:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:50,878:INFO:Initializing create_model()
2025-04-06 21:07:50,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:50,879:INFO:Checking exceptions
2025-04-06 21:07:50,879:INFO:Importing libraries
2025-04-06 21:07:50,879:INFO:Copying training dataset
2025-04-06 21:07:50,891:INFO:Defining folds
2025-04-06 21:07:50,891:INFO:Declaring metric variables
2025-04-06 21:07:50,891:INFO:Importing untrained model
2025-04-06 21:07:50,891:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:07:50,892:INFO:Starting cross validation
2025-04-06 21:07:50,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:53,730:INFO:Calculating mean and std
2025-04-06 21:07:53,731:INFO:Creating metrics dataframe
2025-04-06 21:07:53,733:INFO:Uploading results into container
2025-04-06 21:07:53,734:INFO:Uploading model into container now
2025-04-06 21:07:53,734:INFO:_master_model_container: 11
2025-04-06 21:07:53,734:INFO:_display_container: 2
2025-04-06 21:07:53,734:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:07:53,734:INFO:create_model() successfully completed......................................
2025-04-06 21:07:53,912:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:53,913:INFO:Creating metrics dataframe
2025-04-06 21:07:53,915:INFO:Initializing Decision Tree Regressor
2025-04-06 21:07:53,915:INFO:Total runtime is 0.833623468875885 minutes
2025-04-06 21:07:53,915:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:53,915:INFO:Initializing create_model()
2025-04-06 21:07:53,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:53,915:INFO:Checking exceptions
2025-04-06 21:07:53,916:INFO:Importing libraries
2025-04-06 21:07:53,916:INFO:Copying training dataset
2025-04-06 21:07:53,928:INFO:Defining folds
2025-04-06 21:07:53,928:INFO:Declaring metric variables
2025-04-06 21:07:53,928:INFO:Importing untrained model
2025-04-06 21:07:53,928:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:07:53,929:INFO:Starting cross validation
2025-04-06 21:07:53,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:07:56,981:INFO:Calculating mean and std
2025-04-06 21:07:56,981:INFO:Creating metrics dataframe
2025-04-06 21:07:56,983:INFO:Uploading results into container
2025-04-06 21:07:56,983:INFO:Uploading model into container now
2025-04-06 21:07:56,984:INFO:_master_model_container: 12
2025-04-06 21:07:56,984:INFO:_display_container: 2
2025-04-06 21:07:56,984:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:07:56,984:INFO:create_model() successfully completed......................................
2025-04-06 21:07:57,167:INFO:SubProcess create_model() end ==================================
2025-04-06 21:07:57,167:INFO:Creating metrics dataframe
2025-04-06 21:07:57,170:INFO:Initializing Random Forest Regressor
2025-04-06 21:07:57,170:INFO:Total runtime is 0.8878786206245423 minutes
2025-04-06 21:07:57,170:INFO:SubProcess create_model() called ==================================
2025-04-06 21:07:57,171:INFO:Initializing create_model()
2025-04-06 21:07:57,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:07:57,171:INFO:Checking exceptions
2025-04-06 21:07:57,171:INFO:Importing libraries
2025-04-06 21:07:57,171:INFO:Copying training dataset
2025-04-06 21:07:57,185:INFO:Defining folds
2025-04-06 21:07:57,185:INFO:Declaring metric variables
2025-04-06 21:07:57,185:INFO:Importing untrained model
2025-04-06 21:07:57,185:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:07:57,186:INFO:Starting cross validation
2025-04-06 21:07:57,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:35,297:INFO:Calculating mean and std
2025-04-06 21:08:35,300:INFO:Creating metrics dataframe
2025-04-06 21:08:35,303:INFO:Uploading results into container
2025-04-06 21:08:35,304:INFO:Uploading model into container now
2025-04-06 21:08:35,305:INFO:_master_model_container: 13
2025-04-06 21:08:35,305:INFO:_display_container: 2
2025-04-06 21:08:35,306:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:08:35,306:INFO:create_model() successfully completed......................................
2025-04-06 21:08:35,584:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:35,584:INFO:Creating metrics dataframe
2025-04-06 21:08:35,588:INFO:Initializing Extra Trees Regressor
2025-04-06 21:08:35,588:INFO:Total runtime is 1.5281803170839945 minutes
2025-04-06 21:08:35,589:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:35,589:INFO:Initializing create_model()
2025-04-06 21:08:35,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:35,589:INFO:Checking exceptions
2025-04-06 21:08:35,589:INFO:Importing libraries
2025-04-06 21:08:35,589:INFO:Copying training dataset
2025-04-06 21:08:35,607:INFO:Defining folds
2025-04-06 21:08:35,607:INFO:Declaring metric variables
2025-04-06 21:08:35,607:INFO:Importing untrained model
2025-04-06 21:08:35,608:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:08:35,608:INFO:Starting cross validation
2025-04-06 21:08:35,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:51,335:INFO:Calculating mean and std
2025-04-06 21:08:51,337:INFO:Creating metrics dataframe
2025-04-06 21:08:51,338:INFO:Uploading results into container
2025-04-06 21:08:51,339:INFO:Uploading model into container now
2025-04-06 21:08:51,339:INFO:_master_model_container: 14
2025-04-06 21:08:51,339:INFO:_display_container: 2
2025-04-06 21:08:51,340:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:08:51,340:INFO:create_model() successfully completed......................................
2025-04-06 21:08:51,602:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:51,602:INFO:Creating metrics dataframe
2025-04-06 21:08:51,604:INFO:Initializing AdaBoost Regressor
2025-04-06 21:08:51,604:INFO:Total runtime is 1.7951062281926473 minutes
2025-04-06 21:08:51,605:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:51,605:INFO:Initializing create_model()
2025-04-06 21:08:51,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:51,605:INFO:Checking exceptions
2025-04-06 21:08:51,605:INFO:Importing libraries
2025-04-06 21:08:51,605:INFO:Copying training dataset
2025-04-06 21:08:51,617:INFO:Defining folds
2025-04-06 21:08:51,617:INFO:Declaring metric variables
2025-04-06 21:08:51,617:INFO:Importing untrained model
2025-04-06 21:08:51,617:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:08:51,618:INFO:Starting cross validation
2025-04-06 21:08:51,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:08:56,553:INFO:Calculating mean and std
2025-04-06 21:08:56,554:INFO:Creating metrics dataframe
2025-04-06 21:08:56,555:INFO:Uploading results into container
2025-04-06 21:08:56,556:INFO:Uploading model into container now
2025-04-06 21:08:56,556:INFO:_master_model_container: 15
2025-04-06 21:08:56,556:INFO:_display_container: 2
2025-04-06 21:08:56,557:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:08:56,557:INFO:create_model() successfully completed......................................
2025-04-06 21:08:56,740:INFO:SubProcess create_model() end ==================================
2025-04-06 21:08:56,741:INFO:Creating metrics dataframe
2025-04-06 21:08:56,743:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:08:56,743:INFO:Total runtime is 1.8807562788327534 minutes
2025-04-06 21:08:56,743:INFO:SubProcess create_model() called ==================================
2025-04-06 21:08:56,744:INFO:Initializing create_model()
2025-04-06 21:08:56,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:08:56,744:INFO:Checking exceptions
2025-04-06 21:08:56,744:INFO:Importing libraries
2025-04-06 21:08:56,744:INFO:Copying training dataset
2025-04-06 21:08:56,755:INFO:Defining folds
2025-04-06 21:08:56,755:INFO:Declaring metric variables
2025-04-06 21:08:56,755:INFO:Importing untrained model
2025-04-06 21:08:56,756:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:08:56,756:INFO:Starting cross validation
2025-04-06 21:08:56,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:09,264:INFO:Calculating mean and std
2025-04-06 21:09:09,265:INFO:Creating metrics dataframe
2025-04-06 21:09:09,266:INFO:Uploading results into container
2025-04-06 21:09:09,267:INFO:Uploading model into container now
2025-04-06 21:09:09,267:INFO:_master_model_container: 16
2025-04-06 21:09:09,267:INFO:_display_container: 2
2025-04-06 21:09:09,267:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:09:09,268:INFO:create_model() successfully completed......................................
2025-04-06 21:09:09,447:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:09,447:INFO:Creating metrics dataframe
2025-04-06 21:09:09,449:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:09:09,449:INFO:Total runtime is 2.092515472571055 minutes
2025-04-06 21:09:09,449:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:09,450:INFO:Initializing create_model()
2025-04-06 21:09:09,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:09,450:INFO:Checking exceptions
2025-04-06 21:09:09,450:INFO:Importing libraries
2025-04-06 21:09:09,450:INFO:Copying training dataset
2025-04-06 21:09:09,462:INFO:Defining folds
2025-04-06 21:09:09,462:INFO:Declaring metric variables
2025-04-06 21:09:09,462:INFO:Importing untrained model
2025-04-06 21:09:09,463:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:09:09,463:INFO:Starting cross validation
2025-04-06 21:09:09,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:13,339:INFO:Calculating mean and std
2025-04-06 21:09:13,341:INFO:Creating metrics dataframe
2025-04-06 21:09:13,343:INFO:Uploading results into container
2025-04-06 21:09:13,343:INFO:Uploading model into container now
2025-04-06 21:09:13,344:INFO:_master_model_container: 17
2025-04-06 21:09:13,344:INFO:_display_container: 2
2025-04-06 21:09:13,344:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:13,344:INFO:create_model() successfully completed......................................
2025-04-06 21:09:13,569:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:13,569:INFO:Creating metrics dataframe
2025-04-06 21:09:13,571:INFO:Initializing CatBoost Regressor
2025-04-06 21:09:13,572:INFO:Total runtime is 2.161234664916992 minutes
2025-04-06 21:09:13,572:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:13,572:INFO:Initializing create_model()
2025-04-06 21:09:13,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:13,572:INFO:Checking exceptions
2025-04-06 21:09:13,572:INFO:Importing libraries
2025-04-06 21:09:13,572:INFO:Copying training dataset
2025-04-06 21:09:13,584:INFO:Defining folds
2025-04-06 21:09:13,584:INFO:Declaring metric variables
2025-04-06 21:09:13,584:INFO:Importing untrained model
2025-04-06 21:09:13,589:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:09:13,589:INFO:Starting cross validation
2025-04-06 21:09:13,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:32,194:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 5873, in fit
    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5017, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5066, in _catboost._CatBoost._train
_catboost.CatBoostError: catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2025-04-06 21:09:32,194:INFO:Calculating mean and std
2025-04-06 21:09:32,195:INFO:Creating metrics dataframe
2025-04-06 21:09:32,197:INFO:Uploading results into container
2025-04-06 21:09:32,197:INFO:Uploading model into container now
2025-04-06 21:09:32,197:INFO:_master_model_container: 18
2025-04-06 21:09:32,197:INFO:_display_container: 2
2025-04-06 21:09:32,197:INFO:<catboost.core.CatBoostRegressor object at 0x0000029EB1F93190>
2025-04-06 21:09:32,197:INFO:create_model() successfully completed......................................
2025-04-06 21:09:32,386:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:32,387:INFO:Creating metrics dataframe
2025-04-06 21:09:32,389:INFO:Initializing Dummy Regressor
2025-04-06 21:09:32,389:INFO:Total runtime is 2.4748520652453103 minutes
2025-04-06 21:09:32,389:INFO:SubProcess create_model() called ==================================
2025-04-06 21:09:32,390:INFO:Initializing create_model()
2025-04-06 21:09:32,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029EA7C4BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:32,390:INFO:Checking exceptions
2025-04-06 21:09:32,390:INFO:Importing libraries
2025-04-06 21:09:32,390:INFO:Copying training dataset
2025-04-06 21:09:32,402:INFO:Defining folds
2025-04-06 21:09:32,402:INFO:Declaring metric variables
2025-04-06 21:09:32,402:INFO:Importing untrained model
2025-04-06 21:09:32,402:INFO:Dummy Regressor Imported successfully
2025-04-06 21:09:32,403:INFO:Starting cross validation
2025-04-06 21:09:32,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:09:34,869:INFO:Calculating mean and std
2025-04-06 21:09:34,870:INFO:Creating metrics dataframe
2025-04-06 21:09:34,872:INFO:Uploading results into container
2025-04-06 21:09:34,873:INFO:Uploading model into container now
2025-04-06 21:09:34,873:INFO:_master_model_container: 19
2025-04-06 21:09:34,873:INFO:_display_container: 2
2025-04-06 21:09:34,873:INFO:DummyRegressor()
2025-04-06 21:09:34,873:INFO:create_model() successfully completed......................................
2025-04-06 21:09:35,055:INFO:SubProcess create_model() end ==================================
2025-04-06 21:09:35,055:INFO:Creating metrics dataframe
2025-04-06 21:09:35,082:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:09:35,085:INFO:Initializing create_model()
2025-04-06 21:09:35,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000029EA7F17490>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:09:35,085:INFO:Checking exceptions
2025-04-06 21:09:35,086:INFO:Importing libraries
2025-04-06 21:09:35,086:INFO:Copying training dataset
2025-04-06 21:09:35,105:INFO:Defining folds
2025-04-06 21:09:35,105:INFO:Declaring metric variables
2025-04-06 21:09:35,105:INFO:Importing untrained model
2025-04-06 21:09:35,105:INFO:Declaring custom model
2025-04-06 21:09:35,106:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:09:35,108:INFO:Cross validation set to False
2025-04-06 21:09:35,108:INFO:Fitting Model
2025-04-06 21:09:37,367:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:37,367:INFO:create_model() successfully completed......................................
2025-04-06 21:09:37,536:INFO:_master_model_container: 19
2025-04-06 21:09:37,536:INFO:_display_container: 2
2025-04-06 21:09:37,537:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:09:37,537:INFO:compare_models() successfully completed......................................
2025-04-06 21:14:04,606:INFO:PyCaret ClusteringExperiment
2025-04-06 21:14:04,607:INFO:Logging name: cluster-default-name
2025-04-06 21:14:04,607:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:14:04,607:INFO:version 3.3.2
2025-04-06 21:14:04,607:INFO:Initializing setup()
2025-04-06 21:14:04,607:INFO:self.USI: a478
2025-04-06 21:14:04,607:INFO:self._variable_keys: {'seed', 'exp_id', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'gpu_param', 'logging_param', 'log_plots_param', 'idx', 'X', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:14:04,607:INFO:Checking environment
2025-04-06 21:14:04,607:INFO:python_version: 3.11.4
2025-04-06 21:14:04,607:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:14:04,607:INFO:machine: AMD64
2025-04-06 21:14:04,607:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:14:04,614:INFO:Memory: svmem(total=17127211008, available=2370609152, percent=86.2, used=14756601856, free=2370609152)
2025-04-06 21:14:04,614:INFO:Physical Core: 6
2025-04-06 21:14:04,614:INFO:Logical Core: 12
2025-04-06 21:14:04,614:INFO:Checking libraries
2025-04-06 21:14:04,614:INFO:System:
2025-04-06 21:14:04,614:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:14:04,614:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:14:04,614:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:14:04,614:INFO:PyCaret required dependencies:
2025-04-06 21:14:04,615:INFO:                 pip: 25.0.1
2025-04-06 21:14:04,615:INFO:          setuptools: 65.5.0
2025-04-06 21:14:04,615:INFO:             pycaret: 3.3.2
2025-04-06 21:14:04,615:INFO:             IPython: 8.32.0
2025-04-06 21:14:04,615:INFO:          ipywidgets: 8.1.5
2025-04-06 21:14:04,615:INFO:                tqdm: 4.67.1
2025-04-06 21:14:04,615:INFO:               numpy: 1.26.4
2025-04-06 21:14:04,615:INFO:              pandas: 2.1.4
2025-04-06 21:14:04,615:INFO:              jinja2: 3.1.2
2025-04-06 21:14:04,615:INFO:               scipy: 1.11.4
2025-04-06 21:14:04,615:INFO:              joblib: 1.3.2
2025-04-06 21:14:04,615:INFO:             sklearn: 1.4.2
2025-04-06 21:14:04,615:INFO:                pyod: 2.0.3
2025-04-06 21:14:04,615:INFO:            imblearn: 0.13.0
2025-04-06 21:14:04,615:INFO:   category_encoders: 2.7.0
2025-04-06 21:14:04,615:INFO:            lightgbm: 4.6.0
2025-04-06 21:14:04,615:INFO:               numba: 0.61.0
2025-04-06 21:14:04,615:INFO:            requests: 2.32.3
2025-04-06 21:14:04,615:INFO:          matplotlib: 3.7.5
2025-04-06 21:14:04,616:INFO:          scikitplot: 0.3.7
2025-04-06 21:14:04,616:INFO:         yellowbrick: 1.5
2025-04-06 21:14:04,616:INFO:              plotly: 5.24.1
2025-04-06 21:14:04,616:INFO:    plotly-resampler: Not installed
2025-04-06 21:14:04,616:INFO:             kaleido: 0.2.1
2025-04-06 21:14:04,616:INFO:           schemdraw: 0.15
2025-04-06 21:14:04,616:INFO:         statsmodels: 0.14.4
2025-04-06 21:14:04,616:INFO:              sktime: 0.26.0
2025-04-06 21:14:04,616:INFO:               tbats: 1.1.3
2025-04-06 21:14:04,616:INFO:            pmdarima: 2.0.4
2025-04-06 21:14:04,616:INFO:              psutil: 7.0.0
2025-04-06 21:14:04,616:INFO:          markupsafe: 2.1.3
2025-04-06 21:14:04,616:INFO:             pickle5: Not installed
2025-04-06 21:14:04,616:INFO:         cloudpickle: 3.1.1
2025-04-06 21:14:04,616:INFO:         deprecation: 2.1.0
2025-04-06 21:14:04,616:INFO:              xxhash: 3.5.0
2025-04-06 21:14:04,616:INFO:           wurlitzer: Not installed
2025-04-06 21:14:04,616:INFO:PyCaret optional dependencies:
2025-04-06 21:14:04,616:INFO:                shap: 0.44.1
2025-04-06 21:14:04,617:INFO:           interpret: 0.6.9
2025-04-06 21:14:04,617:INFO:                umap: 0.5.7
2025-04-06 21:14:04,617:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:14:04,617:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:14:04,617:INFO:             autoviz: Not installed
2025-04-06 21:14:04,617:INFO:           fairlearn: 0.7.0
2025-04-06 21:14:04,617:INFO:          deepchecks: Not installed
2025-04-06 21:14:04,617:INFO:             xgboost: Not installed
2025-04-06 21:14:04,617:INFO:            catboost: 1.2.7
2025-04-06 21:14:04,617:INFO:              kmodes: 0.12.2
2025-04-06 21:14:04,617:INFO:             mlxtend: 0.23.4
2025-04-06 21:14:04,617:INFO:       statsforecast: 1.5.0
2025-04-06 21:14:04,617:INFO:        tune_sklearn: Not installed
2025-04-06 21:14:04,617:INFO:                 ray: Not installed
2025-04-06 21:14:04,617:INFO:            hyperopt: 0.2.7
2025-04-06 21:14:04,618:INFO:              optuna: 4.2.1
2025-04-06 21:14:04,618:INFO:               skopt: 0.10.2
2025-04-06 21:14:04,618:INFO:              mlflow: 2.21.0
2025-04-06 21:14:04,618:INFO:              gradio: 5.21.0
2025-04-06 21:14:04,618:INFO:             fastapi: 0.115.11
2025-04-06 21:14:04,618:INFO:             uvicorn: 0.34.0
2025-04-06 21:14:04,618:INFO:              m2cgen: 0.10.0
2025-04-06 21:14:04,618:INFO:           evidently: 0.4.40
2025-04-06 21:14:04,618:INFO:               fugue: 0.8.7
2025-04-06 21:14:04,618:INFO:           streamlit: 1.42.2
2025-04-06 21:14:04,618:INFO:             prophet: Not installed
2025-04-06 21:14:04,618:INFO:None
2025-04-06 21:14:04,618:INFO:Set up data.
2025-04-06 21:14:04,779:INFO:Set up index.
2025-04-06 21:14:04,779:INFO:Assigning column types.
2025-04-06 21:14:04,784:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:14:04,784:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:14:04,785:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,825:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:14:04,826:INFO:Preparing preprocessing pipeline...
2025-04-06 21:14:04,827:INFO:Set up simple imputation.
2025-04-06 21:14:04,832:INFO:Set up encoding of categorical features.
2025-04-06 21:16:49,896:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:16:49,941:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:16:50,353:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:19:12,240:INFO:PyCaret ClusteringExperiment
2025-04-06 21:19:12,240:INFO:Logging name: cluster-default-name
2025-04-06 21:19:12,240:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:19:12,240:INFO:version 3.3.2
2025-04-06 21:19:12,240:INFO:Initializing setup()
2025-04-06 21:19:12,240:INFO:self.USI: 02e7
2025-04-06 21:19:12,241:INFO:self._variable_keys: {'seed', 'exp_id', 'memory', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'gpu_param', 'logging_param', 'log_plots_param', 'idx', 'X', 'data', 'USI', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:19:12,241:INFO:Checking environment
2025-04-06 21:19:12,241:INFO:python_version: 3.11.4
2025-04-06 21:19:12,241:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:19:12,241:INFO:machine: AMD64
2025-04-06 21:19:12,241:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:19:12,247:INFO:Memory: svmem(total=17127211008, available=7965089792, percent=53.5, used=9162121216, free=7965089792)
2025-04-06 21:19:12,247:INFO:Physical Core: 6
2025-04-06 21:19:12,247:INFO:Logical Core: 12
2025-04-06 21:19:12,247:INFO:Checking libraries
2025-04-06 21:19:12,247:INFO:System:
2025-04-06 21:19:12,247:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:19:12,247:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:19:12,248:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:19:12,248:INFO:PyCaret required dependencies:
2025-04-06 21:19:12,248:INFO:                 pip: 25.0.1
2025-04-06 21:19:12,248:INFO:          setuptools: 65.5.0
2025-04-06 21:19:12,248:INFO:             pycaret: 3.3.2
2025-04-06 21:19:12,248:INFO:             IPython: 8.32.0
2025-04-06 21:19:12,248:INFO:          ipywidgets: 8.1.5
2025-04-06 21:19:12,248:INFO:                tqdm: 4.67.1
2025-04-06 21:19:12,248:INFO:               numpy: 1.26.4
2025-04-06 21:19:12,248:INFO:              pandas: 2.1.4
2025-04-06 21:19:12,248:INFO:              jinja2: 3.1.2
2025-04-06 21:19:12,248:INFO:               scipy: 1.11.4
2025-04-06 21:19:12,248:INFO:              joblib: 1.3.2
2025-04-06 21:19:12,248:INFO:             sklearn: 1.4.2
2025-04-06 21:19:12,248:INFO:                pyod: 2.0.3
2025-04-06 21:19:12,248:INFO:            imblearn: 0.13.0
2025-04-06 21:19:12,248:INFO:   category_encoders: 2.7.0
2025-04-06 21:19:12,248:INFO:            lightgbm: 4.6.0
2025-04-06 21:19:12,249:INFO:               numba: 0.61.0
2025-04-06 21:19:12,249:INFO:            requests: 2.32.3
2025-04-06 21:19:12,249:INFO:          matplotlib: 3.7.5
2025-04-06 21:19:12,249:INFO:          scikitplot: 0.3.7
2025-04-06 21:19:12,249:INFO:         yellowbrick: 1.5
2025-04-06 21:19:12,249:INFO:              plotly: 5.24.1
2025-04-06 21:19:12,249:INFO:    plotly-resampler: Not installed
2025-04-06 21:19:12,249:INFO:             kaleido: 0.2.1
2025-04-06 21:19:12,249:INFO:           schemdraw: 0.15
2025-04-06 21:19:12,249:INFO:         statsmodels: 0.14.4
2025-04-06 21:19:12,249:INFO:              sktime: 0.26.0
2025-04-06 21:19:12,249:INFO:               tbats: 1.1.3
2025-04-06 21:19:12,249:INFO:            pmdarima: 2.0.4
2025-04-06 21:19:12,249:INFO:              psutil: 7.0.0
2025-04-06 21:19:12,249:INFO:          markupsafe: 2.1.3
2025-04-06 21:19:12,249:INFO:             pickle5: Not installed
2025-04-06 21:19:12,249:INFO:         cloudpickle: 3.1.1
2025-04-06 21:19:12,249:INFO:         deprecation: 2.1.0
2025-04-06 21:19:12,249:INFO:              xxhash: 3.5.0
2025-04-06 21:19:12,249:INFO:           wurlitzer: Not installed
2025-04-06 21:19:12,249:INFO:PyCaret optional dependencies:
2025-04-06 21:19:12,250:INFO:                shap: 0.44.1
2025-04-06 21:19:12,250:INFO:           interpret: 0.6.9
2025-04-06 21:19:12,250:INFO:                umap: 0.5.7
2025-04-06 21:19:12,250:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:19:12,250:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:19:12,250:INFO:             autoviz: Not installed
2025-04-06 21:19:12,250:INFO:           fairlearn: 0.7.0
2025-04-06 21:19:12,250:INFO:          deepchecks: Not installed
2025-04-06 21:19:12,250:INFO:             xgboost: Not installed
2025-04-06 21:19:12,250:INFO:            catboost: 1.2.7
2025-04-06 21:19:12,250:INFO:              kmodes: 0.12.2
2025-04-06 21:19:12,250:INFO:             mlxtend: 0.23.4
2025-04-06 21:19:12,250:INFO:       statsforecast: 1.5.0
2025-04-06 21:19:12,250:INFO:        tune_sklearn: Not installed
2025-04-06 21:19:12,250:INFO:                 ray: Not installed
2025-04-06 21:19:12,250:INFO:            hyperopt: 0.2.7
2025-04-06 21:19:12,250:INFO:              optuna: 4.2.1
2025-04-06 21:19:12,250:INFO:               skopt: 0.10.2
2025-04-06 21:19:12,250:INFO:              mlflow: 2.21.0
2025-04-06 21:19:12,251:INFO:              gradio: 5.21.0
2025-04-06 21:19:12,251:INFO:             fastapi: 0.115.11
2025-04-06 21:19:12,251:INFO:             uvicorn: 0.34.0
2025-04-06 21:19:12,251:INFO:              m2cgen: 0.10.0
2025-04-06 21:19:12,251:INFO:           evidently: 0.4.40
2025-04-06 21:19:12,251:INFO:               fugue: 0.8.7
2025-04-06 21:19:12,251:INFO:           streamlit: 1.42.2
2025-04-06 21:19:12,251:INFO:             prophet: Not installed
2025-04-06 21:19:12,251:INFO:None
2025-04-06 21:19:12,251:INFO:Set up data.
2025-04-06 21:19:12,263:INFO:Set up index.
2025-04-06 21:19:12,263:INFO:Assigning column types.
2025-04-06 21:19:12,266:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:19:12,266:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:19:12,266:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,266:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,267:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,267:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:12,268:INFO:Preparing preprocessing pipeline...
2025-04-06 21:19:12,268:INFO:Set up simple imputation.
2025-04-06 21:19:12,272:INFO:Set up encoding of categorical features.
2025-04-06 21:19:16,056:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2025-04-06 21:19:16,057:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:19:16,064:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'likes',
                                             'dislikes', 'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thu...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=OneHotEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-06 21:19:16,064:INFO:Creating final display dataframe.
2025-04-06 21:19:19,590:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-06 21:19:20,663:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:19:20,674:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape            (1600, 16)
2     Transformed data shape          (1600, 6424)
3           Numeric features                     5
4       Categorical features                     8
5   Rows with missing values                  3.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  cluster-default-name
16                       USI                  02e7
2025-04-06 21:19:20,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:20,679:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:19:20,684:INFO:setup() successfully completed in 8.45s...............
2025-04-06 21:19:20,685:INFO:Initializing create_model()
2025-04-06 21:19:20,685:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002A1F4DAAAD0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-06 21:19:20,685:INFO:Checking exceptions
2025-04-06 21:19:21,762:INFO:Importing untrained model
2025-04-06 21:19:21,762:INFO:K-Means Clustering Imported successfully
2025-04-06 21:19:21,910:INFO:Fitting Model
2025-04-06 21:19:26,577:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:19:26,577:INFO:create_models() successfully completed......................................
2025-04-06 21:19:26,578:INFO:Uploading results into container
2025-04-06 21:19:26,579:INFO:Uploading model into container now
2025-04-06 21:19:26,586:INFO:_master_model_container: 1
2025-04-06 21:19:26,586:INFO:_display_container: 2
2025-04-06 21:19:26,586:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:19:26,586:INFO:create_model() successfully completed......................................
2025-04-06 21:22:04,081:INFO:PyCaret RegressionExperiment
2025-04-06 21:22:04,081:INFO:Logging name: reg-default-name
2025-04-06 21:22:04,081:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:22:04,081:INFO:version 3.3.2
2025-04-06 21:22:04,081:INFO:Initializing setup()
2025-04-06 21:22:04,081:INFO:self.USI: 3728
2025-04-06 21:22:04,081:INFO:self._variable_keys: {'seed', 'exp_id', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'pipeline', 'target_param', '_available_plots', 'gpu_param', 'y_test', 'logging_param', 'y', 'log_plots_param', 'idx', 'X_train', 'fold_shuffle_param', 'y_train', 'X', 'fold_groups_param', 'X_test', 'data', 'USI', 'transform_target_param', 'n_jobs_param', 'html_param', 'exp_name_log', '_ml_usecase'}
2025-04-06 21:22:04,081:INFO:Checking environment
2025-04-06 21:22:04,081:INFO:python_version: 3.11.4
2025-04-06 21:22:04,081:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:22:04,081:INFO:machine: AMD64
2025-04-06 21:22:04,081:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:22:04,092:INFO:Memory: svmem(total=17127211008, available=7550414848, percent=55.9, used=9576796160, free=7550414848)
2025-04-06 21:22:04,092:INFO:Physical Core: 6
2025-04-06 21:22:04,093:INFO:Logical Core: 12
2025-04-06 21:22:04,093:INFO:Checking libraries
2025-04-06 21:22:04,093:INFO:System:
2025-04-06 21:22:04,093:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:22:04,093:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:22:04,093:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:22:04,093:INFO:PyCaret required dependencies:
2025-04-06 21:22:04,093:INFO:                 pip: 25.0.1
2025-04-06 21:22:04,094:INFO:          setuptools: 65.5.0
2025-04-06 21:22:04,094:INFO:             pycaret: 3.3.2
2025-04-06 21:22:04,094:INFO:             IPython: 8.32.0
2025-04-06 21:22:04,094:INFO:          ipywidgets: 8.1.5
2025-04-06 21:22:04,094:INFO:                tqdm: 4.67.1
2025-04-06 21:22:04,094:INFO:               numpy: 1.26.4
2025-04-06 21:22:04,094:INFO:              pandas: 2.1.4
2025-04-06 21:22:04,094:INFO:              jinja2: 3.1.2
2025-04-06 21:22:04,094:INFO:               scipy: 1.11.4
2025-04-06 21:22:04,094:INFO:              joblib: 1.3.2
2025-04-06 21:22:04,094:INFO:             sklearn: 1.4.2
2025-04-06 21:22:04,094:INFO:                pyod: 2.0.3
2025-04-06 21:22:04,094:INFO:            imblearn: 0.13.0
2025-04-06 21:22:04,094:INFO:   category_encoders: 2.7.0
2025-04-06 21:22:04,094:INFO:            lightgbm: 4.6.0
2025-04-06 21:22:04,094:INFO:               numba: 0.61.0
2025-04-06 21:22:04,094:INFO:            requests: 2.32.3
2025-04-06 21:22:04,094:INFO:          matplotlib: 3.7.5
2025-04-06 21:22:04,095:INFO:          scikitplot: 0.3.7
2025-04-06 21:22:04,095:INFO:         yellowbrick: 1.5
2025-04-06 21:22:04,095:INFO:              plotly: 5.24.1
2025-04-06 21:22:04,095:INFO:    plotly-resampler: Not installed
2025-04-06 21:22:04,095:INFO:             kaleido: 0.2.1
2025-04-06 21:22:04,095:INFO:           schemdraw: 0.15
2025-04-06 21:22:04,095:INFO:         statsmodels: 0.14.4
2025-04-06 21:22:04,095:INFO:              sktime: 0.26.0
2025-04-06 21:22:04,095:INFO:               tbats: 1.1.3
2025-04-06 21:22:04,095:INFO:            pmdarima: 2.0.4
2025-04-06 21:22:04,095:INFO:              psutil: 7.0.0
2025-04-06 21:22:04,095:INFO:          markupsafe: 2.1.3
2025-04-06 21:22:04,095:INFO:             pickle5: Not installed
2025-04-06 21:22:04,095:INFO:         cloudpickle: 3.1.1
2025-04-06 21:22:04,095:INFO:         deprecation: 2.1.0
2025-04-06 21:22:04,095:INFO:              xxhash: 3.5.0
2025-04-06 21:22:04,095:INFO:           wurlitzer: Not installed
2025-04-06 21:22:04,095:INFO:PyCaret optional dependencies:
2025-04-06 21:22:04,095:INFO:                shap: 0.44.1
2025-04-06 21:22:04,096:INFO:           interpret: 0.6.9
2025-04-06 21:22:04,096:INFO:                umap: 0.5.7
2025-04-06 21:22:04,096:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:22:04,096:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:22:04,096:INFO:             autoviz: Not installed
2025-04-06 21:22:04,096:INFO:           fairlearn: 0.7.0
2025-04-06 21:22:04,096:INFO:          deepchecks: Not installed
2025-04-06 21:22:04,096:INFO:             xgboost: Not installed
2025-04-06 21:22:04,096:INFO:            catboost: 1.2.7
2025-04-06 21:22:04,096:INFO:              kmodes: 0.12.2
2025-04-06 21:22:04,096:INFO:             mlxtend: 0.23.4
2025-04-06 21:22:04,096:INFO:       statsforecast: 1.5.0
2025-04-06 21:22:04,096:INFO:        tune_sklearn: Not installed
2025-04-06 21:22:04,096:INFO:                 ray: Not installed
2025-04-06 21:22:04,096:INFO:            hyperopt: 0.2.7
2025-04-06 21:22:04,096:INFO:              optuna: 4.2.1
2025-04-06 21:22:04,096:INFO:               skopt: 0.10.2
2025-04-06 21:22:04,096:INFO:              mlflow: 2.21.0
2025-04-06 21:22:04,097:INFO:              gradio: 5.21.0
2025-04-06 21:22:04,097:INFO:             fastapi: 0.115.11
2025-04-06 21:22:04,097:INFO:             uvicorn: 0.34.0
2025-04-06 21:22:04,097:INFO:              m2cgen: 0.10.0
2025-04-06 21:22:04,097:INFO:           evidently: 0.4.40
2025-04-06 21:22:04,097:INFO:               fugue: 0.8.7
2025-04-06 21:22:04,097:INFO:           streamlit: 1.42.2
2025-04-06 21:22:04,097:INFO:             prophet: Not installed
2025-04-06 21:22:04,097:INFO:None
2025-04-06 21:22:04,097:INFO:Set up data.
2025-04-06 21:22:04,111:INFO:Set up folding strategy.
2025-04-06 21:22:04,111:INFO:Set up train/test split.
2025-04-06 21:22:04,127:INFO:Set up index.
2025-04-06 21:22:04,127:INFO:Assigning column types.
2025-04-06 21:22:04,132:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:22:04,132:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,283:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,291:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,428:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,429:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,430:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:22:04,437:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,443:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,578:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,728:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,728:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:22:04,741:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:04,876:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:04,889:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:22:04,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,026:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,027:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:22:05,119:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,177:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,324:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,324:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:22:05,410:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,469:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:22:05,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,626:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,627:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:22:05,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,772:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:05,919:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:05,921:INFO:Preparing preprocessing pipeline...
2025-04-06 21:22:05,921:INFO:Set up simple imputation.
2025-04-06 21:22:05,925:INFO:Set up encoding of categorical features.
2025-04-06 21:22:06,152:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:22:06,162:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:22:06,162:INFO:Creating final display dataframe.
2025-04-06 21:22:07,011:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1600, 16)
4        Transformed data shape        (1600, 24)
5   Transformed train set shape        (1120, 24)
6    Transformed test set shape         (480, 24)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              3.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3728
2025-04-06 21:22:07,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:07,203:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:07,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:22:07,374:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:22:07,375:INFO:setup() successfully completed in 3.3s...............
2025-04-06 21:22:07,375:INFO:Initializing compare_models()
2025-04-06 21:22:07,375:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:22:07,375:INFO:Checking exceptions
2025-04-06 21:22:07,378:INFO:Preparing display monitor
2025-04-06 21:22:07,380:INFO:Initializing Linear Regression
2025-04-06 21:22:07,380:INFO:Total runtime is 0.0 minutes
2025-04-06 21:22:07,380:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:07,380:INFO:Initializing create_model()
2025-04-06 21:22:07,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:07,380:INFO:Checking exceptions
2025-04-06 21:22:07,380:INFO:Importing libraries
2025-04-06 21:22:07,381:INFO:Copying training dataset
2025-04-06 21:22:07,386:INFO:Defining folds
2025-04-06 21:22:07,386:INFO:Declaring metric variables
2025-04-06 21:22:07,386:INFO:Importing untrained model
2025-04-06 21:22:07,386:INFO:Linear Regression Imported successfully
2025-04-06 21:22:07,386:INFO:Starting cross validation
2025-04-06 21:22:07,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:17,903:INFO:Calculating mean and std
2025-04-06 21:22:17,905:INFO:Creating metrics dataframe
2025-04-06 21:22:17,908:INFO:Uploading results into container
2025-04-06 21:22:17,909:INFO:Uploading model into container now
2025-04-06 21:22:17,911:INFO:_master_model_container: 1
2025-04-06 21:22:17,911:INFO:_display_container: 2
2025-04-06 21:22:17,912:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:22:17,912:INFO:create_model() successfully completed......................................
2025-04-06 21:22:18,194:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:18,195:INFO:Creating metrics dataframe
2025-04-06 21:22:18,197:INFO:Initializing Lasso Regression
2025-04-06 21:22:18,197:INFO:Total runtime is 0.18028005758921306 minutes
2025-04-06 21:22:18,197:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:18,197:INFO:Initializing create_model()
2025-04-06 21:22:18,197:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:18,197:INFO:Checking exceptions
2025-04-06 21:22:18,197:INFO:Importing libraries
2025-04-06 21:22:18,197:INFO:Copying training dataset
2025-04-06 21:22:18,202:INFO:Defining folds
2025-04-06 21:22:18,202:INFO:Declaring metric variables
2025-04-06 21:22:18,202:INFO:Importing untrained model
2025-04-06 21:22:18,202:INFO:Lasso Regression Imported successfully
2025-04-06 21:22:18,203:INFO:Starting cross validation
2025-04-06 21:22:18,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:18,460:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+14, tolerance: 6.350e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+14, tolerance: 6.616e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,508:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+14, tolerance: 7.104e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,525:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+14, tolerance: 6.987e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,561:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+14, tolerance: 7.562e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,568:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+14, tolerance: 7.503e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,602:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+14, tolerance: 6.975e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:18,608:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+14, tolerance: 7.344e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,659:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+14, tolerance: 7.010e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,685:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+14, tolerance: 5.322e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:22,724:INFO:Calculating mean and std
2025-04-06 21:22:22,725:INFO:Creating metrics dataframe
2025-04-06 21:22:22,727:INFO:Uploading results into container
2025-04-06 21:22:22,727:INFO:Uploading model into container now
2025-04-06 21:22:22,728:INFO:_master_model_container: 2
2025-04-06 21:22:22,728:INFO:_display_container: 2
2025-04-06 21:22:22,728:INFO:Lasso(random_state=123)
2025-04-06 21:22:22,728:INFO:create_model() successfully completed......................................
2025-04-06 21:22:22,927:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:22,927:INFO:Creating metrics dataframe
2025-04-06 21:22:22,929:INFO:Initializing Ridge Regression
2025-04-06 21:22:22,929:INFO:Total runtime is 0.2591538111368815 minutes
2025-04-06 21:22:22,930:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:22,930:INFO:Initializing create_model()
2025-04-06 21:22:22,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:22,930:INFO:Checking exceptions
2025-04-06 21:22:22,930:INFO:Importing libraries
2025-04-06 21:22:22,930:INFO:Copying training dataset
2025-04-06 21:22:22,935:INFO:Defining folds
2025-04-06 21:22:22,936:INFO:Declaring metric variables
2025-04-06 21:22:22,936:INFO:Importing untrained model
2025-04-06 21:22:22,936:INFO:Ridge Regression Imported successfully
2025-04-06 21:22:22,936:INFO:Starting cross validation
2025-04-06 21:22:22,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:23,325:INFO:Calculating mean and std
2025-04-06 21:22:23,326:INFO:Creating metrics dataframe
2025-04-06 21:22:23,328:INFO:Uploading results into container
2025-04-06 21:22:23,328:INFO:Uploading model into container now
2025-04-06 21:22:23,328:INFO:_master_model_container: 3
2025-04-06 21:22:23,328:INFO:_display_container: 2
2025-04-06 21:22:23,328:INFO:Ridge(random_state=123)
2025-04-06 21:22:23,328:INFO:create_model() successfully completed......................................
2025-04-06 21:22:23,521:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:23,522:INFO:Creating metrics dataframe
2025-04-06 21:22:23,524:INFO:Initializing Elastic Net
2025-04-06 21:22:23,524:INFO:Total runtime is 0.26906989018122357 minutes
2025-04-06 21:22:23,524:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:23,524:INFO:Initializing create_model()
2025-04-06 21:22:23,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:23,524:INFO:Checking exceptions
2025-04-06 21:22:23,524:INFO:Importing libraries
2025-04-06 21:22:23,524:INFO:Copying training dataset
2025-04-06 21:22:23,529:INFO:Defining folds
2025-04-06 21:22:23,530:INFO:Declaring metric variables
2025-04-06 21:22:23,530:INFO:Importing untrained model
2025-04-06 21:22:23,530:INFO:Elastic Net Imported successfully
2025-04-06 21:22:23,530:INFO:Starting cross validation
2025-04-06 21:22:23,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:23,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+14, tolerance: 5.322e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+14, tolerance: 6.350e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+14, tolerance: 6.616e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,800:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+14, tolerance: 7.010e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,814:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+14, tolerance: 7.104e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,844:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+14, tolerance: 6.987e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,865:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+14, tolerance: 7.562e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,885:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+14, tolerance: 7.503e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,893:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+14, tolerance: 6.975e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+14, tolerance: 7.344e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:22:23,955:INFO:Calculating mean and std
2025-04-06 21:22:23,956:INFO:Creating metrics dataframe
2025-04-06 21:22:23,958:INFO:Uploading results into container
2025-04-06 21:22:23,958:INFO:Uploading model into container now
2025-04-06 21:22:23,959:INFO:_master_model_container: 4
2025-04-06 21:22:23,959:INFO:_display_container: 2
2025-04-06 21:22:23,959:INFO:ElasticNet(random_state=123)
2025-04-06 21:22:23,959:INFO:create_model() successfully completed......................................
2025-04-06 21:22:24,147:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:24,147:INFO:Creating metrics dataframe
2025-04-06 21:22:24,151:INFO:Initializing Least Angle Regression
2025-04-06 21:22:24,151:INFO:Total runtime is 0.2795220613479614 minutes
2025-04-06 21:22:24,152:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:24,152:INFO:Initializing create_model()
2025-04-06 21:22:24,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:24,152:INFO:Checking exceptions
2025-04-06 21:22:24,152:INFO:Importing libraries
2025-04-06 21:22:24,152:INFO:Copying training dataset
2025-04-06 21:22:24,157:INFO:Defining folds
2025-04-06 21:22:24,157:INFO:Declaring metric variables
2025-04-06 21:22:24,158:INFO:Importing untrained model
2025-04-06 21:22:24,158:INFO:Least Angle Regression Imported successfully
2025-04-06 21:22:24,158:INFO:Starting cross validation
2025-04-06 21:22:24,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:24,387:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.209e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,388:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.954e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.518e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.915e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,390:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.412e+04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,392:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.345e+04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.031e+03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.516e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.529e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,401:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.063e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,402:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.138e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.024e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.512e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.274e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,406:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.748e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,406:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.923e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,408:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.829e+05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,408:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.328e+04, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,409:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.336e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,409:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.093e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.383e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.191e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.373e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.396e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.381e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,423:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=8.451e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,450:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.167e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,450:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.078e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,451:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.191e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,451:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.904e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,453:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.981e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,454:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.811e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,454:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.213e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,456:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.387e+07, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,456:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.439e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.217e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,469:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.866e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.441e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.023e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.996e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.192e+05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.800e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,473:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.419e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.438e+04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.480e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.367e+11, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,474:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.952e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.338e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,475:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.169e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,476:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.474e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,476:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.439e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,478:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.536e+03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,479:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.357e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,512:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.804e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.168e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.395e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,513:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.403e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,515:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.938e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,516:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.290e+03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,516:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.682e+06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,517:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.054e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,536:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.945e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,536:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.248e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.254e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.761e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,537:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.338e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.316e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.209e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,538:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.687e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.179e+09, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.281e+04, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.091e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.990e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,539:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=6.671e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.006e+05, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.207e+04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,540:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.552e+04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,541:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.919e+04, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,541:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.775e+03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:24,591:INFO:Calculating mean and std
2025-04-06 21:22:24,592:INFO:Creating metrics dataframe
2025-04-06 21:22:24,594:INFO:Uploading results into container
2025-04-06 21:22:24,594:INFO:Uploading model into container now
2025-04-06 21:22:24,594:INFO:_master_model_container: 5
2025-04-06 21:22:24,595:INFO:_display_container: 2
2025-04-06 21:22:24,595:INFO:Lars(random_state=123)
2025-04-06 21:22:24,595:INFO:create_model() successfully completed......................................
2025-04-06 21:22:24,778:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:24,778:INFO:Creating metrics dataframe
2025-04-06 21:22:24,780:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:22:24,780:INFO:Total runtime is 0.2900100549062093 minutes
2025-04-06 21:22:24,780:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:24,781:INFO:Initializing create_model()
2025-04-06 21:22:24,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:24,781:INFO:Checking exceptions
2025-04-06 21:22:24,781:INFO:Importing libraries
2025-04-06 21:22:24,781:INFO:Copying training dataset
2025-04-06 21:22:24,787:INFO:Defining folds
2025-04-06 21:22:24,787:INFO:Declaring metric variables
2025-04-06 21:22:24,787:INFO:Importing untrained model
2025-04-06 21:22:24,788:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:22:24,788:INFO:Starting cross validation
2025-04-06 21:22:24,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:25,056:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.454e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,057:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.734e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,058:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.050e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,059:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.866e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,060:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=4.259e+03, previous alpha=8.300e+02, with an active set of 19 regressors.
  warnings.warn(

2025-04-06 21:22:25,091:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.480e+11, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,092:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.398e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,092:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.396e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,093:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.699e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,093:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=8.792e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.521e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.757e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,094:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.224e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,095:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.951e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,096:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.243e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,096:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.471e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.240e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.189e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,097:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=4.261e+02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,099:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=2.272e+04, previous alpha=9.279e+01, with an active set of 20 regressors.
  warnings.warn(

2025-04-06 21:22:25,127:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.096e+05, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,127:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.492e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,128:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=8.906e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,130:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=7.119e+03, previous alpha=7.107e+02, with an active set of 18 regressors.
  warnings.warn(

2025-04-06 21:22:25,157:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.074e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,158:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.716e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,159:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.042e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,159:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.415e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,160:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.717e+08, previous alpha=1.023e+04, with an active set of 13 regressors.
  warnings.warn(

2025-04-06 21:22:25,165:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.294e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,166:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.032e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.018e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.436e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,167:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.976e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,168:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.069e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,169:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.908e+03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:22:25,169:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=2.907e+03, previous alpha=1.060e+03, with an active set of 17 regressors.
  warnings.warn(

2025-04-06 21:22:25,215:INFO:Calculating mean and std
2025-04-06 21:22:25,216:INFO:Creating metrics dataframe
2025-04-06 21:22:25,218:INFO:Uploading results into container
2025-04-06 21:22:25,218:INFO:Uploading model into container now
2025-04-06 21:22:25,219:INFO:_master_model_container: 6
2025-04-06 21:22:25,219:INFO:_display_container: 2
2025-04-06 21:22:25,219:INFO:LassoLars(random_state=123)
2025-04-06 21:22:25,219:INFO:create_model() successfully completed......................................
2025-04-06 21:22:25,406:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:25,406:INFO:Creating metrics dataframe
2025-04-06 21:22:25,408:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:22:25,408:INFO:Total runtime is 0.30046358505884807 minutes
2025-04-06 21:22:25,408:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:25,408:INFO:Initializing create_model()
2025-04-06 21:22:25,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:25,409:INFO:Checking exceptions
2025-04-06 21:22:25,409:INFO:Importing libraries
2025-04-06 21:22:25,409:INFO:Copying training dataset
2025-04-06 21:22:25,413:INFO:Defining folds
2025-04-06 21:22:25,413:INFO:Declaring metric variables
2025-04-06 21:22:25,413:INFO:Importing untrained model
2025-04-06 21:22:25,414:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:22:25,414:INFO:Starting cross validation
2025-04-06 21:22:25,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:25,817:INFO:Calculating mean and std
2025-04-06 21:22:25,818:INFO:Creating metrics dataframe
2025-04-06 21:22:25,820:INFO:Uploading results into container
2025-04-06 21:22:25,821:INFO:Uploading model into container now
2025-04-06 21:22:25,821:INFO:_master_model_container: 7
2025-04-06 21:22:25,821:INFO:_display_container: 2
2025-04-06 21:22:25,821:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:22:25,821:INFO:create_model() successfully completed......................................
2025-04-06 21:22:26,011:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:26,011:INFO:Creating metrics dataframe
2025-04-06 21:22:26,013:INFO:Initializing Bayesian Ridge
2025-04-06 21:22:26,013:INFO:Total runtime is 0.31055250962575276 minutes
2025-04-06 21:22:26,013:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:26,014:INFO:Initializing create_model()
2025-04-06 21:22:26,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:26,014:INFO:Checking exceptions
2025-04-06 21:22:26,014:INFO:Importing libraries
2025-04-06 21:22:26,014:INFO:Copying training dataset
2025-04-06 21:22:26,018:INFO:Defining folds
2025-04-06 21:22:26,018:INFO:Declaring metric variables
2025-04-06 21:22:26,019:INFO:Importing untrained model
2025-04-06 21:22:26,019:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:22:26,019:INFO:Starting cross validation
2025-04-06 21:22:26,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:26,413:INFO:Calculating mean and std
2025-04-06 21:22:26,414:INFO:Creating metrics dataframe
2025-04-06 21:22:26,415:INFO:Uploading results into container
2025-04-06 21:22:26,416:INFO:Uploading model into container now
2025-04-06 21:22:26,416:INFO:_master_model_container: 8
2025-04-06 21:22:26,416:INFO:_display_container: 2
2025-04-06 21:22:26,416:INFO:BayesianRidge()
2025-04-06 21:22:26,416:INFO:create_model() successfully completed......................................
2025-04-06 21:22:26,601:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:26,601:INFO:Creating metrics dataframe
2025-04-06 21:22:26,603:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:22:26,604:INFO:Total runtime is 0.3203834096590678 minutes
2025-04-06 21:22:26,604:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:26,604:INFO:Initializing create_model()
2025-04-06 21:22:26,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:26,604:INFO:Checking exceptions
2025-04-06 21:22:26,604:INFO:Importing libraries
2025-04-06 21:22:26,604:INFO:Copying training dataset
2025-04-06 21:22:26,609:INFO:Defining folds
2025-04-06 21:22:26,609:INFO:Declaring metric variables
2025-04-06 21:22:26,609:INFO:Importing untrained model
2025-04-06 21:22:26,609:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:22:26,609:INFO:Starting cross validation
2025-04-06 21:22:26,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:27,016:INFO:Calculating mean and std
2025-04-06 21:22:27,017:INFO:Creating metrics dataframe
2025-04-06 21:22:27,018:INFO:Uploading results into container
2025-04-06 21:22:27,019:INFO:Uploading model into container now
2025-04-06 21:22:27,019:INFO:_master_model_container: 9
2025-04-06 21:22:27,019:INFO:_display_container: 2
2025-04-06 21:22:27,019:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:22:27,019:INFO:create_model() successfully completed......................................
2025-04-06 21:22:27,211:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:27,212:INFO:Creating metrics dataframe
2025-04-06 21:22:27,214:INFO:Initializing Huber Regressor
2025-04-06 21:22:27,214:INFO:Total runtime is 0.33057785828908287 minutes
2025-04-06 21:22:27,214:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:27,214:INFO:Initializing create_model()
2025-04-06 21:22:27,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:27,215:INFO:Checking exceptions
2025-04-06 21:22:27,215:INFO:Importing libraries
2025-04-06 21:22:27,215:INFO:Copying training dataset
2025-04-06 21:22:27,221:INFO:Defining folds
2025-04-06 21:22:27,221:INFO:Declaring metric variables
2025-04-06 21:22:27,221:INFO:Importing untrained model
2025-04-06 21:22:27,221:INFO:Huber Regressor Imported successfully
2025-04-06 21:22:27,221:INFO:Starting cross validation
2025-04-06 21:22:27,223:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:27,507:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:22:27,544:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:22:27,678:INFO:Calculating mean and std
2025-04-06 21:22:27,679:INFO:Creating metrics dataframe
2025-04-06 21:22:27,680:INFO:Uploading results into container
2025-04-06 21:22:27,681:INFO:Uploading model into container now
2025-04-06 21:22:27,682:INFO:_master_model_container: 10
2025-04-06 21:22:27,682:INFO:_display_container: 2
2025-04-06 21:22:27,682:INFO:HuberRegressor()
2025-04-06 21:22:27,682:INFO:create_model() successfully completed......................................
2025-04-06 21:22:27,868:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:27,868:INFO:Creating metrics dataframe
2025-04-06 21:22:27,870:INFO:Initializing K Neighbors Regressor
2025-04-06 21:22:27,871:INFO:Total runtime is 0.3415256222089132 minutes
2025-04-06 21:22:27,871:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:27,871:INFO:Initializing create_model()
2025-04-06 21:22:27,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:27,871:INFO:Checking exceptions
2025-04-06 21:22:27,871:INFO:Importing libraries
2025-04-06 21:22:27,871:INFO:Copying training dataset
2025-04-06 21:22:27,877:INFO:Defining folds
2025-04-06 21:22:27,877:INFO:Declaring metric variables
2025-04-06 21:22:27,878:INFO:Importing untrained model
2025-04-06 21:22:27,878:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:22:27,878:INFO:Starting cross validation
2025-04-06 21:22:27,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:28,286:INFO:Calculating mean and std
2025-04-06 21:22:28,287:INFO:Creating metrics dataframe
2025-04-06 21:22:28,288:INFO:Uploading results into container
2025-04-06 21:22:28,289:INFO:Uploading model into container now
2025-04-06 21:22:28,289:INFO:_master_model_container: 11
2025-04-06 21:22:28,289:INFO:_display_container: 2
2025-04-06 21:22:28,289:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:22:28,289:INFO:create_model() successfully completed......................................
2025-04-06 21:22:28,476:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:28,476:INFO:Creating metrics dataframe
2025-04-06 21:22:28,478:INFO:Initializing Decision Tree Regressor
2025-04-06 21:22:28,478:INFO:Total runtime is 0.3516429424285889 minutes
2025-04-06 21:22:28,478:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:28,479:INFO:Initializing create_model()
2025-04-06 21:22:28,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:28,479:INFO:Checking exceptions
2025-04-06 21:22:28,479:INFO:Importing libraries
2025-04-06 21:22:28,479:INFO:Copying training dataset
2025-04-06 21:22:28,484:INFO:Defining folds
2025-04-06 21:22:28,484:INFO:Declaring metric variables
2025-04-06 21:22:28,485:INFO:Importing untrained model
2025-04-06 21:22:28,485:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:22:28,485:INFO:Starting cross validation
2025-04-06 21:22:28,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:28,883:INFO:Calculating mean and std
2025-04-06 21:22:28,884:INFO:Creating metrics dataframe
2025-04-06 21:22:28,885:INFO:Uploading results into container
2025-04-06 21:22:28,886:INFO:Uploading model into container now
2025-04-06 21:22:28,886:INFO:_master_model_container: 12
2025-04-06 21:22:28,886:INFO:_display_container: 2
2025-04-06 21:22:28,886:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:22:28,886:INFO:create_model() successfully completed......................................
2025-04-06 21:22:29,058:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:29,059:INFO:Creating metrics dataframe
2025-04-06 21:22:29,061:INFO:Initializing Random Forest Regressor
2025-04-06 21:22:29,061:INFO:Total runtime is 0.3613513032595317 minutes
2025-04-06 21:22:29,061:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:29,061:INFO:Initializing create_model()
2025-04-06 21:22:29,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:29,061:INFO:Checking exceptions
2025-04-06 21:22:29,061:INFO:Importing libraries
2025-04-06 21:22:29,062:INFO:Copying training dataset
2025-04-06 21:22:29,066:INFO:Defining folds
2025-04-06 21:22:29,066:INFO:Declaring metric variables
2025-04-06 21:22:29,066:INFO:Importing untrained model
2025-04-06 21:22:29,067:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:22:29,067:INFO:Starting cross validation
2025-04-06 21:22:29,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:30,841:INFO:Calculating mean and std
2025-04-06 21:22:30,842:INFO:Creating metrics dataframe
2025-04-06 21:22:30,843:INFO:Uploading results into container
2025-04-06 21:22:30,844:INFO:Uploading model into container now
2025-04-06 21:22:30,844:INFO:_master_model_container: 13
2025-04-06 21:22:30,844:INFO:_display_container: 2
2025-04-06 21:22:30,844:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:30,845:INFO:create_model() successfully completed......................................
2025-04-06 21:22:31,033:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:31,033:INFO:Creating metrics dataframe
2025-04-06 21:22:31,035:INFO:Initializing Extra Trees Regressor
2025-04-06 21:22:31,036:INFO:Total runtime is 0.3942694902420044 minutes
2025-04-06 21:22:31,036:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:31,036:INFO:Initializing create_model()
2025-04-06 21:22:31,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:31,036:INFO:Checking exceptions
2025-04-06 21:22:31,036:INFO:Importing libraries
2025-04-06 21:22:31,036:INFO:Copying training dataset
2025-04-06 21:22:31,041:INFO:Defining folds
2025-04-06 21:22:31,041:INFO:Declaring metric variables
2025-04-06 21:22:31,041:INFO:Importing untrained model
2025-04-06 21:22:31,042:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:22:31,042:INFO:Starting cross validation
2025-04-06 21:22:31,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:32,163:INFO:Calculating mean and std
2025-04-06 21:22:32,164:INFO:Creating metrics dataframe
2025-04-06 21:22:32,165:INFO:Uploading results into container
2025-04-06 21:22:32,166:INFO:Uploading model into container now
2025-04-06 21:22:32,166:INFO:_master_model_container: 14
2025-04-06 21:22:32,166:INFO:_display_container: 2
2025-04-06 21:22:32,166:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:32,166:INFO:create_model() successfully completed......................................
2025-04-06 21:22:32,345:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:32,345:INFO:Creating metrics dataframe
2025-04-06 21:22:32,347:INFO:Initializing AdaBoost Regressor
2025-04-06 21:22:32,347:INFO:Total runtime is 0.41611528396606445 minutes
2025-04-06 21:22:32,348:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:32,348:INFO:Initializing create_model()
2025-04-06 21:22:32,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:32,348:INFO:Checking exceptions
2025-04-06 21:22:32,348:INFO:Importing libraries
2025-04-06 21:22:32,348:INFO:Copying training dataset
2025-04-06 21:22:32,353:INFO:Defining folds
2025-04-06 21:22:32,353:INFO:Declaring metric variables
2025-04-06 21:22:32,353:INFO:Importing untrained model
2025-04-06 21:22:32,353:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:22:32,354:INFO:Starting cross validation
2025-04-06 21:22:32,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:32,918:INFO:Calculating mean and std
2025-04-06 21:22:32,919:INFO:Creating metrics dataframe
2025-04-06 21:22:32,920:INFO:Uploading results into container
2025-04-06 21:22:32,921:INFO:Uploading model into container now
2025-04-06 21:22:32,921:INFO:_master_model_container: 15
2025-04-06 21:22:32,921:INFO:_display_container: 2
2025-04-06 21:22:32,921:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:22:32,921:INFO:create_model() successfully completed......................................
2025-04-06 21:22:33,105:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:33,105:INFO:Creating metrics dataframe
2025-04-06 21:22:33,107:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:22:33,107:INFO:Total runtime is 0.42878547112147014 minutes
2025-04-06 21:22:33,107:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:33,107:INFO:Initializing create_model()
2025-04-06 21:22:33,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:33,107:INFO:Checking exceptions
2025-04-06 21:22:33,107:INFO:Importing libraries
2025-04-06 21:22:33,107:INFO:Copying training dataset
2025-04-06 21:22:33,112:INFO:Defining folds
2025-04-06 21:22:33,112:INFO:Declaring metric variables
2025-04-06 21:22:33,112:INFO:Importing untrained model
2025-04-06 21:22:33,113:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:22:33,113:INFO:Starting cross validation
2025-04-06 21:22:33,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:33,962:INFO:Calculating mean and std
2025-04-06 21:22:33,962:INFO:Creating metrics dataframe
2025-04-06 21:22:33,964:INFO:Uploading results into container
2025-04-06 21:22:33,964:INFO:Uploading model into container now
2025-04-06 21:22:33,965:INFO:_master_model_container: 16
2025-04-06 21:22:33,965:INFO:_display_container: 2
2025-04-06 21:22:33,965:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:22:33,965:INFO:create_model() successfully completed......................................
2025-04-06 21:22:34,138:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:34,138:INFO:Creating metrics dataframe
2025-04-06 21:22:34,141:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:22:34,141:INFO:Total runtime is 0.44601293007532755 minutes
2025-04-06 21:22:34,141:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:34,141:INFO:Initializing create_model()
2025-04-06 21:22:34,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:34,141:INFO:Checking exceptions
2025-04-06 21:22:34,141:INFO:Importing libraries
2025-04-06 21:22:34,141:INFO:Copying training dataset
2025-04-06 21:22:34,146:INFO:Defining folds
2025-04-06 21:22:34,146:INFO:Declaring metric variables
2025-04-06 21:22:34,146:INFO:Importing untrained model
2025-04-06 21:22:34,147:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:22:34,147:INFO:Starting cross validation
2025-04-06 21:22:34,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:35,632:INFO:Calculating mean and std
2025-04-06 21:22:35,633:INFO:Creating metrics dataframe
2025-04-06 21:22:35,635:INFO:Uploading results into container
2025-04-06 21:22:35,636:INFO:Uploading model into container now
2025-04-06 21:22:35,636:INFO:_master_model_container: 17
2025-04-06 21:22:35,636:INFO:_display_container: 2
2025-04-06 21:22:35,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:22:35,637:INFO:create_model() successfully completed......................................
2025-04-06 21:22:35,833:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:35,833:INFO:Creating metrics dataframe
2025-04-06 21:22:35,835:INFO:Initializing CatBoost Regressor
2025-04-06 21:22:35,836:INFO:Total runtime is 0.47426937023798627 minutes
2025-04-06 21:22:35,836:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:35,836:INFO:Initializing create_model()
2025-04-06 21:22:35,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:35,836:INFO:Checking exceptions
2025-04-06 21:22:35,836:INFO:Importing libraries
2025-04-06 21:22:35,836:INFO:Copying training dataset
2025-04-06 21:22:35,841:INFO:Defining folds
2025-04-06 21:22:35,841:INFO:Declaring metric variables
2025-04-06 21:22:35,841:INFO:Importing untrained model
2025-04-06 21:22:35,845:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:22:35,845:INFO:Starting cross validation
2025-04-06 21:22:35,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:44,806:INFO:Calculating mean and std
2025-04-06 21:22:44,807:INFO:Creating metrics dataframe
2025-04-06 21:22:44,810:INFO:Uploading results into container
2025-04-06 21:22:44,811:INFO:Uploading model into container now
2025-04-06 21:22:44,811:INFO:_master_model_container: 18
2025-04-06 21:22:44,811:INFO:_display_container: 2
2025-04-06 21:22:44,811:INFO:<catboost.core.CatBoostRegressor object at 0x0000029EA7C20250>
2025-04-06 21:22:44,811:INFO:create_model() successfully completed......................................
2025-04-06 21:22:45,015:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:45,015:INFO:Creating metrics dataframe
2025-04-06 21:22:45,017:INFO:Initializing Dummy Regressor
2025-04-06 21:22:45,017:INFO:Total runtime is 0.627294369538625 minutes
2025-04-06 21:22:45,017:INFO:SubProcess create_model() called ==================================
2025-04-06 21:22:45,017:INFO:Initializing create_model()
2025-04-06 21:22:45,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A1F4A70050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:45,018:INFO:Checking exceptions
2025-04-06 21:22:45,018:INFO:Importing libraries
2025-04-06 21:22:45,018:INFO:Copying training dataset
2025-04-06 21:22:45,025:INFO:Defining folds
2025-04-06 21:22:45,025:INFO:Declaring metric variables
2025-04-06 21:22:45,025:INFO:Importing untrained model
2025-04-06 21:22:45,025:INFO:Dummy Regressor Imported successfully
2025-04-06 21:22:45,026:INFO:Starting cross validation
2025-04-06 21:22:45,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:22:45,446:INFO:Calculating mean and std
2025-04-06 21:22:45,446:INFO:Creating metrics dataframe
2025-04-06 21:22:45,448:INFO:Uploading results into container
2025-04-06 21:22:45,448:INFO:Uploading model into container now
2025-04-06 21:22:45,449:INFO:_master_model_container: 19
2025-04-06 21:22:45,449:INFO:_display_container: 2
2025-04-06 21:22:45,449:INFO:DummyRegressor()
2025-04-06 21:22:45,449:INFO:create_model() successfully completed......................................
2025-04-06 21:22:45,639:INFO:SubProcess create_model() end ==================================
2025-04-06 21:22:45,639:INFO:Creating metrics dataframe
2025-04-06 21:22:45,642:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:22:45,644:INFO:Initializing create_model()
2025-04-06 21:22:45,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002A1F4DAA690>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:22:45,644:INFO:Checking exceptions
2025-04-06 21:22:45,644:INFO:Importing libraries
2025-04-06 21:22:45,644:INFO:Copying training dataset
2025-04-06 21:22:45,650:INFO:Defining folds
2025-04-06 21:22:45,650:INFO:Declaring metric variables
2025-04-06 21:22:45,650:INFO:Importing untrained model
2025-04-06 21:22:45,650:INFO:Declaring custom model
2025-04-06 21:22:45,650:INFO:Huber Regressor Imported successfully
2025-04-06 21:22:45,652:INFO:Cross validation set to False
2025-04-06 21:22:45,652:INFO:Fitting Model
2025-04-06 21:22:45,836:INFO:HuberRegressor()
2025-04-06 21:22:45,836:INFO:create_model() successfully completed......................................
2025-04-06 21:22:46,008:INFO:_master_model_container: 19
2025-04-06 21:22:46,008:INFO:_display_container: 2
2025-04-06 21:22:46,008:INFO:HuberRegressor()
2025-04-06 21:22:46,008:INFO:compare_models() successfully completed......................................
2025-04-06 21:51:31,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:51:31,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:52:02,009:INFO:PyCaret RegressionExperiment
2025-04-06 21:52:02,009:INFO:Logging name: reg-default-name
2025-04-06 21:52:02,009:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:52:02,010:INFO:version 3.3.2
2025-04-06 21:52:02,010:INFO:Initializing setup()
2025-04-06 21:52:02,010:INFO:self.USI: 335a
2025-04-06 21:52:02,010:INFO:self._variable_keys: {'X_train', 'USI', 'exp_id', 'n_jobs_param', 'target_param', 'y_train', 'exp_name_log', 'gpu_param', 'data', 'html_param', 'logging_param', '_available_plots', 'X', 'log_plots_param', 'fold_shuffle_param', 'transform_target_param', 'y', 'X_test', 'fold_groups_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'seed', '_ml_usecase', 'pipeline', 'idx', 'memory'}
2025-04-06 21:52:02,010:INFO:Checking environment
2025-04-06 21:52:02,010:INFO:python_version: 3.11.4
2025-04-06 21:52:02,010:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:52:02,010:INFO:machine: AMD64
2025-04-06 21:52:02,035:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:52:02,040:INFO:Memory: svmem(total=17127211008, available=5105315840, percent=70.2, used=12021895168, free=5105315840)
2025-04-06 21:52:02,040:INFO:Physical Core: 6
2025-04-06 21:52:02,040:INFO:Logical Core: 12
2025-04-06 21:52:02,040:INFO:Checking libraries
2025-04-06 21:52:02,040:INFO:System:
2025-04-06 21:52:02,040:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:52:02,040:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:52:02,040:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:52:02,040:INFO:PyCaret required dependencies:
2025-04-06 21:52:02,774:INFO:                 pip: 25.0.1
2025-04-06 21:52:02,774:INFO:          setuptools: 65.5.0
2025-04-06 21:52:02,774:INFO:             pycaret: 3.3.2
2025-04-06 21:52:02,775:INFO:             IPython: 8.12.3
2025-04-06 21:52:02,775:INFO:          ipywidgets: 8.1.5
2025-04-06 21:52:02,775:INFO:                tqdm: 4.67.1
2025-04-06 21:52:02,775:INFO:               numpy: 1.26.4
2025-04-06 21:52:02,775:INFO:              pandas: 2.1.4
2025-04-06 21:52:02,775:INFO:              jinja2: 3.1.2
2025-04-06 21:52:02,775:INFO:               scipy: 1.11.4
2025-04-06 21:52:02,775:INFO:              joblib: 1.3.2
2025-04-06 21:52:02,775:INFO:             sklearn: 1.4.2
2025-04-06 21:52:02,775:INFO:                pyod: 2.0.3
2025-04-06 21:52:02,775:INFO:            imblearn: 0.13.0
2025-04-06 21:52:02,775:INFO:   category_encoders: 2.7.0
2025-04-06 21:52:02,775:INFO:            lightgbm: 4.6.0
2025-04-06 21:52:02,775:INFO:               numba: 0.61.0
2025-04-06 21:52:02,775:INFO:            requests: 2.32.3
2025-04-06 21:52:02,775:INFO:          matplotlib: 3.7.5
2025-04-06 21:52:02,775:INFO:          scikitplot: 0.3.7
2025-04-06 21:52:02,775:INFO:         yellowbrick: 1.5
2025-04-06 21:52:02,775:INFO:              plotly: 5.24.1
2025-04-06 21:52:02,776:INFO:    plotly-resampler: Not installed
2025-04-06 21:52:02,776:INFO:             kaleido: 0.2.1
2025-04-06 21:52:02,776:INFO:           schemdraw: 0.15
2025-04-06 21:52:02,776:INFO:         statsmodels: 0.14.4
2025-04-06 21:52:02,776:INFO:              sktime: 0.26.0
2025-04-06 21:52:02,776:INFO:               tbats: 1.1.3
2025-04-06 21:52:02,776:INFO:            pmdarima: 2.0.4
2025-04-06 21:52:02,776:INFO:              psutil: 7.0.0
2025-04-06 21:52:02,776:INFO:          markupsafe: 2.1.3
2025-04-06 21:52:02,776:INFO:             pickle5: Not installed
2025-04-06 21:52:02,776:INFO:         cloudpickle: 3.1.1
2025-04-06 21:52:02,776:INFO:         deprecation: 2.1.0
2025-04-06 21:52:02,776:INFO:              xxhash: 3.5.0
2025-04-06 21:52:02,776:INFO:           wurlitzer: Not installed
2025-04-06 21:52:02,776:INFO:PyCaret optional dependencies:
2025-04-06 21:52:05,798:INFO:                shap: 0.44.1
2025-04-06 21:52:05,799:INFO:           interpret: 0.6.9
2025-04-06 21:52:05,799:INFO:                umap: 0.5.7
2025-04-06 21:52:05,799:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:52:05,799:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:52:05,799:INFO:             autoviz: Not installed
2025-04-06 21:52:05,799:INFO:           fairlearn: 0.7.0
2025-04-06 21:52:05,799:INFO:          deepchecks: Not installed
2025-04-06 21:52:05,799:INFO:             xgboost: Not installed
2025-04-06 21:52:05,799:INFO:            catboost: 1.2.7
2025-04-06 21:52:05,799:INFO:              kmodes: 0.12.2
2025-04-06 21:52:05,799:INFO:             mlxtend: 0.23.4
2025-04-06 21:52:05,799:INFO:       statsforecast: 1.5.0
2025-04-06 21:52:05,799:INFO:        tune_sklearn: Not installed
2025-04-06 21:52:05,799:INFO:                 ray: Not installed
2025-04-06 21:52:05,799:INFO:            hyperopt: 0.2.7
2025-04-06 21:52:05,799:INFO:              optuna: 4.2.1
2025-04-06 21:52:05,799:INFO:               skopt: 0.10.2
2025-04-06 21:52:05,799:INFO:              mlflow: 2.21.0
2025-04-06 21:52:05,800:INFO:              gradio: 5.21.0
2025-04-06 21:52:05,800:INFO:             fastapi: 0.115.11
2025-04-06 21:52:05,800:INFO:             uvicorn: 0.34.0
2025-04-06 21:52:05,800:INFO:              m2cgen: 0.10.0
2025-04-06 21:52:05,800:INFO:           evidently: 0.4.40
2025-04-06 21:52:05,800:INFO:               fugue: 0.8.7
2025-04-06 21:52:05,800:INFO:           streamlit: 1.42.2
2025-04-06 21:52:05,800:INFO:             prophet: Not installed
2025-04-06 21:52:05,800:INFO:None
2025-04-06 21:52:05,800:INFO:Set up data.
2025-04-06 21:52:05,811:INFO:Set up folding strategy.
2025-04-06 21:52:05,811:INFO:Set up train/test split.
2025-04-06 21:52:05,819:INFO:Set up index.
2025-04-06 21:52:05,820:INFO:Assigning column types.
2025-04-06 21:52:05,824:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:52:05,824:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,830:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:05,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:05,973:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,005:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,011:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,017:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,151:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,152:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:52:06,158:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,299:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,305:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,312:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,445:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,445:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:52:06,457:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,592:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,593:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,738:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,738:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:52:06,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:06,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:06,883:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:06,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,034:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:52:07,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,185:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:52:07,332:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,333:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,333:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:52:07,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,481:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:07,634:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:07,636:INFO:Preparing preprocessing pipeline...
2025-04-06 21:52:07,636:INFO:Set up simple imputation.
2025-04-06 21:52:07,639:INFO:Set up encoding of categorical features.
2025-04-06 21:52:07,861:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:52:07,873:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:52:07,873:INFO:Creating final display dataframe.
2025-04-06 21:52:08,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1000, 16)
4        Transformed data shape        (1000, 20)
5   Transformed train set shape         (700, 20)
6    Transformed test set shape         (300, 20)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              2.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              335a
2025-04-06 21:52:08,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:08,690:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:08,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:52:08,837:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:52:08,838:INFO:setup() successfully completed in 6.84s...............
2025-04-06 21:52:08,838:INFO:Initializing compare_models()
2025-04-06 21:52:08,839:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:52:08,839:INFO:Checking exceptions
2025-04-06 21:52:08,841:INFO:Preparing display monitor
2025-04-06 21:52:08,844:INFO:Initializing Linear Regression
2025-04-06 21:52:08,844:INFO:Total runtime is 0.0 minutes
2025-04-06 21:52:08,844:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:08,844:INFO:Initializing create_model()
2025-04-06 21:52:08,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:08,844:INFO:Checking exceptions
2025-04-06 21:52:08,844:INFO:Importing libraries
2025-04-06 21:52:08,844:INFO:Copying training dataset
2025-04-06 21:52:08,848:INFO:Defining folds
2025-04-06 21:52:08,848:INFO:Declaring metric variables
2025-04-06 21:52:08,848:INFO:Importing untrained model
2025-04-06 21:52:08,850:INFO:Linear Regression Imported successfully
2025-04-06 21:52:08,850:INFO:Starting cross validation
2025-04-06 21:52:08,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:17,348:INFO:Calculating mean and std
2025-04-06 21:52:17,349:INFO:Creating metrics dataframe
2025-04-06 21:52:17,351:INFO:Uploading results into container
2025-04-06 21:52:17,351:INFO:Uploading model into container now
2025-04-06 21:52:17,351:INFO:_master_model_container: 1
2025-04-06 21:52:17,352:INFO:_display_container: 2
2025-04-06 21:52:17,352:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:52:17,352:INFO:create_model() successfully completed......................................
2025-04-06 21:52:17,529:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:17,529:INFO:Creating metrics dataframe
2025-04-06 21:52:17,531:INFO:Initializing Lasso Regression
2025-04-06 21:52:17,531:INFO:Total runtime is 0.14478984276453655 minutes
2025-04-06 21:52:17,531:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:17,531:INFO:Initializing create_model()
2025-04-06 21:52:17,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:17,531:INFO:Checking exceptions
2025-04-06 21:52:17,531:INFO:Importing libraries
2025-04-06 21:52:17,531:INFO:Copying training dataset
2025-04-06 21:52:17,536:INFO:Defining folds
2025-04-06 21:52:17,536:INFO:Declaring metric variables
2025-04-06 21:52:17,537:INFO:Importing untrained model
2025-04-06 21:52:17,537:INFO:Lasso Regression Imported successfully
2025-04-06 21:52:17,537:INFO:Starting cross validation
2025-04-06 21:52:17,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:17,746:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,762:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,796:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,805:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,809:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:17,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,032:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,035:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,073:INFO:Calculating mean and std
2025-04-06 21:52:22,074:INFO:Creating metrics dataframe
2025-04-06 21:52:22,076:INFO:Uploading results into container
2025-04-06 21:52:22,076:INFO:Uploading model into container now
2025-04-06 21:52:22,077:INFO:_master_model_container: 2
2025-04-06 21:52:22,077:INFO:_display_container: 2
2025-04-06 21:52:22,077:INFO:Lasso(random_state=123)
2025-04-06 21:52:22,077:INFO:create_model() successfully completed......................................
2025-04-06 21:52:22,234:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:22,235:INFO:Creating metrics dataframe
2025-04-06 21:52:22,237:INFO:Initializing Ridge Regression
2025-04-06 21:52:22,237:INFO:Total runtime is 0.2232274572054545 minutes
2025-04-06 21:52:22,237:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:22,238:INFO:Initializing create_model()
2025-04-06 21:52:22,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:22,238:INFO:Checking exceptions
2025-04-06 21:52:22,238:INFO:Importing libraries
2025-04-06 21:52:22,238:INFO:Copying training dataset
2025-04-06 21:52:22,243:INFO:Defining folds
2025-04-06 21:52:22,243:INFO:Declaring metric variables
2025-04-06 21:52:22,243:INFO:Importing untrained model
2025-04-06 21:52:22,243:INFO:Ridge Regression Imported successfully
2025-04-06 21:52:22,244:INFO:Starting cross validation
2025-04-06 21:52:22,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:22,546:INFO:Calculating mean and std
2025-04-06 21:52:22,547:INFO:Creating metrics dataframe
2025-04-06 21:52:22,549:INFO:Uploading results into container
2025-04-06 21:52:22,549:INFO:Uploading model into container now
2025-04-06 21:52:22,549:INFO:_master_model_container: 3
2025-04-06 21:52:22,549:INFO:_display_container: 2
2025-04-06 21:52:22,550:INFO:Ridge(random_state=123)
2025-04-06 21:52:22,550:INFO:create_model() successfully completed......................................
2025-04-06 21:52:22,692:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:22,693:INFO:Creating metrics dataframe
2025-04-06 21:52:22,695:INFO:Initializing Elastic Net
2025-04-06 21:52:22,695:INFO:Total runtime is 0.23084967533747355 minutes
2025-04-06 21:52:22,696:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:22,696:INFO:Initializing create_model()
2025-04-06 21:52:22,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:22,696:INFO:Checking exceptions
2025-04-06 21:52:22,696:INFO:Importing libraries
2025-04-06 21:52:22,696:INFO:Copying training dataset
2025-04-06 21:52:22,701:INFO:Defining folds
2025-04-06 21:52:22,701:INFO:Declaring metric variables
2025-04-06 21:52:22,701:INFO:Importing untrained model
2025-04-06 21:52:22,701:INFO:Elastic Net Imported successfully
2025-04-06 21:52:22,701:INFO:Starting cross validation
2025-04-06 21:52:22,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:22,858:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,883:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,886:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,933:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,941:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,953:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,969:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:22,978:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:52:23,022:INFO:Calculating mean and std
2025-04-06 21:52:23,022:INFO:Creating metrics dataframe
2025-04-06 21:52:23,024:INFO:Uploading results into container
2025-04-06 21:52:23,024:INFO:Uploading model into container now
2025-04-06 21:52:23,025:INFO:_master_model_container: 4
2025-04-06 21:52:23,025:INFO:_display_container: 2
2025-04-06 21:52:23,025:INFO:ElasticNet(random_state=123)
2025-04-06 21:52:23,025:INFO:create_model() successfully completed......................................
2025-04-06 21:52:23,175:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:23,175:INFO:Creating metrics dataframe
2025-04-06 21:52:23,178:INFO:Initializing Least Angle Regression
2025-04-06 21:52:23,178:INFO:Total runtime is 0.23890920877456664 minutes
2025-04-06 21:52:23,178:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:23,178:INFO:Initializing create_model()
2025-04-06 21:52:23,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:23,178:INFO:Checking exceptions
2025-04-06 21:52:23,178:INFO:Importing libraries
2025-04-06 21:52:23,179:INFO:Copying training dataset
2025-04-06 21:52:23,184:INFO:Defining folds
2025-04-06 21:52:23,184:INFO:Declaring metric variables
2025-04-06 21:52:23,184:INFO:Importing untrained model
2025-04-06 21:52:23,184:INFO:Least Angle Regression Imported successfully
2025-04-06 21:52:23,185:INFO:Starting cross validation
2025-04-06 21:52:23,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.121e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.120e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,341:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.372e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,342:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.648e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.431e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.080e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,343:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.567e+02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,344:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.488e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,344:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.301e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,358:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,358:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,359:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,360:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,360:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,361:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,361:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,363:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,363:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,364:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,367:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.412e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,368:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.698e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,369:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.589e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,370:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.551e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,370:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.154e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,371:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.175e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,372:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.115e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,372:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.886e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,389:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.513e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,390:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.871e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.958e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.629e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,391:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.726e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,392:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.376e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,393:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.619e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.127e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,394:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.382e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,395:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,396:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,396:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,397:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,403:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.011e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.339e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.335e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,404:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.975e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,416:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,417:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,418:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,419:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.973e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,420:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.309e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,421:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.449e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.946e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,422:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.865e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,423:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.290e+02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,424:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.199e+05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,424:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.387e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,425:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.188e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,430:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,431:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,432:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,432:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,433:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,433:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,434:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,435:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,435:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,436:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.342e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,438:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,439:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,439:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,440:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,440:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,441:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.163e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,442:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.558e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,442:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,443:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,444:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.913e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,444:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.308e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.481e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.113e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.647e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.429e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,445:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.331e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.280e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.261e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.848e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,446:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.208e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,449:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.147e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,465:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,466:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,466:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,467:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.905e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.210e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,468:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.344e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,469:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.795e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.296e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,470:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.561e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.488e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,471:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.365e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.294e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,472:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.322e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,512:INFO:Calculating mean and std
2025-04-06 21:52:23,513:INFO:Creating metrics dataframe
2025-04-06 21:52:23,515:INFO:Uploading results into container
2025-04-06 21:52:23,515:INFO:Uploading model into container now
2025-04-06 21:52:23,515:INFO:_master_model_container: 5
2025-04-06 21:52:23,516:INFO:_display_container: 2
2025-04-06 21:52:23,516:INFO:Lars(random_state=123)
2025-04-06 21:52:23,516:INFO:create_model() successfully completed......................................
2025-04-06 21:52:23,664:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:23,665:INFO:Creating metrics dataframe
2025-04-06 21:52:23,668:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:52:23,668:INFO:Total runtime is 0.247063414255778 minutes
2025-04-06 21:52:23,668:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:23,668:INFO:Initializing create_model()
2025-04-06 21:52:23,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:23,668:INFO:Checking exceptions
2025-04-06 21:52:23,668:INFO:Importing libraries
2025-04-06 21:52:23,668:INFO:Copying training dataset
2025-04-06 21:52:23,673:INFO:Defining folds
2025-04-06 21:52:23,673:INFO:Declaring metric variables
2025-04-06 21:52:23,673:INFO:Importing untrained model
2025-04-06 21:52:23,674:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:52:23,674:INFO:Starting cross validation
2025-04-06 21:52:23,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:23,831:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.433e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.215e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,832:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.107e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,833:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.334e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,833:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.969e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,834:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.995e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,835:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.374e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,835:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.355e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.161e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.451e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,837:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.079e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,844:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,845:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,845:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,846:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,846:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,847:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,847:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,850:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,896:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,897:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,898:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.029e+10, previous alpha=6.634e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,899:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,901:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.793e+07, previous alpha=5.163e+03, with an active set of 12 regressors.
  warnings.warn(

2025-04-06 21:52:23,916:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,916:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,917:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,918:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.114e+10, previous alpha=6.961e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.894e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.944e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,920:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.526e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,921:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.799e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,921:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.823e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,922:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.346e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,922:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.385e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,923:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.498e+08, previous alpha=2.565e+03, with an active set of 14 regressors.
  warnings.warn(

2025-04-06 21:52:23,934:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,934:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,935:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,935:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,936:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,938:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,939:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,939:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:52:23,940:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=8.178e+09, previous alpha=4.617e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:52:23,986:INFO:Calculating mean and std
2025-04-06 21:52:23,986:INFO:Creating metrics dataframe
2025-04-06 21:52:23,988:INFO:Uploading results into container
2025-04-06 21:52:23,988:INFO:Uploading model into container now
2025-04-06 21:52:23,989:INFO:_master_model_container: 6
2025-04-06 21:52:23,989:INFO:_display_container: 2
2025-04-06 21:52:23,989:INFO:LassoLars(random_state=123)
2025-04-06 21:52:23,989:INFO:create_model() successfully completed......................................
2025-04-06 21:52:24,134:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:24,134:INFO:Creating metrics dataframe
2025-04-06 21:52:24,137:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:52:24,137:INFO:Total runtime is 0.2548876325289408 minutes
2025-04-06 21:52:24,137:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:24,137:INFO:Initializing create_model()
2025-04-06 21:52:24,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:24,138:INFO:Checking exceptions
2025-04-06 21:52:24,138:INFO:Importing libraries
2025-04-06 21:52:24,138:INFO:Copying training dataset
2025-04-06 21:52:24,142:INFO:Defining folds
2025-04-06 21:52:24,142:INFO:Declaring metric variables
2025-04-06 21:52:24,142:INFO:Importing untrained model
2025-04-06 21:52:24,143:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:52:24,143:INFO:Starting cross validation
2025-04-06 21:52:24,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:24,469:INFO:Calculating mean and std
2025-04-06 21:52:24,470:INFO:Creating metrics dataframe
2025-04-06 21:52:24,472:INFO:Uploading results into container
2025-04-06 21:52:24,472:INFO:Uploading model into container now
2025-04-06 21:52:24,473:INFO:_master_model_container: 7
2025-04-06 21:52:24,473:INFO:_display_container: 2
2025-04-06 21:52:24,473:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:52:24,473:INFO:create_model() successfully completed......................................
2025-04-06 21:52:24,628:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:24,628:INFO:Creating metrics dataframe
2025-04-06 21:52:24,630:INFO:Initializing Bayesian Ridge
2025-04-06 21:52:24,631:INFO:Total runtime is 0.2631000876426697 minutes
2025-04-06 21:52:24,631:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:24,631:INFO:Initializing create_model()
2025-04-06 21:52:24,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:24,631:INFO:Checking exceptions
2025-04-06 21:52:24,631:INFO:Importing libraries
2025-04-06 21:52:24,631:INFO:Copying training dataset
2025-04-06 21:52:24,637:INFO:Defining folds
2025-04-06 21:52:24,637:INFO:Declaring metric variables
2025-04-06 21:52:24,637:INFO:Importing untrained model
2025-04-06 21:52:24,638:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:52:24,638:INFO:Starting cross validation
2025-04-06 21:52:24,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:24,949:INFO:Calculating mean and std
2025-04-06 21:52:24,950:INFO:Creating metrics dataframe
2025-04-06 21:52:24,951:INFO:Uploading results into container
2025-04-06 21:52:24,952:INFO:Uploading model into container now
2025-04-06 21:52:24,952:INFO:_master_model_container: 8
2025-04-06 21:52:24,952:INFO:_display_container: 2
2025-04-06 21:52:24,953:INFO:BayesianRidge()
2025-04-06 21:52:24,953:INFO:create_model() successfully completed......................................
2025-04-06 21:52:25,102:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:25,102:INFO:Creating metrics dataframe
2025-04-06 21:52:25,105:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:52:25,105:INFO:Total runtime is 0.2710230350494385 minutes
2025-04-06 21:52:25,105:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:25,106:INFO:Initializing create_model()
2025-04-06 21:52:25,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:25,106:INFO:Checking exceptions
2025-04-06 21:52:25,106:INFO:Importing libraries
2025-04-06 21:52:25,106:INFO:Copying training dataset
2025-04-06 21:52:25,111:INFO:Defining folds
2025-04-06 21:52:25,111:INFO:Declaring metric variables
2025-04-06 21:52:25,111:INFO:Importing untrained model
2025-04-06 21:52:25,112:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:52:25,112:INFO:Starting cross validation
2025-04-06 21:52:25,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:25,414:INFO:Calculating mean and std
2025-04-06 21:52:25,415:INFO:Creating metrics dataframe
2025-04-06 21:52:25,417:INFO:Uploading results into container
2025-04-06 21:52:25,417:INFO:Uploading model into container now
2025-04-06 21:52:25,418:INFO:_master_model_container: 9
2025-04-06 21:52:25,418:INFO:_display_container: 2
2025-04-06 21:52:25,418:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:52:25,418:INFO:create_model() successfully completed......................................
2025-04-06 21:52:25,571:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:25,571:INFO:Creating metrics dataframe
2025-04-06 21:52:25,573:INFO:Initializing Huber Regressor
2025-04-06 21:52:25,573:INFO:Total runtime is 0.27882731358210244 minutes
2025-04-06 21:52:25,574:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:25,574:INFO:Initializing create_model()
2025-04-06 21:52:25,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:25,574:INFO:Checking exceptions
2025-04-06 21:52:25,574:INFO:Importing libraries
2025-04-06 21:52:25,574:INFO:Copying training dataset
2025-04-06 21:52:25,579:INFO:Defining folds
2025-04-06 21:52:25,579:INFO:Declaring metric variables
2025-04-06 21:52:25,579:INFO:Importing untrained model
2025-04-06 21:52:25,580:INFO:Huber Regressor Imported successfully
2025-04-06 21:52:25,580:INFO:Starting cross validation
2025-04-06 21:52:25,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:25,811:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,812:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,836:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,837:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,870:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,887:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,895:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:25,936:INFO:Calculating mean and std
2025-04-06 21:52:25,937:INFO:Creating metrics dataframe
2025-04-06 21:52:25,938:INFO:Uploading results into container
2025-04-06 21:52:25,938:INFO:Uploading model into container now
2025-04-06 21:52:25,939:INFO:_master_model_container: 10
2025-04-06 21:52:25,939:INFO:_display_container: 2
2025-04-06 21:52:25,939:INFO:HuberRegressor()
2025-04-06 21:52:25,939:INFO:create_model() successfully completed......................................
2025-04-06 21:52:26,081:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:26,081:INFO:Creating metrics dataframe
2025-04-06 21:52:26,084:INFO:Initializing K Neighbors Regressor
2025-04-06 21:52:26,084:INFO:Total runtime is 0.2873404224713643 minutes
2025-04-06 21:52:26,084:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:26,085:INFO:Initializing create_model()
2025-04-06 21:52:26,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:26,085:INFO:Checking exceptions
2025-04-06 21:52:26,085:INFO:Importing libraries
2025-04-06 21:52:26,085:INFO:Copying training dataset
2025-04-06 21:52:26,090:INFO:Defining folds
2025-04-06 21:52:26,090:INFO:Declaring metric variables
2025-04-06 21:52:26,090:INFO:Importing untrained model
2025-04-06 21:52:26,090:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:52:26,091:INFO:Starting cross validation
2025-04-06 21:52:26,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:26,404:INFO:Calculating mean and std
2025-04-06 21:52:26,404:INFO:Creating metrics dataframe
2025-04-06 21:52:26,406:INFO:Uploading results into container
2025-04-06 21:52:26,406:INFO:Uploading model into container now
2025-04-06 21:52:26,406:INFO:_master_model_container: 11
2025-04-06 21:52:26,406:INFO:_display_container: 2
2025-04-06 21:52:26,406:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:52:26,407:INFO:create_model() successfully completed......................................
2025-04-06 21:52:26,560:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:26,560:INFO:Creating metrics dataframe
2025-04-06 21:52:26,563:INFO:Initializing Decision Tree Regressor
2025-04-06 21:52:26,563:INFO:Total runtime is 0.29531611998875934 minutes
2025-04-06 21:52:26,564:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:26,564:INFO:Initializing create_model()
2025-04-06 21:52:26,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:26,564:INFO:Checking exceptions
2025-04-06 21:52:26,564:INFO:Importing libraries
2025-04-06 21:52:26,564:INFO:Copying training dataset
2025-04-06 21:52:26,569:INFO:Defining folds
2025-04-06 21:52:26,569:INFO:Declaring metric variables
2025-04-06 21:52:26,569:INFO:Importing untrained model
2025-04-06 21:52:26,569:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:52:26,569:INFO:Starting cross validation
2025-04-06 21:52:26,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:26,868:INFO:Calculating mean and std
2025-04-06 21:52:26,869:INFO:Creating metrics dataframe
2025-04-06 21:52:26,871:INFO:Uploading results into container
2025-04-06 21:52:26,871:INFO:Uploading model into container now
2025-04-06 21:52:26,871:INFO:_master_model_container: 12
2025-04-06 21:52:26,871:INFO:_display_container: 2
2025-04-06 21:52:26,872:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:52:26,872:INFO:create_model() successfully completed......................................
2025-04-06 21:52:27,019:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:27,019:INFO:Creating metrics dataframe
2025-04-06 21:52:27,021:INFO:Initializing Random Forest Regressor
2025-04-06 21:52:27,021:INFO:Total runtime is 0.3029526591300964 minutes
2025-04-06 21:52:27,021:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:27,021:INFO:Initializing create_model()
2025-04-06 21:52:27,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:27,021:INFO:Checking exceptions
2025-04-06 21:52:27,022:INFO:Importing libraries
2025-04-06 21:52:27,022:INFO:Copying training dataset
2025-04-06 21:52:27,026:INFO:Defining folds
2025-04-06 21:52:27,026:INFO:Declaring metric variables
2025-04-06 21:52:27,027:INFO:Importing untrained model
2025-04-06 21:52:27,027:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:52:27,027:INFO:Starting cross validation
2025-04-06 21:52:27,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:28,195:INFO:Calculating mean and std
2025-04-06 21:52:28,195:INFO:Creating metrics dataframe
2025-04-06 21:52:28,197:INFO:Uploading results into container
2025-04-06 21:52:28,197:INFO:Uploading model into container now
2025-04-06 21:52:28,198:INFO:_master_model_container: 13
2025-04-06 21:52:28,198:INFO:_display_container: 2
2025-04-06 21:52:28,198:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:28,198:INFO:create_model() successfully completed......................................
2025-04-06 21:52:28,344:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:28,344:INFO:Creating metrics dataframe
2025-04-06 21:52:28,346:INFO:Initializing Extra Trees Regressor
2025-04-06 21:52:28,346:INFO:Total runtime is 0.325038468837738 minutes
2025-04-06 21:52:28,346:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:28,347:INFO:Initializing create_model()
2025-04-06 21:52:28,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:28,347:INFO:Checking exceptions
2025-04-06 21:52:28,347:INFO:Importing libraries
2025-04-06 21:52:28,347:INFO:Copying training dataset
2025-04-06 21:52:28,352:INFO:Defining folds
2025-04-06 21:52:28,352:INFO:Declaring metric variables
2025-04-06 21:52:28,352:INFO:Importing untrained model
2025-04-06 21:52:28,352:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:52:28,353:INFO:Starting cross validation
2025-04-06 21:52:28,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:29,160:INFO:Calculating mean and std
2025-04-06 21:52:29,161:INFO:Creating metrics dataframe
2025-04-06 21:52:29,162:INFO:Uploading results into container
2025-04-06 21:52:29,163:INFO:Uploading model into container now
2025-04-06 21:52:29,163:INFO:_master_model_container: 14
2025-04-06 21:52:29,163:INFO:_display_container: 2
2025-04-06 21:52:29,164:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:29,164:INFO:create_model() successfully completed......................................
2025-04-06 21:52:29,313:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:29,314:INFO:Creating metrics dataframe
2025-04-06 21:52:29,316:INFO:Initializing AdaBoost Regressor
2025-04-06 21:52:29,316:INFO:Total runtime is 0.34120856523513793 minutes
2025-04-06 21:52:29,316:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:29,316:INFO:Initializing create_model()
2025-04-06 21:52:29,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:29,316:INFO:Checking exceptions
2025-04-06 21:52:29,317:INFO:Importing libraries
2025-04-06 21:52:29,317:INFO:Copying training dataset
2025-04-06 21:52:29,322:INFO:Defining folds
2025-04-06 21:52:29,322:INFO:Declaring metric variables
2025-04-06 21:52:29,322:INFO:Importing untrained model
2025-04-06 21:52:29,322:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:52:29,323:INFO:Starting cross validation
2025-04-06 21:52:29,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:29,774:INFO:Calculating mean and std
2025-04-06 21:52:29,775:INFO:Creating metrics dataframe
2025-04-06 21:52:29,777:INFO:Uploading results into container
2025-04-06 21:52:29,777:INFO:Uploading model into container now
2025-04-06 21:52:29,777:INFO:_master_model_container: 15
2025-04-06 21:52:29,777:INFO:_display_container: 2
2025-04-06 21:52:29,778:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:52:29,778:INFO:create_model() successfully completed......................................
2025-04-06 21:52:29,926:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:29,926:INFO:Creating metrics dataframe
2025-04-06 21:52:29,928:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:52:29,928:INFO:Total runtime is 0.3513988693555196 minutes
2025-04-06 21:52:29,929:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:29,929:INFO:Initializing create_model()
2025-04-06 21:52:29,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:29,929:INFO:Checking exceptions
2025-04-06 21:52:29,929:INFO:Importing libraries
2025-04-06 21:52:29,929:INFO:Copying training dataset
2025-04-06 21:52:29,934:INFO:Defining folds
2025-04-06 21:52:29,934:INFO:Declaring metric variables
2025-04-06 21:52:29,934:INFO:Importing untrained model
2025-04-06 21:52:29,935:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:52:29,935:INFO:Starting cross validation
2025-04-06 21:52:29,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:30,563:INFO:Calculating mean and std
2025-04-06 21:52:30,564:INFO:Creating metrics dataframe
2025-04-06 21:52:30,565:INFO:Uploading results into container
2025-04-06 21:52:30,566:INFO:Uploading model into container now
2025-04-06 21:52:30,566:INFO:_master_model_container: 16
2025-04-06 21:52:30,566:INFO:_display_container: 2
2025-04-06 21:52:30,566:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:52:30,567:INFO:create_model() successfully completed......................................
2025-04-06 21:52:30,712:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:30,712:INFO:Creating metrics dataframe
2025-04-06 21:52:30,714:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:52:30,714:INFO:Total runtime is 0.36449965635935466 minutes
2025-04-06 21:52:30,714:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:30,715:INFO:Initializing create_model()
2025-04-06 21:52:30,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:30,715:INFO:Checking exceptions
2025-04-06 21:52:30,715:INFO:Importing libraries
2025-04-06 21:52:30,715:INFO:Copying training dataset
2025-04-06 21:52:30,719:INFO:Defining folds
2025-04-06 21:52:30,719:INFO:Declaring metric variables
2025-04-06 21:52:30,719:INFO:Importing untrained model
2025-04-06 21:52:30,720:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:52:30,720:INFO:Starting cross validation
2025-04-06 21:52:30,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:31,997:INFO:Calculating mean and std
2025-04-06 21:52:31,998:INFO:Creating metrics dataframe
2025-04-06 21:52:32,000:INFO:Uploading results into container
2025-04-06 21:52:32,001:INFO:Uploading model into container now
2025-04-06 21:52:32,001:INFO:_master_model_container: 17
2025-04-06 21:52:32,001:INFO:_display_container: 2
2025-04-06 21:52:32,002:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:52:32,002:INFO:create_model() successfully completed......................................
2025-04-06 21:52:32,203:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:32,203:INFO:Creating metrics dataframe
2025-04-06 21:52:32,206:INFO:Initializing CatBoost Regressor
2025-04-06 21:52:32,206:INFO:Total runtime is 0.3893664280573527 minutes
2025-04-06 21:52:32,206:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:32,207:INFO:Initializing create_model()
2025-04-06 21:52:32,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:32,207:INFO:Checking exceptions
2025-04-06 21:52:32,207:INFO:Importing libraries
2025-04-06 21:52:32,207:INFO:Copying training dataset
2025-04-06 21:52:32,213:INFO:Defining folds
2025-04-06 21:52:32,213:INFO:Declaring metric variables
2025-04-06 21:52:32,213:INFO:Importing untrained model
2025-04-06 21:52:32,214:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:52:32,214:INFO:Starting cross validation
2025-04-06 21:52:32,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:42,167:INFO:Calculating mean and std
2025-04-06 21:52:42,167:INFO:Creating metrics dataframe
2025-04-06 21:52:42,169:INFO:Uploading results into container
2025-04-06 21:52:42,169:INFO:Uploading model into container now
2025-04-06 21:52:42,170:INFO:_master_model_container: 18
2025-04-06 21:52:42,170:INFO:_display_container: 2
2025-04-06 21:52:42,170:INFO:<catboost.core.CatBoostRegressor object at 0x000001EBE4821D50>
2025-04-06 21:52:42,170:INFO:create_model() successfully completed......................................
2025-04-06 21:52:42,322:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:42,323:INFO:Creating metrics dataframe
2025-04-06 21:52:42,325:INFO:Initializing Dummy Regressor
2025-04-06 21:52:42,325:INFO:Total runtime is 0.5580158988634746 minutes
2025-04-06 21:52:42,325:INFO:SubProcess create_model() called ==================================
2025-04-06 21:52:42,325:INFO:Initializing create_model()
2025-04-06 21:52:42,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EBE2616F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:42,326:INFO:Checking exceptions
2025-04-06 21:52:42,326:INFO:Importing libraries
2025-04-06 21:52:42,326:INFO:Copying training dataset
2025-04-06 21:52:42,330:INFO:Defining folds
2025-04-06 21:52:42,330:INFO:Declaring metric variables
2025-04-06 21:52:42,330:INFO:Importing untrained model
2025-04-06 21:52:42,331:INFO:Dummy Regressor Imported successfully
2025-04-06 21:52:42,331:INFO:Starting cross validation
2025-04-06 21:52:42,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:52:42,695:INFO:Calculating mean and std
2025-04-06 21:52:42,695:INFO:Creating metrics dataframe
2025-04-06 21:52:42,697:INFO:Uploading results into container
2025-04-06 21:52:42,697:INFO:Uploading model into container now
2025-04-06 21:52:42,698:INFO:_master_model_container: 19
2025-04-06 21:52:42,698:INFO:_display_container: 2
2025-04-06 21:52:42,698:INFO:DummyRegressor()
2025-04-06 21:52:42,698:INFO:create_model() successfully completed......................................
2025-04-06 21:52:42,853:INFO:SubProcess create_model() end ==================================
2025-04-06 21:52:42,853:INFO:Creating metrics dataframe
2025-04-06 21:52:42,856:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:52:42,858:INFO:Initializing create_model()
2025-04-06 21:52:42,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EBE011C490>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:52:42,858:INFO:Checking exceptions
2025-04-06 21:52:42,858:INFO:Importing libraries
2025-04-06 21:52:42,858:INFO:Copying training dataset
2025-04-06 21:52:42,863:INFO:Defining folds
2025-04-06 21:52:42,863:INFO:Declaring metric variables
2025-04-06 21:52:42,864:INFO:Importing untrained model
2025-04-06 21:52:42,864:INFO:Declaring custom model
2025-04-06 21:52:42,864:INFO:Huber Regressor Imported successfully
2025-04-06 21:52:42,865:INFO:Cross validation set to False
2025-04-06 21:52:42,865:INFO:Fitting Model
2025-04-06 21:52:43,057:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:52:43,058:INFO:HuberRegressor()
2025-04-06 21:52:43,058:INFO:create_model() successfully completed......................................
2025-04-06 21:52:43,216:INFO:_master_model_container: 19
2025-04-06 21:52:43,216:INFO:_display_container: 2
2025-04-06 21:52:43,216:INFO:HuberRegressor()
2025-04-06 21:52:43,217:INFO:compare_models() successfully completed......................................
2025-04-06 21:55:08,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:08,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-06 21:55:18,334:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:158: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  grouped_data = df_filtered.groupby("view_bins")["likes"].mean().reset_index()

2025-04-06 21:55:18,339:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:161: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=grouped_data["view_bins"].astype(str), y=grouped_data["likes"], ax=ax, palette="Purples_r")

2025-04-06 21:55:18,677:WARNING:D:\VS Code\arquitetura\processing\data_analysis.py:188: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=category_views.index, y=category_views.values, ax=ax, palette="Blues_r")

2025-04-06 21:56:17,130:INFO:PyCaret RegressionExperiment
2025-04-06 21:56:17,130:INFO:Logging name: reg-default-name
2025-04-06 21:56:17,130:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:56:17,130:INFO:version 3.3.2
2025-04-06 21:56:17,130:INFO:Initializing setup()
2025-04-06 21:56:17,130:INFO:self.USI: 61f6
2025-04-06 21:56:17,130:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:17,131:INFO:Checking environment
2025-04-06 21:56:17,131:INFO:python_version: 3.11.4
2025-04-06 21:56:17,131:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:17,131:INFO:machine: AMD64
2025-04-06 21:56:17,161:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:17,166:INFO:Memory: svmem(total=17127211008, available=5194280960, percent=69.7, used=11932930048, free=5194280960)
2025-04-06 21:56:17,166:INFO:Physical Core: 6
2025-04-06 21:56:17,166:INFO:Logical Core: 12
2025-04-06 21:56:17,166:INFO:Checking libraries
2025-04-06 21:56:17,166:INFO:System:
2025-04-06 21:56:17,166:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:17,166:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:17,166:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:17,166:INFO:PyCaret required dependencies:
2025-04-06 21:56:17,916:INFO:                 pip: 25.0.1
2025-04-06 21:56:17,916:INFO:          setuptools: 65.5.0
2025-04-06 21:56:17,916:INFO:             pycaret: 3.3.2
2025-04-06 21:56:17,916:INFO:             IPython: 8.12.3
2025-04-06 21:56:17,916:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:17,916:INFO:                tqdm: 4.67.1
2025-04-06 21:56:17,916:INFO:               numpy: 1.26.4
2025-04-06 21:56:17,916:INFO:              pandas: 2.1.4
2025-04-06 21:56:17,916:INFO:              jinja2: 3.1.2
2025-04-06 21:56:17,916:INFO:               scipy: 1.11.4
2025-04-06 21:56:17,916:INFO:              joblib: 1.3.2
2025-04-06 21:56:17,916:INFO:             sklearn: 1.4.2
2025-04-06 21:56:17,916:INFO:                pyod: 2.0.3
2025-04-06 21:56:17,916:INFO:            imblearn: 0.13.0
2025-04-06 21:56:17,916:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:17,917:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:17,917:INFO:               numba: 0.61.0
2025-04-06 21:56:17,917:INFO:            requests: 2.32.3
2025-04-06 21:56:17,917:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:17,917:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:17,917:INFO:         yellowbrick: 1.5
2025-04-06 21:56:17,917:INFO:              plotly: 5.24.1
2025-04-06 21:56:17,917:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:17,917:INFO:             kaleido: 0.2.1
2025-04-06 21:56:17,917:INFO:           schemdraw: 0.15
2025-04-06 21:56:17,917:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:17,917:INFO:              sktime: 0.26.0
2025-04-06 21:56:17,917:INFO:               tbats: 1.1.3
2025-04-06 21:56:17,918:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:17,918:INFO:              psutil: 7.0.0
2025-04-06 21:56:17,918:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:17,918:INFO:             pickle5: Not installed
2025-04-06 21:56:17,918:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:17,918:INFO:         deprecation: 2.1.0
2025-04-06 21:56:17,918:INFO:              xxhash: 3.5.0
2025-04-06 21:56:17,918:INFO:           wurlitzer: Not installed
2025-04-06 21:56:17,918:INFO:PyCaret optional dependencies:
2025-04-06 21:56:20,640:INFO:                shap: 0.44.1
2025-04-06 21:56:20,640:INFO:           interpret: 0.6.9
2025-04-06 21:56:20,640:INFO:                umap: 0.5.7
2025-04-06 21:56:20,640:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:20,640:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:20,640:INFO:             autoviz: Not installed
2025-04-06 21:56:20,640:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:20,640:INFO:          deepchecks: Not installed
2025-04-06 21:56:20,640:INFO:             xgboost: Not installed
2025-04-06 21:56:20,640:INFO:            catboost: 1.2.7
2025-04-06 21:56:20,640:INFO:              kmodes: 0.12.2
2025-04-06 21:56:20,640:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:20,640:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:20,640:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:20,640:INFO:                 ray: Not installed
2025-04-06 21:56:20,640:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:20,640:INFO:              optuna: 4.2.1
2025-04-06 21:56:20,640:INFO:               skopt: 0.10.2
2025-04-06 21:56:20,640:INFO:              mlflow: 2.21.0
2025-04-06 21:56:20,640:INFO:              gradio: 5.21.0
2025-04-06 21:56:20,640:INFO:             fastapi: 0.115.11
2025-04-06 21:56:20,640:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:20,640:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:20,640:INFO:           evidently: 0.4.40
2025-04-06 21:56:20,640:INFO:               fugue: 0.8.7
2025-04-06 21:56:20,640:INFO:           streamlit: 1.42.2
2025-04-06 21:56:20,640:INFO:             prophet: Not installed
2025-04-06 21:56:20,640:INFO:None
2025-04-06 21:56:20,640:INFO:Set up data.
2025-04-06 21:56:20,652:INFO:Set up folding strategy.
2025-04-06 21:56:20,652:INFO:Set up train/test split.
2025-04-06 21:56:20,661:INFO:Set up index.
2025-04-06 21:56:20,661:INFO:Assigning column types.
2025-04-06 21:56:20,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:56:20,665:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,671:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:20,815:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:20,841:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,847:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,854:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,988:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:20,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:20,989:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:20,989:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:56:20,995:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,002:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,134:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,141:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,147:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,279:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,280:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:56:21,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,427:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,576:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,577:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:56:21,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,722:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:21,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:21,867:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:21,868:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:56:21,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:22,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,015:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:22,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,161:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,162:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:56:22,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,307:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:22,450:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:22,452:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:22,452:INFO:Set up simple imputation.
2025-04-06 21:56:22,455:INFO:Set up encoding of categorical features.
2025-04-06 21:56:30,148:INFO:PyCaret RegressionExperiment
2025-04-06 21:56:30,148:INFO:Logging name: reg-default-name
2025-04-06 21:56:30,148:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:56:30,148:INFO:version 3.3.2
2025-04-06 21:56:30,148:INFO:Initializing setup()
2025-04-06 21:56:30,148:INFO:self.USI: 1c4a
2025-04-06 21:56:30,148:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:30,148:INFO:Checking environment
2025-04-06 21:56:30,148:INFO:python_version: 3.11.4
2025-04-06 21:56:30,148:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:30,148:INFO:machine: AMD64
2025-04-06 21:56:30,149:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:30,153:INFO:Memory: svmem(total=17127211008, available=5154443264, percent=69.9, used=11972767744, free=5154443264)
2025-04-06 21:56:30,153:INFO:Physical Core: 6
2025-04-06 21:56:30,153:INFO:Logical Core: 12
2025-04-06 21:56:30,153:INFO:Checking libraries
2025-04-06 21:56:30,153:INFO:System:
2025-04-06 21:56:30,153:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:30,153:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:30,153:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:30,154:INFO:PyCaret required dependencies:
2025-04-06 21:56:30,154:INFO:                 pip: 25.0.1
2025-04-06 21:56:30,154:INFO:          setuptools: 65.5.0
2025-04-06 21:56:30,154:INFO:             pycaret: 3.3.2
2025-04-06 21:56:30,154:INFO:             IPython: 8.12.3
2025-04-06 21:56:30,154:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:30,154:INFO:                tqdm: 4.67.1
2025-04-06 21:56:30,154:INFO:               numpy: 1.26.4
2025-04-06 21:56:30,154:INFO:              pandas: 2.1.4
2025-04-06 21:56:30,154:INFO:              jinja2: 3.1.2
2025-04-06 21:56:30,154:INFO:               scipy: 1.11.4
2025-04-06 21:56:30,154:INFO:              joblib: 1.3.2
2025-04-06 21:56:30,154:INFO:             sklearn: 1.4.2
2025-04-06 21:56:30,154:INFO:                pyod: 2.0.3
2025-04-06 21:56:30,154:INFO:            imblearn: 0.13.0
2025-04-06 21:56:30,154:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:30,154:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:30,154:INFO:               numba: 0.61.0
2025-04-06 21:56:30,154:INFO:            requests: 2.32.3
2025-04-06 21:56:30,155:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:30,155:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:30,155:INFO:         yellowbrick: 1.5
2025-04-06 21:56:30,155:INFO:              plotly: 5.24.1
2025-04-06 21:56:30,155:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:30,155:INFO:             kaleido: 0.2.1
2025-04-06 21:56:30,155:INFO:           schemdraw: 0.15
2025-04-06 21:56:30,155:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:30,155:INFO:              sktime: 0.26.0
2025-04-06 21:56:30,155:INFO:               tbats: 1.1.3
2025-04-06 21:56:30,155:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:30,155:INFO:              psutil: 7.0.0
2025-04-06 21:56:30,155:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:30,155:INFO:             pickle5: Not installed
2025-04-06 21:56:30,155:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:30,155:INFO:         deprecation: 2.1.0
2025-04-06 21:56:30,155:INFO:              xxhash: 3.5.0
2025-04-06 21:56:30,155:INFO:           wurlitzer: Not installed
2025-04-06 21:56:30,155:INFO:PyCaret optional dependencies:
2025-04-06 21:56:30,155:INFO:                shap: 0.44.1
2025-04-06 21:56:30,156:INFO:           interpret: 0.6.9
2025-04-06 21:56:30,156:INFO:                umap: 0.5.7
2025-04-06 21:56:30,156:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:30,156:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:30,156:INFO:             autoviz: Not installed
2025-04-06 21:56:30,156:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:30,156:INFO:          deepchecks: Not installed
2025-04-06 21:56:30,156:INFO:             xgboost: Not installed
2025-04-06 21:56:30,156:INFO:            catboost: 1.2.7
2025-04-06 21:56:30,156:INFO:              kmodes: 0.12.2
2025-04-06 21:56:30,156:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:30,156:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:30,156:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:30,156:INFO:                 ray: Not installed
2025-04-06 21:56:30,156:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:30,156:INFO:              optuna: 4.2.1
2025-04-06 21:56:30,156:INFO:               skopt: 0.10.2
2025-04-06 21:56:30,156:INFO:              mlflow: 2.21.0
2025-04-06 21:56:30,157:INFO:              gradio: 5.21.0
2025-04-06 21:56:30,157:INFO:             fastapi: 0.115.11
2025-04-06 21:56:30,157:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:30,157:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:30,157:INFO:           evidently: 0.4.40
2025-04-06 21:56:30,157:INFO:               fugue: 0.8.7
2025-04-06 21:56:30,157:INFO:           streamlit: 1.42.2
2025-04-06 21:56:30,157:INFO:             prophet: Not installed
2025-04-06 21:56:30,157:INFO:None
2025-04-06 21:56:30,157:INFO:Set up data.
2025-04-06 21:56:30,168:INFO:Set up folding strategy.
2025-04-06 21:56:30,168:INFO:Set up train/test split.
2025-04-06 21:56:30,177:INFO:Set up index.
2025-04-06 21:56:30,178:INFO:Assigning column types.
2025-04-06 21:56:30,181:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:56:30,182:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,323:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,323:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,470:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,470:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:56:30,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,479:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,605:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,761:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,761:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:56:30,774:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,848:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:30,907:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:30,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:56:30,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,053:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,054:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:56:31,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,201:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,346:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,346:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:56:31,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,493:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:56:31,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,636:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,636:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:56:31,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,780:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:56:31,924:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:56:31,926:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:31,926:INFO:Set up simple imputation.
2025-04-06 21:56:31,929:INFO:Set up encoding of categorical features.
2025-04-06 21:56:36,370:INFO:PyCaret ClusteringExperiment
2025-04-06 21:56:36,370:INFO:Logging name: cluster-default-name
2025-04-06 21:56:36,370:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-06 21:56:36,370:INFO:version 3.3.2
2025-04-06 21:56:36,370:INFO:Initializing setup()
2025-04-06 21:56:36,370:INFO:self.USI: 21a8
2025-04-06 21:56:36,370:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'data', 'memory', 'gpu_param', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'seed', 'logging_param', 'log_plots_param', 'exp_id'}
2025-04-06 21:56:36,370:INFO:Checking environment
2025-04-06 21:56:36,370:INFO:python_version: 3.11.4
2025-04-06 21:56:36,370:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:56:36,370:INFO:machine: AMD64
2025-04-06 21:56:36,370:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:56:36,370:INFO:Memory: svmem(total=17127211008, available=5107380224, percent=70.2, used=12019830784, free=5107380224)
2025-04-06 21:56:36,370:INFO:Physical Core: 6
2025-04-06 21:56:36,370:INFO:Logical Core: 12
2025-04-06 21:56:36,370:INFO:Checking libraries
2025-04-06 21:56:36,370:INFO:System:
2025-04-06 21:56:36,370:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:56:36,370:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:56:36,370:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:56:36,370:INFO:PyCaret required dependencies:
2025-04-06 21:56:36,370:INFO:                 pip: 25.0.1
2025-04-06 21:56:36,370:INFO:          setuptools: 65.5.0
2025-04-06 21:56:36,370:INFO:             pycaret: 3.3.2
2025-04-06 21:56:36,370:INFO:             IPython: 8.12.3
2025-04-06 21:56:36,370:INFO:          ipywidgets: 8.1.5
2025-04-06 21:56:36,370:INFO:                tqdm: 4.67.1
2025-04-06 21:56:36,370:INFO:               numpy: 1.26.4
2025-04-06 21:56:36,370:INFO:              pandas: 2.1.4
2025-04-06 21:56:36,370:INFO:              jinja2: 3.1.2
2025-04-06 21:56:36,370:INFO:               scipy: 1.11.4
2025-04-06 21:56:36,370:INFO:              joblib: 1.3.2
2025-04-06 21:56:36,370:INFO:             sklearn: 1.4.2
2025-04-06 21:56:36,370:INFO:                pyod: 2.0.3
2025-04-06 21:56:36,370:INFO:            imblearn: 0.13.0
2025-04-06 21:56:36,370:INFO:   category_encoders: 2.7.0
2025-04-06 21:56:36,370:INFO:            lightgbm: 4.6.0
2025-04-06 21:56:36,370:INFO:               numba: 0.61.0
2025-04-06 21:56:36,370:INFO:            requests: 2.32.3
2025-04-06 21:56:36,370:INFO:          matplotlib: 3.7.5
2025-04-06 21:56:36,370:INFO:          scikitplot: 0.3.7
2025-04-06 21:56:36,370:INFO:         yellowbrick: 1.5
2025-04-06 21:56:36,370:INFO:              plotly: 5.24.1
2025-04-06 21:56:36,370:INFO:    plotly-resampler: Not installed
2025-04-06 21:56:36,370:INFO:             kaleido: 0.2.1
2025-04-06 21:56:36,370:INFO:           schemdraw: 0.15
2025-04-06 21:56:36,370:INFO:         statsmodels: 0.14.4
2025-04-06 21:56:36,370:INFO:              sktime: 0.26.0
2025-04-06 21:56:36,370:INFO:               tbats: 1.1.3
2025-04-06 21:56:36,370:INFO:            pmdarima: 2.0.4
2025-04-06 21:56:36,370:INFO:              psutil: 7.0.0
2025-04-06 21:56:36,370:INFO:          markupsafe: 2.1.3
2025-04-06 21:56:36,370:INFO:             pickle5: Not installed
2025-04-06 21:56:36,370:INFO:         cloudpickle: 3.1.1
2025-04-06 21:56:36,370:INFO:         deprecation: 2.1.0
2025-04-06 21:56:36,370:INFO:              xxhash: 3.5.0
2025-04-06 21:56:36,370:INFO:           wurlitzer: Not installed
2025-04-06 21:56:36,370:INFO:PyCaret optional dependencies:
2025-04-06 21:56:36,370:INFO:                shap: 0.44.1
2025-04-06 21:56:36,370:INFO:           interpret: 0.6.9
2025-04-06 21:56:36,370:INFO:                umap: 0.5.7
2025-04-06 21:56:36,370:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:56:36,370:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:56:36,370:INFO:             autoviz: Not installed
2025-04-06 21:56:36,370:INFO:           fairlearn: 0.7.0
2025-04-06 21:56:36,370:INFO:          deepchecks: Not installed
2025-04-06 21:56:36,370:INFO:             xgboost: Not installed
2025-04-06 21:56:36,370:INFO:            catboost: 1.2.7
2025-04-06 21:56:36,370:INFO:              kmodes: 0.12.2
2025-04-06 21:56:36,370:INFO:             mlxtend: 0.23.4
2025-04-06 21:56:36,370:INFO:       statsforecast: 1.5.0
2025-04-06 21:56:36,370:INFO:        tune_sklearn: Not installed
2025-04-06 21:56:36,370:INFO:                 ray: Not installed
2025-04-06 21:56:36,370:INFO:            hyperopt: 0.2.7
2025-04-06 21:56:36,370:INFO:              optuna: 4.2.1
2025-04-06 21:56:36,370:INFO:               skopt: 0.10.2
2025-04-06 21:56:36,370:INFO:              mlflow: 2.21.0
2025-04-06 21:56:36,370:INFO:              gradio: 5.21.0
2025-04-06 21:56:36,370:INFO:             fastapi: 0.115.11
2025-04-06 21:56:36,370:INFO:             uvicorn: 0.34.0
2025-04-06 21:56:36,370:INFO:              m2cgen: 0.10.0
2025-04-06 21:56:36,370:INFO:           evidently: 0.4.40
2025-04-06 21:56:36,370:INFO:               fugue: 0.8.7
2025-04-06 21:56:36,370:INFO:           streamlit: 1.42.2
2025-04-06 21:56:36,370:INFO:             prophet: Not installed
2025-04-06 21:56:36,370:INFO:None
2025-04-06 21:56:36,370:INFO:Set up data.
2025-04-06 21:56:36,389:INFO:Set up index.
2025-04-06 21:56:36,389:INFO:Assigning column types.
2025-04-06 21:56:36,392:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-06 21:56:36,392:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:56:36,392:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,402:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-06 21:56:36,402:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,402:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-06 21:56:36,403:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,403:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:36,404:INFO:Preparing preprocessing pipeline...
2025-04-06 21:56:36,404:INFO:Set up simple imputation.
2025-04-06 21:56:36,404:INFO:Set up encoding of categorical features.
2025-04-06 21:56:38,825:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:278: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2025-04-06 21:56:38,825:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:56:38,832:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'views', 'likes',
                                             'dislikes', 'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thu...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_link', 'description'],
                                    transformer=OneHotEncoder(cols=['video_id',
                                                                    'trending_date',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-06 21:56:38,832:INFO:Creating final display dataframe.
2025-04-06 21:56:41,026:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:111: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2025-04-06 21:56:41,800:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:56:41,808:INFO:Setup _display_container:                  Description                 Value
0                 Session id                   123
1        Original data shape            (1000, 16)
2     Transformed data shape          (1000, 4500)
3           Numeric features                     5
4       Categorical features                     8
5   Rows with missing values                  2.6%
6                 Preprocess                  True
7            Imputation type                simple
8         Numeric imputation                  mean
9     Categorical imputation                  mode
10  Maximum one-hot encoding                    -1
11           Encoding method                  None
12                  CPU Jobs                    -1
13                   Use GPU                 False
14            Log Experiment                 False
15           Experiment Name  cluster-default-name
16                       USI                  21a8
2025-04-06 21:56:41,812:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:41,813:INFO:Soft dependency imported: kmodes: 0.12.2
2025-04-06 21:56:41,813:INFO:setup() successfully completed in 5.45s...............
2025-04-06 21:56:41,813:INFO:Initializing create_model()
2025-04-06 21:56:41,813:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024FBA5D0650>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-06 21:56:41,813:INFO:Checking exceptions
2025-04-06 21:56:42,415:INFO:Importing untrained model
2025-04-06 21:56:42,415:INFO:K-Means Clustering Imported successfully
2025-04-06 21:56:42,478:INFO:Fitting Model
2025-04-06 21:56:44,785:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:56:44,786:INFO:create_models() successfully completed......................................
2025-04-06 21:56:44,786:INFO:Uploading results into container
2025-04-06 21:56:44,787:INFO:Uploading model into container now
2025-04-06 21:56:44,794:INFO:_master_model_container: 1
2025-04-06 21:56:44,794:INFO:_display_container: 2
2025-04-06 21:56:44,794:INFO:KMeans(n_clusters=4, random_state=123)
2025-04-06 21:56:44,795:INFO:create_model() successfully completed......................................
2025-04-06 21:56:55,188:INFO:Initializing predict_model()
2025-04-06 21:56:55,188:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024FBA5D0650>, estimator=KMeans(n_clusters=4, random_state=123), ml_usecase=None)
2025-04-06 21:56:56,953:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2025-04-06 21:57:41,303:INFO:PyCaret RegressionExperiment
2025-04-06 21:57:41,303:INFO:Logging name: reg-default-name
2025-04-06 21:57:41,303:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-06 21:57:41,303:INFO:version 3.3.2
2025-04-06 21:57:41,303:INFO:Initializing setup()
2025-04-06 21:57:41,303:INFO:self.USI: 3ef6
2025-04-06 21:57:41,303:INFO:self._variable_keys: {'idx', 'USI', 'pipeline', 'X_train', 'X_test', 'data', 'memory', 'transform_target_param', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'html_param', 'exp_name_log', 'gpu_n_jobs_param', '_ml_usecase', 'fold_groups_param', 'n_jobs_param', '_available_plots', 'target_param', 'y_test', 'X', 'y_train', 'seed', 'logging_param', 'y', 'log_plots_param', 'exp_id'}
2025-04-06 21:57:41,303:INFO:Checking environment
2025-04-06 21:57:41,303:INFO:python_version: 3.11.4
2025-04-06 21:57:41,303:INFO:python_build: ('tags/v3.11.4:d2340ef', 'Jun  7 2023 05:45:37')
2025-04-06 21:57:41,304:INFO:machine: AMD64
2025-04-06 21:57:41,304:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-06 21:57:41,308:INFO:Memory: svmem(total=17127211008, available=5045952512, percent=70.5, used=12081258496, free=5045952512)
2025-04-06 21:57:41,308:INFO:Physical Core: 6
2025-04-06 21:57:41,308:INFO:Logical Core: 12
2025-04-06 21:57:41,308:INFO:Checking libraries
2025-04-06 21:57:41,308:INFO:System:
2025-04-06 21:57:41,309:INFO:    python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]
2025-04-06 21:57:41,309:INFO:executable: C:\Users\eduli\AppData\Local\Programs\Python\Python311\python.exe
2025-04-06 21:57:41,309:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-06 21:57:41,309:INFO:PyCaret required dependencies:
2025-04-06 21:57:41,309:INFO:                 pip: 25.0.1
2025-04-06 21:57:41,309:INFO:          setuptools: 65.5.0
2025-04-06 21:57:41,309:INFO:             pycaret: 3.3.2
2025-04-06 21:57:41,309:INFO:             IPython: 8.12.3
2025-04-06 21:57:41,309:INFO:          ipywidgets: 8.1.5
2025-04-06 21:57:41,309:INFO:                tqdm: 4.67.1
2025-04-06 21:57:41,309:INFO:               numpy: 1.26.4
2025-04-06 21:57:41,309:INFO:              pandas: 2.1.4
2025-04-06 21:57:41,309:INFO:              jinja2: 3.1.2
2025-04-06 21:57:41,309:INFO:               scipy: 1.11.4
2025-04-06 21:57:41,309:INFO:              joblib: 1.3.2
2025-04-06 21:57:41,309:INFO:             sklearn: 1.4.2
2025-04-06 21:57:41,309:INFO:                pyod: 2.0.3
2025-04-06 21:57:41,309:INFO:            imblearn: 0.13.0
2025-04-06 21:57:41,310:INFO:   category_encoders: 2.7.0
2025-04-06 21:57:41,310:INFO:            lightgbm: 4.6.0
2025-04-06 21:57:41,310:INFO:               numba: 0.61.0
2025-04-06 21:57:41,310:INFO:            requests: 2.32.3
2025-04-06 21:57:41,310:INFO:          matplotlib: 3.7.5
2025-04-06 21:57:41,310:INFO:          scikitplot: 0.3.7
2025-04-06 21:57:41,310:INFO:         yellowbrick: 1.5
2025-04-06 21:57:41,310:INFO:              plotly: 5.24.1
2025-04-06 21:57:41,310:INFO:    plotly-resampler: Not installed
2025-04-06 21:57:41,310:INFO:             kaleido: 0.2.1
2025-04-06 21:57:41,310:INFO:           schemdraw: 0.15
2025-04-06 21:57:41,310:INFO:         statsmodels: 0.14.4
2025-04-06 21:57:41,310:INFO:              sktime: 0.26.0
2025-04-06 21:57:41,310:INFO:               tbats: 1.1.3
2025-04-06 21:57:41,310:INFO:            pmdarima: 2.0.4
2025-04-06 21:57:41,310:INFO:              psutil: 7.0.0
2025-04-06 21:57:41,310:INFO:          markupsafe: 2.1.3
2025-04-06 21:57:41,310:INFO:             pickle5: Not installed
2025-04-06 21:57:41,310:INFO:         cloudpickle: 3.1.1
2025-04-06 21:57:41,310:INFO:         deprecation: 2.1.0
2025-04-06 21:57:41,310:INFO:              xxhash: 3.5.0
2025-04-06 21:57:41,311:INFO:           wurlitzer: Not installed
2025-04-06 21:57:41,311:INFO:PyCaret optional dependencies:
2025-04-06 21:57:41,311:INFO:                shap: 0.44.1
2025-04-06 21:57:41,311:INFO:           interpret: 0.6.9
2025-04-06 21:57:41,311:INFO:                umap: 0.5.7
2025-04-06 21:57:41,311:INFO:     ydata_profiling: 4.14.0
2025-04-06 21:57:41,311:INFO:  explainerdashboard: 0.4.8
2025-04-06 21:57:41,311:INFO:             autoviz: Not installed
2025-04-06 21:57:41,311:INFO:           fairlearn: 0.7.0
2025-04-06 21:57:41,311:INFO:          deepchecks: Not installed
2025-04-06 21:57:41,311:INFO:             xgboost: Not installed
2025-04-06 21:57:41,311:INFO:            catboost: 1.2.7
2025-04-06 21:57:41,311:INFO:              kmodes: 0.12.2
2025-04-06 21:57:41,311:INFO:             mlxtend: 0.23.4
2025-04-06 21:57:41,311:INFO:       statsforecast: 1.5.0
2025-04-06 21:57:41,311:INFO:        tune_sklearn: Not installed
2025-04-06 21:57:41,311:INFO:                 ray: Not installed
2025-04-06 21:57:41,311:INFO:            hyperopt: 0.2.7
2025-04-06 21:57:41,312:INFO:              optuna: 4.2.1
2025-04-06 21:57:41,312:INFO:               skopt: 0.10.2
2025-04-06 21:57:41,312:INFO:              mlflow: 2.21.0
2025-04-06 21:57:41,312:INFO:              gradio: 5.21.0
2025-04-06 21:57:41,312:INFO:             fastapi: 0.115.11
2025-04-06 21:57:41,312:INFO:             uvicorn: 0.34.0
2025-04-06 21:57:41,312:INFO:              m2cgen: 0.10.0
2025-04-06 21:57:41,312:INFO:           evidently: 0.4.40
2025-04-06 21:57:41,312:INFO:               fugue: 0.8.7
2025-04-06 21:57:41,312:INFO:           streamlit: 1.42.2
2025-04-06 21:57:41,312:INFO:             prophet: Not installed
2025-04-06 21:57:41,312:INFO:None
2025-04-06 21:57:41,312:INFO:Set up data.
2025-04-06 21:57:41,323:INFO:Set up folding strategy.
2025-04-06 21:57:41,323:INFO:Set up train/test split.
2025-04-06 21:57:41,331:INFO:Set up index.
2025-04-06 21:57:41,331:INFO:Assigning column types.
2025-04-06 21:57:41,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-06 21:57:41,335:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,339:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,483:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,484:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,485:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,620:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-06 21:57:41,620:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,635:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,760:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:41,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:41,920:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:41,921:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-06 21:57:41,933:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,069:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,082:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,225:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,225:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-06 21:57:42,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,376:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,522:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,523:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-06 21:57:42,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,668:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-06 21:57:42,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,817:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:42,819:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-06 21:57:42,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:42,962:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,110:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,112:INFO:Preparing preprocessing pipeline...
2025-04-06 21:57:43,112:INFO:Set up simple imputation.
2025-04-06 21:57:43,115:INFO:Set up encoding of categorical features.
2025-04-06 21:57:43,321:INFO:Finished creating preprocessing pipeline.
2025-04-06 21:57:43,330:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\eduli\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['category_id', 'likes', 'dislikes',
                                             'comment_count'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['video_id', 'trending_date',
                                             'title', 'channel_title',
                                             'publish_time', 'tags',
                                             'thumbnail_l...
                                    transformer=OneHotEncoder(cols=['trending_date'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['video_id', 'title',
                                             'channel_title', 'publish_time',
                                             'tags', 'thumbnail_link',
                                             'description'],
                                    transformer=TargetEncoder(cols=['video_id',
                                                                    'title',
                                                                    'channel_title',
                                                                    'publish_time',
                                                                    'tags',
                                                                    'thumbnail_link',
                                                                    'description'],
                                                              handle_missing='return_nan')))])
2025-04-06 21:57:43,330:INFO:Creating final display dataframe.
2025-04-06 21:57:43,595:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             views
2                   Target type        Regression
3           Original data shape        (1000, 16)
4        Transformed data shape        (1000, 20)
5   Transformed train set shape         (700, 20)
6    Transformed test set shape         (300, 20)
7              Numeric features                 4
8          Categorical features                 8
9      Rows with missing values              2.6%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3ef6
2025-04-06 21:57:43,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,748:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-06 21:57:43,897:INFO:Soft dependency imported: catboost: 1.2.7
2025-04-06 21:57:43,898:INFO:setup() successfully completed in 2.61s...............
2025-04-06 21:57:43,898:INFO:Initializing compare_models()
2025-04-06 21:57:43,898:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-06 21:57:43,898:INFO:Checking exceptions
2025-04-06 21:57:43,900:INFO:Preparing display monitor
2025-04-06 21:57:43,902:INFO:Initializing Linear Regression
2025-04-06 21:57:43,902:INFO:Total runtime is 0.0 minutes
2025-04-06 21:57:43,903:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:43,903:INFO:Initializing create_model()
2025-04-06 21:57:43,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:43,903:INFO:Checking exceptions
2025-04-06 21:57:43,903:INFO:Importing libraries
2025-04-06 21:57:43,903:INFO:Copying training dataset
2025-04-06 21:57:43,909:INFO:Defining folds
2025-04-06 21:57:43,909:INFO:Declaring metric variables
2025-04-06 21:57:43,909:INFO:Importing untrained model
2025-04-06 21:57:43,909:INFO:Linear Regression Imported successfully
2025-04-06 21:57:43,909:INFO:Starting cross validation
2025-04-06 21:57:43,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:52,179:INFO:Calculating mean and std
2025-04-06 21:57:52,181:INFO:Creating metrics dataframe
2025-04-06 21:57:52,183:INFO:Uploading results into container
2025-04-06 21:57:52,184:INFO:Uploading model into container now
2025-04-06 21:57:52,185:INFO:_master_model_container: 1
2025-04-06 21:57:52,185:INFO:_display_container: 2
2025-04-06 21:57:52,185:INFO:LinearRegression(n_jobs=-1)
2025-04-06 21:57:52,185:INFO:create_model() successfully completed......................................
2025-04-06 21:57:52,376:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:52,376:INFO:Creating metrics dataframe
2025-04-06 21:57:52,380:INFO:Initializing Lasso Regression
2025-04-06 21:57:52,381:INFO:Total runtime is 0.14132106701533 minutes
2025-04-06 21:57:52,381:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:52,382:INFO:Initializing create_model()
2025-04-06 21:57:52,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:52,382:INFO:Checking exceptions
2025-04-06 21:57:52,382:INFO:Importing libraries
2025-04-06 21:57:52,382:INFO:Copying training dataset
2025-04-06 21:57:52,391:INFO:Defining folds
2025-04-06 21:57:52,392:INFO:Declaring metric variables
2025-04-06 21:57:52,392:INFO:Importing untrained model
2025-04-06 21:57:52,392:INFO:Lasso Regression Imported successfully
2025-04-06 21:57:52,393:INFO:Starting cross validation
2025-04-06 21:57:52,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:52,663:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,669:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,722:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,730:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,743:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:52,849:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,117:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,157:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:57,201:INFO:Calculating mean and std
2025-04-06 21:57:57,202:INFO:Creating metrics dataframe
2025-04-06 21:57:57,204:INFO:Uploading results into container
2025-04-06 21:57:57,204:INFO:Uploading model into container now
2025-04-06 21:57:57,205:INFO:_master_model_container: 2
2025-04-06 21:57:57,205:INFO:_display_container: 2
2025-04-06 21:57:57,205:INFO:Lasso(random_state=123)
2025-04-06 21:57:57,205:INFO:create_model() successfully completed......................................
2025-04-06 21:57:57,408:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:57,408:INFO:Creating metrics dataframe
2025-04-06 21:57:57,411:INFO:Initializing Ridge Regression
2025-04-06 21:57:57,411:INFO:Total runtime is 0.22515811522801718 minutes
2025-04-06 21:57:57,411:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:57,411:INFO:Initializing create_model()
2025-04-06 21:57:57,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:57,411:INFO:Checking exceptions
2025-04-06 21:57:57,411:INFO:Importing libraries
2025-04-06 21:57:57,411:INFO:Copying training dataset
2025-04-06 21:57:57,417:INFO:Defining folds
2025-04-06 21:57:57,417:INFO:Declaring metric variables
2025-04-06 21:57:57,417:INFO:Importing untrained model
2025-04-06 21:57:57,417:INFO:Ridge Regression Imported successfully
2025-04-06 21:57:57,418:INFO:Starting cross validation
2025-04-06 21:57:57,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:57,754:INFO:Calculating mean and std
2025-04-06 21:57:57,755:INFO:Creating metrics dataframe
2025-04-06 21:57:57,756:INFO:Uploading results into container
2025-04-06 21:57:57,756:INFO:Uploading model into container now
2025-04-06 21:57:57,756:INFO:_master_model_container: 3
2025-04-06 21:57:57,757:INFO:_display_container: 2
2025-04-06 21:57:57,757:INFO:Ridge(random_state=123)
2025-04-06 21:57:57,757:INFO:create_model() successfully completed......................................
2025-04-06 21:57:57,910:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:57,910:INFO:Creating metrics dataframe
2025-04-06 21:57:57,912:INFO:Initializing Elastic Net
2025-04-06 21:57:57,912:INFO:Total runtime is 0.23349734942118328 minutes
2025-04-06 21:57:57,913:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:57,913:INFO:Initializing create_model()
2025-04-06 21:57:57,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:57,913:INFO:Checking exceptions
2025-04-06 21:57:57,913:INFO:Importing libraries
2025-04-06 21:57:57,913:INFO:Copying training dataset
2025-04-06 21:57:57,917:INFO:Defining folds
2025-04-06 21:57:57,917:INFO:Declaring metric variables
2025-04-06 21:57:57,918:INFO:Importing untrained model
2025-04-06 21:57:57,918:INFO:Elastic Net Imported successfully
2025-04-06 21:57:57,918:INFO:Starting cross validation
2025-04-06 21:57:57,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:58,105:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+13, tolerance: 3.274e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,111:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+13, tolerance: 2.407e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,141:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+13, tolerance: 3.697e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,174:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+13, tolerance: 3.633e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,176:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.415e+13, tolerance: 3.909e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,198:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+13, tolerance: 3.851e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,210:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+13, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+13, tolerance: 3.858e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,239:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+13, tolerance: 3.217e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,257:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e+13, tolerance: 3.906e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-06 21:57:58,305:INFO:Calculating mean and std
2025-04-06 21:57:58,305:INFO:Creating metrics dataframe
2025-04-06 21:57:58,307:INFO:Uploading results into container
2025-04-06 21:57:58,307:INFO:Uploading model into container now
2025-04-06 21:57:58,308:INFO:_master_model_container: 4
2025-04-06 21:57:58,308:INFO:_display_container: 2
2025-04-06 21:57:58,308:INFO:ElasticNet(random_state=123)
2025-04-06 21:57:58,308:INFO:create_model() successfully completed......................................
2025-04-06 21:57:58,472:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:58,472:INFO:Creating metrics dataframe
2025-04-06 21:57:58,475:INFO:Initializing Least Angle Regression
2025-04-06 21:57:58,475:INFO:Total runtime is 0.24288624127705893 minutes
2025-04-06 21:57:58,475:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:58,476:INFO:Initializing create_model()
2025-04-06 21:57:58,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:58,476:INFO:Checking exceptions
2025-04-06 21:57:58,476:INFO:Importing libraries
2025-04-06 21:57:58,476:INFO:Copying training dataset
2025-04-06 21:57:58,481:INFO:Defining folds
2025-04-06 21:57:58,481:INFO:Declaring metric variables
2025-04-06 21:57:58,481:INFO:Importing untrained model
2025-04-06 21:57:58,482:INFO:Least Angle Regression Imported successfully
2025-04-06 21:57:58,482:INFO:Starting cross validation
2025-04-06 21:57:58,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:58,707:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.121e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,708:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.120e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,710:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.372e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,711:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=6.648e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,712:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.431e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,712:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.412e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,713:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.080e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,713:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.567e+02, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,714:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.488e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,714:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.301e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,715:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.698e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,716:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.589e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,716:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.551e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.154e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,717:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,718:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,718:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.175e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,719:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,719:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,720:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.115e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,720:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.886e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,722:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,723:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,724:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,724:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,733:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,734:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,735:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,736:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,737:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.973e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,737:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.309e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,738:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.449e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.946e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,739:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.865e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,740:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=7.290e+02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.199e+05, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.387e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,741:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.188e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,745:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.513e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,746:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.871e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.958e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.629e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,747:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.726e+04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,748:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,749:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,750:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.011e+04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.376e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.339e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.619e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.335e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,752:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.127e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,753:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.975e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,753:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.382e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,768:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,768:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,769:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,770:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,770:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.163e+10, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.558e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.241e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=8.493e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.913e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,771:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.308e+03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.431e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.113e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,776:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=9.481e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,777:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.429e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,777:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.647e+05, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,778:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.280e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,778:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=4.331e+04, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,779:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.261e+04, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,780:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.848e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,781:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.208e+03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,781:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.147e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,785:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,785:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,786:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,787:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.905e+09, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.210e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,788:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.344e+08, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,789:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.795e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,790:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.296e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,790:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.561e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.756e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,791:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=9.488e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=8.365e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,792:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=4.342e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,793:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=7.294e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,794:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.322e-02, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:58,846:INFO:Calculating mean and std
2025-04-06 21:57:58,847:INFO:Creating metrics dataframe
2025-04-06 21:57:58,848:INFO:Uploading results into container
2025-04-06 21:57:58,849:INFO:Uploading model into container now
2025-04-06 21:57:58,849:INFO:_master_model_container: 5
2025-04-06 21:57:58,849:INFO:_display_container: 2
2025-04-06 21:57:58,850:INFO:Lars(random_state=123)
2025-04-06 21:57:58,850:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,010:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,010:INFO:Creating metrics dataframe
2025-04-06 21:57:59,013:INFO:Initializing Lasso Least Angle Regression
2025-04-06 21:57:59,013:INFO:Total runtime is 0.25185402631759646 minutes
2025-04-06 21:57:59,013:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,014:INFO:Initializing create_model()
2025-04-06 21:57:59,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,014:INFO:Checking exceptions
2025-04-06 21:57:59,014:INFO:Importing libraries
2025-04-06 21:57:59,014:INFO:Copying training dataset
2025-04-06 21:57:59,019:INFO:Defining folds
2025-04-06 21:57:59,019:INFO:Declaring metric variables
2025-04-06 21:57:59,019:INFO:Importing untrained model
2025-04-06 21:57:59,019:INFO:Lasso Least Angle Regression Imported successfully
2025-04-06 21:57:59,020:INFO:Starting cross validation
2025-04-06 21:57:59,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:59,188:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.433e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,189:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.215e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,190:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.107e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,192:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.334e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,193:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.969e+07, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,194:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=4.995e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,195:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.374e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,195:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.355e+03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.161e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.451e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,197:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.079e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.601e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.300e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,215:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.499e+08, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,216:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.099e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,217:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.084e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,217:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.470e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,218:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.569e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.114e+03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,219:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.011e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,221:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.969e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,268:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.343e+09, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,269:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=6.689e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,269:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.643e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,270:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=5.794e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,271:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.793e+07, previous alpha=5.163e+03, with an active set of 12 regressors.
  warnings.warn(

2025-04-06 21:57:59,273:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.891e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,273:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=9.454e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.727e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.362e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,274:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.173e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,276:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.114e+10, previous alpha=6.961e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.762e+11, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=8.810e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,278:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.405e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.200e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.088e+10, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,279:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=1.029e+10, previous alpha=6.634e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,287:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.933e+09, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,288:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.466e+09, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,288:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.233e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,289:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=4.845e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,289:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.658e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,290:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.826e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,290:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.433e+03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.894e+08, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=6.436e+02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.944e+08, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.897e+02, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,291:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.526e+08, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.799e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.823e+04, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,292:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.346e+03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,293:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.385e+03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,294:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.498e+08, previous alpha=2.565e+03, with an active set of 14 regressors.
  warnings.warn(

2025-04-06 21:57:59,305:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.997e+10, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.498e+10, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.748e+10, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,306:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=8.641e+09, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-06 21:57:59,307:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=8.178e+09, previous alpha=4.617e+09, with an active set of 6 regressors.
  warnings.warn(

2025-04-06 21:57:59,352:INFO:Calculating mean and std
2025-04-06 21:57:59,353:INFO:Creating metrics dataframe
2025-04-06 21:57:59,355:INFO:Uploading results into container
2025-04-06 21:57:59,355:INFO:Uploading model into container now
2025-04-06 21:57:59,355:INFO:_master_model_container: 6
2025-04-06 21:57:59,356:INFO:_display_container: 2
2025-04-06 21:57:59,356:INFO:LassoLars(random_state=123)
2025-04-06 21:57:59,356:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,512:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,512:INFO:Creating metrics dataframe
2025-04-06 21:57:59,514:INFO:Initializing Orthogonal Matching Pursuit
2025-04-06 21:57:59,514:INFO:Total runtime is 0.26020932594935103 minutes
2025-04-06 21:57:59,515:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,515:INFO:Initializing create_model()
2025-04-06 21:57:59,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,515:INFO:Checking exceptions
2025-04-06 21:57:59,515:INFO:Importing libraries
2025-04-06 21:57:59,515:INFO:Copying training dataset
2025-04-06 21:57:59,520:INFO:Defining folds
2025-04-06 21:57:59,521:INFO:Declaring metric variables
2025-04-06 21:57:59,521:INFO:Importing untrained model
2025-04-06 21:57:59,521:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-06 21:57:59,521:INFO:Starting cross validation
2025-04-06 21:57:59,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:57:59,821:INFO:Calculating mean and std
2025-04-06 21:57:59,822:INFO:Creating metrics dataframe
2025-04-06 21:57:59,823:INFO:Uploading results into container
2025-04-06 21:57:59,824:INFO:Uploading model into container now
2025-04-06 21:57:59,825:INFO:_master_model_container: 7
2025-04-06 21:57:59,825:INFO:_display_container: 2
2025-04-06 21:57:59,825:INFO:OrthogonalMatchingPursuit()
2025-04-06 21:57:59,825:INFO:create_model() successfully completed......................................
2025-04-06 21:57:59,980:INFO:SubProcess create_model() end ==================================
2025-04-06 21:57:59,980:INFO:Creating metrics dataframe
2025-04-06 21:57:59,983:INFO:Initializing Bayesian Ridge
2025-04-06 21:57:59,983:INFO:Total runtime is 0.26801386674245203 minutes
2025-04-06 21:57:59,983:INFO:SubProcess create_model() called ==================================
2025-04-06 21:57:59,983:INFO:Initializing create_model()
2025-04-06 21:57:59,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:57:59,983:INFO:Checking exceptions
2025-04-06 21:57:59,983:INFO:Importing libraries
2025-04-06 21:57:59,984:INFO:Copying training dataset
2025-04-06 21:57:59,988:INFO:Defining folds
2025-04-06 21:57:59,988:INFO:Declaring metric variables
2025-04-06 21:57:59,988:INFO:Importing untrained model
2025-04-06 21:57:59,989:INFO:Bayesian Ridge Imported successfully
2025-04-06 21:57:59,989:INFO:Starting cross validation
2025-04-06 21:57:59,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:00,325:INFO:Calculating mean and std
2025-04-06 21:58:00,326:INFO:Creating metrics dataframe
2025-04-06 21:58:00,328:INFO:Uploading results into container
2025-04-06 21:58:00,329:INFO:Uploading model into container now
2025-04-06 21:58:00,329:INFO:_master_model_container: 8
2025-04-06 21:58:00,329:INFO:_display_container: 2
2025-04-06 21:58:00,329:INFO:BayesianRidge()
2025-04-06 21:58:00,329:INFO:create_model() successfully completed......................................
2025-04-06 21:58:00,502:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:00,502:INFO:Creating metrics dataframe
2025-04-06 21:58:00,505:INFO:Initializing Passive Aggressive Regressor
2025-04-06 21:58:00,505:INFO:Total runtime is 0.27672396103541064 minutes
2025-04-06 21:58:00,505:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:00,505:INFO:Initializing create_model()
2025-04-06 21:58:00,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:00,505:INFO:Checking exceptions
2025-04-06 21:58:00,505:INFO:Importing libraries
2025-04-06 21:58:00,505:INFO:Copying training dataset
2025-04-06 21:58:00,510:INFO:Defining folds
2025-04-06 21:58:00,510:INFO:Declaring metric variables
2025-04-06 21:58:00,510:INFO:Importing untrained model
2025-04-06 21:58:00,511:INFO:Passive Aggressive Regressor Imported successfully
2025-04-06 21:58:00,511:INFO:Starting cross validation
2025-04-06 21:58:00,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:00,829:INFO:Calculating mean and std
2025-04-06 21:58:00,830:INFO:Creating metrics dataframe
2025-04-06 21:58:00,831:INFO:Uploading results into container
2025-04-06 21:58:00,832:INFO:Uploading model into container now
2025-04-06 21:58:00,832:INFO:_master_model_container: 9
2025-04-06 21:58:00,832:INFO:_display_container: 2
2025-04-06 21:58:00,833:INFO:PassiveAggressiveRegressor(random_state=123)
2025-04-06 21:58:00,833:INFO:create_model() successfully completed......................................
2025-04-06 21:58:00,988:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:00,988:INFO:Creating metrics dataframe
2025-04-06 21:58:00,991:INFO:Initializing Huber Regressor
2025-04-06 21:58:00,991:INFO:Total runtime is 0.28481064240137743 minutes
2025-04-06 21:58:00,991:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:00,991:INFO:Initializing create_model()
2025-04-06 21:58:00,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:00,992:INFO:Checking exceptions
2025-04-06 21:58:00,992:INFO:Importing libraries
2025-04-06 21:58:00,992:INFO:Copying training dataset
2025-04-06 21:58:00,997:INFO:Defining folds
2025-04-06 21:58:00,998:INFO:Declaring metric variables
2025-04-06 21:58:00,998:INFO:Importing untrained model
2025-04-06 21:58:00,998:INFO:Huber Regressor Imported successfully
2025-04-06 21:58:00,998:INFO:Starting cross validation
2025-04-06 21:58:00,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:01,244:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,245:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,250:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,275:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,287:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,314:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,321:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:01,368:INFO:Calculating mean and std
2025-04-06 21:58:01,369:INFO:Creating metrics dataframe
2025-04-06 21:58:01,370:INFO:Uploading results into container
2025-04-06 21:58:01,371:INFO:Uploading model into container now
2025-04-06 21:58:01,371:INFO:_master_model_container: 10
2025-04-06 21:58:01,371:INFO:_display_container: 2
2025-04-06 21:58:01,371:INFO:HuberRegressor()
2025-04-06 21:58:01,371:INFO:create_model() successfully completed......................................
2025-04-06 21:58:01,553:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:01,554:INFO:Creating metrics dataframe
2025-04-06 21:58:01,556:INFO:Initializing K Neighbors Regressor
2025-04-06 21:58:01,557:INFO:Total runtime is 0.29423513015111297 minutes
2025-04-06 21:58:01,557:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:01,557:INFO:Initializing create_model()
2025-04-06 21:58:01,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:01,557:INFO:Checking exceptions
2025-04-06 21:58:01,557:INFO:Importing libraries
2025-04-06 21:58:01,557:INFO:Copying training dataset
2025-04-06 21:58:01,563:INFO:Defining folds
2025-04-06 21:58:01,563:INFO:Declaring metric variables
2025-04-06 21:58:01,564:INFO:Importing untrained model
2025-04-06 21:58:01,564:INFO:K Neighbors Regressor Imported successfully
2025-04-06 21:58:01,564:INFO:Starting cross validation
2025-04-06 21:58:01,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:01,901:INFO:Calculating mean and std
2025-04-06 21:58:01,902:INFO:Creating metrics dataframe
2025-04-06 21:58:01,903:INFO:Uploading results into container
2025-04-06 21:58:01,904:INFO:Uploading model into container now
2025-04-06 21:58:01,904:INFO:_master_model_container: 11
2025-04-06 21:58:01,904:INFO:_display_container: 2
2025-04-06 21:58:01,904:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-06 21:58:01,905:INFO:create_model() successfully completed......................................
2025-04-06 21:58:02,062:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:02,062:INFO:Creating metrics dataframe
2025-04-06 21:58:02,065:INFO:Initializing Decision Tree Regressor
2025-04-06 21:58:02,065:INFO:Total runtime is 0.30271740357081106 minutes
2025-04-06 21:58:02,065:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:02,065:INFO:Initializing create_model()
2025-04-06 21:58:02,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:02,065:INFO:Checking exceptions
2025-04-06 21:58:02,065:INFO:Importing libraries
2025-04-06 21:58:02,066:INFO:Copying training dataset
2025-04-06 21:58:02,071:INFO:Defining folds
2025-04-06 21:58:02,071:INFO:Declaring metric variables
2025-04-06 21:58:02,071:INFO:Importing untrained model
2025-04-06 21:58:02,071:INFO:Decision Tree Regressor Imported successfully
2025-04-06 21:58:02,072:INFO:Starting cross validation
2025-04-06 21:58:02,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:02,437:INFO:Calculating mean and std
2025-04-06 21:58:02,438:INFO:Creating metrics dataframe
2025-04-06 21:58:02,439:INFO:Uploading results into container
2025-04-06 21:58:02,439:INFO:Uploading model into container now
2025-04-06 21:58:02,439:INFO:_master_model_container: 12
2025-04-06 21:58:02,439:INFO:_display_container: 2
2025-04-06 21:58:02,440:INFO:DecisionTreeRegressor(random_state=123)
2025-04-06 21:58:02,440:INFO:create_model() successfully completed......................................
2025-04-06 21:58:02,609:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:02,610:INFO:Creating metrics dataframe
2025-04-06 21:58:02,612:INFO:Initializing Random Forest Regressor
2025-04-06 21:58:02,612:INFO:Total runtime is 0.3118304769198101 minutes
2025-04-06 21:58:02,612:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:02,613:INFO:Initializing create_model()
2025-04-06 21:58:02,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:02,613:INFO:Checking exceptions
2025-04-06 21:58:02,613:INFO:Importing libraries
2025-04-06 21:58:02,613:INFO:Copying training dataset
2025-04-06 21:58:02,617:INFO:Defining folds
2025-04-06 21:58:02,617:INFO:Declaring metric variables
2025-04-06 21:58:02,617:INFO:Importing untrained model
2025-04-06 21:58:02,618:INFO:Random Forest Regressor Imported successfully
2025-04-06 21:58:02,618:INFO:Starting cross validation
2025-04-06 21:58:02,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:03,916:INFO:Calculating mean and std
2025-04-06 21:58:03,917:INFO:Creating metrics dataframe
2025-04-06 21:58:03,919:INFO:Uploading results into container
2025-04-06 21:58:03,920:INFO:Uploading model into container now
2025-04-06 21:58:03,920:INFO:_master_model_container: 13
2025-04-06 21:58:03,920:INFO:_display_container: 2
2025-04-06 21:58:03,921:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:03,921:INFO:create_model() successfully completed......................................
2025-04-06 21:58:04,100:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:04,100:INFO:Creating metrics dataframe
2025-04-06 21:58:04,103:INFO:Initializing Extra Trees Regressor
2025-04-06 21:58:04,103:INFO:Total runtime is 0.33667778174082447 minutes
2025-04-06 21:58:04,103:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:04,104:INFO:Initializing create_model()
2025-04-06 21:58:04,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:04,104:INFO:Checking exceptions
2025-04-06 21:58:04,104:INFO:Importing libraries
2025-04-06 21:58:04,104:INFO:Copying training dataset
2025-04-06 21:58:04,109:INFO:Defining folds
2025-04-06 21:58:04,109:INFO:Declaring metric variables
2025-04-06 21:58:04,109:INFO:Importing untrained model
2025-04-06 21:58:04,109:INFO:Extra Trees Regressor Imported successfully
2025-04-06 21:58:04,110:INFO:Starting cross validation
2025-04-06 21:58:04,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:04,957:INFO:Calculating mean and std
2025-04-06 21:58:04,957:INFO:Creating metrics dataframe
2025-04-06 21:58:04,959:INFO:Uploading results into container
2025-04-06 21:58:04,960:INFO:Uploading model into container now
2025-04-06 21:58:04,960:INFO:_master_model_container: 14
2025-04-06 21:58:04,960:INFO:_display_container: 2
2025-04-06 21:58:04,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:04,961:INFO:create_model() successfully completed......................................
2025-04-06 21:58:05,135:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:05,135:INFO:Creating metrics dataframe
2025-04-06 21:58:05,137:INFO:Initializing AdaBoost Regressor
2025-04-06 21:58:05,138:INFO:Total runtime is 0.3539403637250265 minutes
2025-04-06 21:58:05,138:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:05,138:INFO:Initializing create_model()
2025-04-06 21:58:05,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:05,138:INFO:Checking exceptions
2025-04-06 21:58:05,138:INFO:Importing libraries
2025-04-06 21:58:05,138:INFO:Copying training dataset
2025-04-06 21:58:05,143:INFO:Defining folds
2025-04-06 21:58:05,143:INFO:Declaring metric variables
2025-04-06 21:58:05,143:INFO:Importing untrained model
2025-04-06 21:58:05,143:INFO:AdaBoost Regressor Imported successfully
2025-04-06 21:58:05,144:INFO:Starting cross validation
2025-04-06 21:58:05,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:05,662:INFO:Calculating mean and std
2025-04-06 21:58:05,663:INFO:Creating metrics dataframe
2025-04-06 21:58:05,666:INFO:Uploading results into container
2025-04-06 21:58:05,667:INFO:Uploading model into container now
2025-04-06 21:58:05,668:INFO:_master_model_container: 15
2025-04-06 21:58:05,668:INFO:_display_container: 2
2025-04-06 21:58:05,668:INFO:AdaBoostRegressor(random_state=123)
2025-04-06 21:58:05,668:INFO:create_model() successfully completed......................................
2025-04-06 21:58:05,857:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:05,857:INFO:Creating metrics dataframe
2025-04-06 21:58:05,859:INFO:Initializing Gradient Boosting Regressor
2025-04-06 21:58:05,859:INFO:Total runtime is 0.3659558455149333 minutes
2025-04-06 21:58:05,859:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:05,859:INFO:Initializing create_model()
2025-04-06 21:58:05,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:05,859:INFO:Checking exceptions
2025-04-06 21:58:05,859:INFO:Importing libraries
2025-04-06 21:58:05,859:INFO:Copying training dataset
2025-04-06 21:58:05,864:INFO:Defining folds
2025-04-06 21:58:05,864:INFO:Declaring metric variables
2025-04-06 21:58:05,864:INFO:Importing untrained model
2025-04-06 21:58:05,865:INFO:Gradient Boosting Regressor Imported successfully
2025-04-06 21:58:05,865:INFO:Starting cross validation
2025-04-06 21:58:05,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:06,476:INFO:Calculating mean and std
2025-04-06 21:58:06,477:INFO:Creating metrics dataframe
2025-04-06 21:58:06,479:INFO:Uploading results into container
2025-04-06 21:58:06,479:INFO:Uploading model into container now
2025-04-06 21:58:06,479:INFO:_master_model_container: 16
2025-04-06 21:58:06,480:INFO:_display_container: 2
2025-04-06 21:58:06,480:INFO:GradientBoostingRegressor(random_state=123)
2025-04-06 21:58:06,480:INFO:create_model() successfully completed......................................
2025-04-06 21:58:06,651:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:06,651:INFO:Creating metrics dataframe
2025-04-06 21:58:06,654:INFO:Initializing Light Gradient Boosting Machine
2025-04-06 21:58:06,654:INFO:Total runtime is 0.3792034506797791 minutes
2025-04-06 21:58:06,655:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:06,655:INFO:Initializing create_model()
2025-04-06 21:58:06,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:06,655:INFO:Checking exceptions
2025-04-06 21:58:06,655:INFO:Importing libraries
2025-04-06 21:58:06,655:INFO:Copying training dataset
2025-04-06 21:58:06,661:INFO:Defining folds
2025-04-06 21:58:06,661:INFO:Declaring metric variables
2025-04-06 21:58:06,661:INFO:Importing untrained model
2025-04-06 21:58:06,662:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-06 21:58:06,662:INFO:Starting cross validation
2025-04-06 21:58:06,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:07,809:INFO:Calculating mean and std
2025-04-06 21:58:07,810:INFO:Creating metrics dataframe
2025-04-06 21:58:07,811:INFO:Uploading results into container
2025-04-06 21:58:07,812:INFO:Uploading model into container now
2025-04-06 21:58:07,812:INFO:_master_model_container: 17
2025-04-06 21:58:07,812:INFO:_display_container: 2
2025-04-06 21:58:07,813:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-04-06 21:58:07,813:INFO:create_model() successfully completed......................................
2025-04-06 21:58:07,998:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:07,998:INFO:Creating metrics dataframe
2025-04-06 21:58:08,000:INFO:Initializing CatBoost Regressor
2025-04-06 21:58:08,000:INFO:Total runtime is 0.40164004961649585 minutes
2025-04-06 21:58:08,000:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:08,000:INFO:Initializing create_model()
2025-04-06 21:58:08,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:08,000:INFO:Checking exceptions
2025-04-06 21:58:08,000:INFO:Importing libraries
2025-04-06 21:58:08,001:INFO:Copying training dataset
2025-04-06 21:58:08,006:INFO:Defining folds
2025-04-06 21:58:08,006:INFO:Declaring metric variables
2025-04-06 21:58:08,006:INFO:Importing untrained model
2025-04-06 21:58:08,006:INFO:CatBoost Regressor Imported successfully
2025-04-06 21:58:08,007:INFO:Starting cross validation
2025-04-06 21:58:08,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:17,855:INFO:Calculating mean and std
2025-04-06 21:58:17,856:INFO:Creating metrics dataframe
2025-04-06 21:58:17,858:INFO:Uploading results into container
2025-04-06 21:58:17,859:INFO:Uploading model into container now
2025-04-06 21:58:17,859:INFO:_master_model_container: 18
2025-04-06 21:58:17,859:INFO:_display_container: 2
2025-04-06 21:58:17,859:INFO:<catboost.core.CatBoostRegressor object at 0x0000024FBB172A10>
2025-04-06 21:58:17,860:INFO:create_model() successfully completed......................................
2025-04-06 21:58:18,040:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:18,040:INFO:Creating metrics dataframe
2025-04-06 21:58:18,043:INFO:Initializing Dummy Regressor
2025-04-06 21:58:18,043:INFO:Total runtime is 0.569020446141561 minutes
2025-04-06 21:58:18,043:INFO:SubProcess create_model() called ==================================
2025-04-06 21:58:18,044:INFO:Initializing create_model()
2025-04-06 21:58:18,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024FBC306F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:18,044:INFO:Checking exceptions
2025-04-06 21:58:18,044:INFO:Importing libraries
2025-04-06 21:58:18,044:INFO:Copying training dataset
2025-04-06 21:58:18,049:INFO:Defining folds
2025-04-06 21:58:18,050:INFO:Declaring metric variables
2025-04-06 21:58:18,050:INFO:Importing untrained model
2025-04-06 21:58:18,050:INFO:Dummy Regressor Imported successfully
2025-04-06 21:58:18,051:INFO:Starting cross validation
2025-04-06 21:58:18,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-06 21:58:18,423:INFO:Calculating mean and std
2025-04-06 21:58:18,424:INFO:Creating metrics dataframe
2025-04-06 21:58:18,426:INFO:Uploading results into container
2025-04-06 21:58:18,426:INFO:Uploading model into container now
2025-04-06 21:58:18,427:INFO:_master_model_container: 19
2025-04-06 21:58:18,427:INFO:_display_container: 2
2025-04-06 21:58:18,427:INFO:DummyRegressor()
2025-04-06 21:58:18,427:INFO:create_model() successfully completed......................................
2025-04-06 21:58:18,634:INFO:SubProcess create_model() end ==================================
2025-04-06 21:58:18,635:INFO:Creating metrics dataframe
2025-04-06 21:58:18,639:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-06 21:58:18,641:INFO:Initializing create_model()
2025-04-06 21:58:18,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-06 21:58:18,641:INFO:Checking exceptions
2025-04-06 21:58:18,642:INFO:Importing libraries
2025-04-06 21:58:18,642:INFO:Copying training dataset
2025-04-06 21:58:18,647:INFO:Defining folds
2025-04-06 21:58:18,648:INFO:Declaring metric variables
2025-04-06 21:58:18,648:INFO:Importing untrained model
2025-04-06 21:58:18,648:INFO:Declaring custom model
2025-04-06 21:58:18,648:INFO:Huber Regressor Imported successfully
2025-04-06 21:58:18,650:INFO:Cross validation set to False
2025-04-06 21:58:18,650:INFO:Fitting Model
2025-04-06 21:58:18,862:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-06 21:58:18,862:INFO:HuberRegressor()
2025-04-06 21:58:18,862:INFO:create_model() successfully completed......................................
2025-04-06 21:58:19,034:INFO:_master_model_container: 19
2025-04-06 21:58:19,034:INFO:_display_container: 2
2025-04-06 21:58:19,035:INFO:HuberRegressor()
2025-04-06 21:58:19,035:INFO:compare_models() successfully completed......................................
2025-04-06 21:58:44,374:INFO:Initializing predict_model()
2025-04-06 21:58:44,374:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024FBA949260>)
2025-04-06 21:58:44,374:INFO:Checking exceptions
2025-04-06 21:58:44,374:INFO:Preloading libraries
2025-04-06 21:58:44,375:INFO:Set up data.
2025-04-06 21:58:44,386:INFO:Set up index.
2025-04-06 21:58:44,662:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-04-06 21:59:03,825:INFO:Initializing predict_model()
2025-04-06 21:59:03,825:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024FBFBE5DD0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024FBB25DE40>)
2025-04-06 21:59:03,825:INFO:Checking exceptions
2025-04-06 21:59:03,825:INFO:Preloading libraries
2025-04-06 21:59:03,825:INFO:Set up data.
2025-04-06 21:59:03,833:INFO:Set up index.
2025-04-06 21:59:03,900:WARNING:C:\Users\eduli\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

